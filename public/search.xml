<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[在不同机器上维护 hexo github blog 的方法和坑]]></title>
    <url>%2F2019%2F03%2F27%2Fmethods-and-pitfalls-on-maintaining-hexo-github-blog-from-multiple-devices%2F</url>
    <content type="text"><![CDATA[常规的更新文章或者更新主题之类的方法就不写了。由于是托管在 GitHub 上的 hexo 博客，不像是一般部署在一台固定机器上的 WordPress 那样从哪里都可以 ssh 上去管理。因此有必要记录一下摸索出来的过程。 方法主要是因为 hexo 实现 github blog 是通过 source/ 下一系列的 markdown 文件用于记录文章内容，再通过 hexo g 命令生成美观的静态页面在浏览器中显示，两者是缺一不可的：如果只有 markdown 文件，也不是不能读，但这样和读 README.md 没什么区别了，起不到博客的作用；如果只有静态页面文件，倒是像个博客了，但是如果要更新，改一次就累死人了。按照我的理解，前者相当于源码，后者相当于由源码编译出来的二进制文件，因此要两手抓，两手都要硬，通过两个分支来对整个 hexo github blog 进行管理就可以了。 在写完 markdown 文件之后，执行一下 hexo clean，把已经生成的静态页面文件都清理掉（据我理解实际上是把 public/ 删掉了，但不确定除此以外还有没有清理其它内容）。这个时候目录下的内容基本都是“源码”了，将这个状态下的整个目录 git push 到项目的某个次要分支。之后都是通过这个次要分支来维护每次更新，只要在 git clone 下来之后 git checkout 到这个分支就可以了。 维护完次要分支之后，就可以使用 hexo g 来生成静态页面文件了，这个过程视机器性能而定，快则几秒钟，慢则几分钟，在我的 VPS 上甚至有可能被 kill……在生成完静态页面文件之后，就可以直接部署到 GitHub 上了。前提是要有 hexo-deployer-git 这一个插件并且在配置文件里已经配置好 GitHub 的用户名和分支（这里需要用 master 分支），执行 hexo d 就可以直接部署上去了。这个过程的实质是把 public/ 里面的内容 push 到 master 分支了。 这样，静态页面文件通过 master 分支维护，访问者访问 foo.github.io 时访问的也是 master 分支的静态页面文件，而 markdown 文件则隐藏在次要分支的 source/ 中。 坑 主题目录文件丢失：如果是使用 next 之类的从 GitHub 上 clone 下来的主题，那么主题目录下就会有 .git 目录，而整个项目根目录也有一个 .git 目录，这就会导致在 push 到 GitHub 的时候会忽略掉整个主题目录的文件，下一次 clone 下来的时候主题目录就是空的了。解决方法：移除主题目录中的 .git* 目录/文件，避免出现嵌套 git 的情况。 hexo d 将整个项目根目录 push 到 master 分支：这种情况一般是在不同的位置（包括不同机器，或者同一台机器的不同目录）clone 项目导致的。在项目根目录下会有 .deploy_git/，这个目录下的内容和 public/ 一样，在这种情况下会产生混乱。解决方法：在 hexo clean 之前把 .deploy_git/ 目录删除，余下步骤照常执行。 更新内容后成功部署，但刷新页面不更新：由于是静态页面，因此浏览器会使用缓存。解决方法：ctrl + F5 刷新即可。]]></content>
      <tags>
        <tag>git</tag>
        <tag>坑</tag>
        <tag>GitHub</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何安装及管理 Ruby]]></title>
    <url>%2F2018%2F12%2F25%2Fhow-to-install-and-manage-ruby%2F</url>
    <content type="text"><![CDATA[可以使用 rvm 管理 Ruby 及其软件包。 预先安装 Ruby 需要使用到的软件包： 1yum install -y gcc-c++ patch readline readline-devel zlib zlib-devel libyaml-devel libffi-devel openssl-devel make bzip2 autoconf automake libtool bison iconv-devel 使用 rvm 官方提供的脚本安装 rvm： 1curl -L get.rvm.io | sh -s stable 如果按照以上命令安装 rvm 失败，需要使用以下方式更新相关证书： 12curl -sSL https://rvm.io/mpapis.asc | gpg2 --import -curl -sSL https://rvm.io/pkuczynski.asc | gpg2 --import - 证书更新之后再次执行 curl -L get.rvm.io | sh -s stable 安装 rvm。安装完成时候可以设置 rvm 命令： 1source /etc/profile.d/rvm.sh 查看当前 Ruby 版本： 1ruby -v 使用 rvm 安装指定版本的 Ruby： 1rvm install &#123;ruby_version&#125; 如果安装过程太慢，可以考虑切换到其它安装源镜像，在 /usr/local.rvm/user/db 文件中加入： 1ruby_url=&#123;ruby_source_url&#125; 即可。]]></content>
      <tags>
        <tag>Ruby</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[命令别名：定义自己的命令]]></title>
    <url>%2F2018%2F12%2F24%2FAliases-DIY-Shell-Commands%2F</url>
    <content type="text"><![CDATA[学习如何创建别名：你可以将太长或难以记忆的命令打包成你自己构建的命令。 命令别名Alias在 Linux shell 中指的是将一些太长或者太难记的多个命令组合起来，成为一个由用户自己构建的命令。 可以通过 alias 命令来创建命令别名。在 alias 后面跟上想要创建的别名名称、一个等号（=），以及希望使用这个别名来执行的命令，这样一个命令别名就创建好了。举个例子，ls 命令在默认情况下是不会对输出的内容进行着色的，这样就不能让用户一眼分辨出目录、文件和连接了。对此，可以创建这样一个命令别名，在输出目录内容的时候为输出内容着色： 1alias lc=&apos;ls --color=auto&apos; 其中 lc 是自定义的命令别名，代表 “list with color” 的意思。在创建命令别名的时候，需要先确认使用的别名是不是已经有对应的命令了，如果有的话，原本的命令就会被覆盖掉了。注意，定义命令别名的时候，= 两端是没有空格的。当运行 lc 的时候，就相当于执行了 ls --color 命令。 此后，执行 lc 列出目录内容的时候，就会输出带有着色的内容了。 你可能会发现你在执行 ls 的时候，本来就是输出带有着色的内容。那是因为大部分 Linux 发行版都已经将 ls 设定为带有着色的命令别名了。 可以直接使用的命令别名实际上，执行不带任何内容的 alias 命令就可以看到当前已经设定的所有命令别名。对于不同的发行版，包含的命令别名不尽相同，但普遍都会有以下这些命令别名： alias ls=&#39;ls --color=auto&#39;：这个命令别名在前面已经提到过了。--color=auto 参数会让 ls 命令在通过标准输出在终端中显示内容时进行着色，而其它情况（例如通过管道输出到文件）下则不进行着色。--color 这个参数还可以设置为 always 或never。 alias cp=&#39;cp -i&#39;：-i 参数代表“交互interactive”。在使用 cp 命令复制文件的时候，可能会无意中覆盖现有的文件，在使用了 -i 参数之后，cp 命令会在一些关键操作前向用户发出询问。 alias free=&#39;free -m&#39;：在 free 命令后面加上 -m 参数，就可以将输出的内存信息以 MiB 这个更方面阅读和计算的单位输出，而不是默认的 Byte 单位。 你使用的发行版自带的命令别名可能多多少少和上面有些差别。但你都可以在命令前面加上 \ 修饰符来使用命令的最基本形式（而不是别名）。例如： 1\free 就是直接执行 free，而不是 free -m。还有： 1\ls 执行的就是不带有--color=auto 参数的 ls。 如果想要持久地保存命令别名，可以在 .bashrc 文件中进行修改，而它来源于我们的 /etc/skel 目录。 使用命令别名纠正错误各种发行版的设计者都会尽量设置用户可能需要用到的命令别名。但是不同的用户的习惯各不相同，一些用户可能刚从其它操作系统迁移到 Linux，而不同操作系统的基本命令又因 shell 而异。因此，对于刚从 Windows/MS-DOS 系统迁移到 Linux 系统的用户，不妨使用 1alias dir=&apos;ls&apos; 这个命令别名来列出目录内容。 类似地， 12alias copy=&apos;cp&apos;alias move=&apos;mv&apos; 也可以在尚未完全熟悉 Linux 的时候用得顺手。 还有一种情况，就是在经常出现输入错误的场合中做出容错，例如，对于我来说， Administration 这个单词就很难快速正确地输入，因此很多用户都会设置类似这样的别名： 1alias sl=&apos;ls&apos; 以及 1alias gerp=&apos;echo &quot;You did it *again*!&quot;; grep&apos; grep 命令最基本的用途就是在文件中查找字符串，在熟悉这个命令之后，它一定是最常用的命令之一，因此输入错误导致不得不重输命令就很令人抓狂。 在上面 gerp 的例子中，包含的不只是一条命令，而是两条。第一条命令 echo &quot;You did it *again*!&quot; 输出了一条提醒用户拼写错误的消息，然后使用分号（；）把两条命令隔开，再往后才是 grep 这一条正确的命令。 在我的系统上使用 gerp 来搜索 /etc/skel/.bashrc 中包含“alias”这个单词的行，就会输出以下内容： 123456789101112$ gerp -R alias /etc/skel/.bashrcYou did it *again*! alias ls=&apos;ls --color=auto&apos; alias grep=&apos;grep --colour=auto&apos; alias egrep=&apos;egrep --colour=auto&apos; alias fgrep=&apos;fgrep --colour=auto&apos; alias cp=&quot;cp -i&quot;alias df=&apos;df -h&apos;alias free=&apos;free -m&apos;alias np=&apos;nano -w PKGBUILD&apos; alias more=less shopt -s expand_aliases 在命令别名中以固定的顺序执行多个命令，甚至更进一步，把多个命令串连起来，让后面的命令可以使用到前面的命令的执行结果。这样的做法已经非常接近 bash 脚本了。这篇文章已经接近尾声，我们将在下一篇文章中详细介绍。 如果想要删除在终端中临时设置的别名，可以使用 unalias 命令。 1unalias gerp 如果想要持久保存命令别名，可以将命令别名放在用户主目录的 .bashrc 文件中，具体的方法在上一篇文章中已经介绍过。 via: https://www.linux.com/blog/learn/2018/12/aliases-diy-shell-commands]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bash 环境变量的那些事]]></title>
    <url>%2F2018%2F12%2F23%2FBash-Variables-Environmental-and-Otherwise%2F</url>
    <content type="text"><![CDATA[初学者可以在此教程中了解环境变量。 bash 变量，尤其是讨厌的环境变量，已经是一个老生常谈的话题了。我们也更应该对它有一个详细的了解，让它为我们所用。 下面就打开终端，开始吧。 环境变量HOME （LCTT 译注：双关语）除了是你脱下帽子惬意休息的地方，同时也是 Linux 中的一个变量，它是当前用户主目录的路径： 1echo $HOME 以上这个命令会显示当前用户的主目录路径，通常都在 /home/&lt;your username&gt; 下。 顾名思义，变量的值是可以根据上下文变化的。实际上，Linux 系统中每一个用户的 HOME 变量都是不一样的，当然你也可以这样自行更改 HOME 变量的值： 1HOME=/home/&lt;your username&gt;/Documents 以上这个命令将会把 HOME 变量设置为你的 Documents 目录。 其中有三点需要留意： = 符号和其两侧的内容之间不加空格。空格在 shell 中有专门的意义，不能随意地在任何地方添加空格。 如果你需要对变量进行赋值，只需要使用变量名称就可以了。但如果需要读取或者使用变量的值，需要在变量前面加上一个 $ 号。 更改 HOME 变量具有一定的风险。有很多程序是依赖于 HOME 变量的，更改 HOME 变量可能会导致一些不可预见的结果。例如，如果按照上面的方式更改了 HOME 变量，然后执行不带有任何参数的 cd 命令，在通常情况下，会跳转到用户的主目录下，但在这个时候，会跳转到 HOME 变量指定的目录下。 上面第 3 点中环境变量的更改并不是持久有效的，在终端关闭后重新打开终端，又或者是新建一个终端，执行 echo $HOME 命令输出的仍然会是初始的值，而不是重新自定义的值。 在讨论如何持久地更改一个环境变量之前，我们先来看一下另一个比较重要的环境变量。 PATH 变量在 PATH 变量中存放了一系列目录，而且是放置了可执行程序的目录。正是由于 PATH 变量的存在，让你不需要知道应用程序具体安装到了什么目录，而 shell 却可以正确地找到这些应用程序。 如果你查看 PATH 变量的值，大概会是以下这样： 12$ echo $PATH/usr/local/sbin:/usr/local/bin:/usr/bin:/usr/sbin:/bin:/sbin 每两个目录之间使用冒号 : 分隔。如果某个应用程序的所在目录不在 PATH 变量中，那么运行的时候就需要声明应用程序的目录让 shell 能够找到。 1/home/&lt;user name&gt;/bin/my_program.sh 例如以上命令就会执行当前用户 bin/ 目录下的 my_program.sh 文件。 有一个常见的问题：如果你不希望弄乱系统的 bin/ 目录，同时也不希望你自己的文件被其它人运行，还不想每次运行的时候都要输入完整的路径，那么，你可以在你的主目录中创建一个独立的 bin/ 目录： 1mkdir $HOME/bin 然后将这个目录添加到 PATH 变量中： 1PATH=$PATH:$HOME/bin 然后 /home/&lt;user name&gt;/bin/ 目录就会出现在 PATH 变量中了。但正如之前所说，这个变更只会在当前的 shell 生效，当前的 shell 一旦关闭，环境变量的值就又恢复原状了。 如果要让变更对当前用户持续生效，就不能在 shell 中直接执行对应的变更，而是应该将这些变更操作写在每次启动 shell 时都会运行的文件当中。这个文件就是当前用户主目录中的 .bashrc 文件。文件名前面的点号表明这是一个隐藏文件，执行普通的 ls 命令是不会将这个文件显示出来的，但只要在 ls 命令中加入 -a 参数就可以看到这个文件了。 你可以使用诸如 kate、gedit、nano 或者 vim 这些文本编辑器来打开 .bashrc 文件（但不要用 LibreOffice Writer，它是一个文字处理软件，跟前面几个文字编辑器完全不同）。打开 .bashrc 文件之后，你会看见里面放置了一些 shell 命令，是用于为当前用户设置环境的。 在文件的末尾添加新行并输入以下内容： 1export PATH=$PATH:$HOME/bin 保存并关闭 .bashrc 文件，接下来你就会看到 export 语句的效果。执行以下的命令让刚才的修改立即生效： 1source .bashrc 刚才执行的 source 命令让 .bashrc 文件在当前的 shell 立即生效，并且对于之后打开的 shell 都会有效。因此另一个等效的方法是退出并重新进入 shell，但这样也太麻烦了。 现在，你的 shell 就能自动寻找到 /home/&lt;user name&gt;/bin/ 下的程序了，执行这个目录下的程序也不需要完整地写出程序的路径。 自定义变量当然，你也可以定义自己的变量。刚才我们看到的变量名称都是全大写的，实际上变量名称的定义还是比较灵活的。 定义新变量的过程非常直观，直接对它赋值就可以了： 1new_variable=&quot;Hello&quot; 然后可以用以下的方式读取到已定义变量的值： 1echo $new_variable 程序的正常工作离不开各种变量，例如要将某个选项设置为打开，又或者让程序找到所需的代码库，都需要使用变量。在 bash 中运行程序的时候会生成一个子 shell，这个子 shell 和执行原程序的父 shell 并不是完全一样的，只是继承了父 shell 的部分内容，而且默认是不继承父 shell 中的变量的。因为变量默认情况下是局部变量，出于安全原因，一个 shell 中的局部变量不会被另一个 shell 读取到，即使是子 shell 也不可以。 下面举一个例子。首先定义一个变量： 1robots=&quot;R2D2 &amp; C3PO&quot; 然后执行： 1bash 现在是在 bash shell 中创建了一个子 shell。 执行这个命令看看还能不能读取到刚才定义的变量： 1echo $robots 你会发现读取不到。 还是在这个子 shell 中，为 robots 变量赋一个不同的值： 1robots=&quot;These aren&apos;t the ones you are looking for&quot; 再读取一次： 12$ echo $robotsThese aren&apos;t the ones you are looking for 退出这个子 shell： 1exit 然后再看一下现在 robots 变量的值： 12$ echo $robotsR2D2 &amp; C3P0 这一个特性可以有效避免配置过程中产生混乱，同时也会导致一个问题：如果程序中需要设置变量，但却由于子 shell 的原因无法正常访问到这个变量，该如何解决呢？这个时候就需要用到 export 了。 重复一次刚才的过程，但这一次不是通过 robots=&quot;R2D2 &amp; C3PO&quot; 方式来设置变量，而是使用 export 命令： 1export robots=&quot;R2D2 &amp; C3PO&quot; 现在你会发现，在进入子 shell 之后，robots 变量的值仍然是最初赋予的值。 要注意的是，尽管子 shell 会继承通过 export 导出的变量，但如果在子 shell 中对这个变量重新赋值，是不会影响到父 shell 中对应变量的。 如果要查看所有通过 export 导出的变量，可以执行以下命令： 1export -p 自定义的变量会显示在这个列表的末尾。这个列表中还有一些常见的变量：例如 USER 的值是当前用户的用户名，PWD 的值是当前用户当前所在的目录，而 OLDPWD 的值则是当前用户上一个访问过的目录。因此如果执行： 1cd - 就会切换到上一个访问过的目录，那是因为 cd 命令读取到了 OLDPWD 变量的值。 你也可以使用 env 命令查看所有环境变量。 如果要取消导出一个变量，可以加上 -n 参数： 1export -n robots 接下来了解过环境变量的知识之后，你已经到达了可能对自己和他人造成危险的水平，接下来就需要了解如何通过使用别名来让环境变得更安全、更友好以保护自己了。 via: https://www.linux.com/blog/learn/2018/12/bash-variables-environmental-and-otherwise]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Bash</tag>
        <tag>环境变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无服务器架构的三个意义]]></title>
    <url>%2F2018%2F12%2F11%2F3-implications-of-serverless%2F</url>
    <content type="text"><![CDATA[以及，对于无服务器Serverless架构，什么时候该用，什么时候不该用呢？ 如果将如今互联网体验中最方便实用的那一部分去掉，那么留下来的基本就是客户端-服务端client-server模式了。这一个模式在互联网建立初期就已经在使用了，直到目前都没有太大的变化，也就是说，这个模式仍然在为我们服务。 那么，当人们谈论无服务器Serverless架构的时候，到底是指什么呢？其实，无服务器架构并不是说不使用服务器了。恰恰相反，客户端-服务端模式仍然在其中发挥着重要的作用。 无服务器架构实际上指的是能够让开发者在不需要关心服务器上架、为操作系统打补丁、创建容器镜像这些工作的情况下，就能够完成编码、部署和创建应用这一整套流程的架构。 无服务器架构的三个重要意义 一些缺乏开发经验的人员现在要参与到开发工作中来了。无服务器架构能够让他们尽量只学习必要的工作内容，把更多的时间放在更具创造性的开发工作中。 开发者不再需要重复造轮子。运行和维护服务器、为操作系统打补丁、创建容器等这一系列工作，都可以由更专业的无服务器架构提供商来完成。 最现实的一点是，如果不使用无服务器架构，那么在服务器管理方面，总需要有一个作最终决策的人。当服务器发生崩溃时，或是需要在服务器上执行某些操作时，总是需要这样一个统领全局的人来作出决策。因此最佳的方案是使用无服务器架构。 什么时候该用或者不该用无服务器架构？听起来无服务器架构是个好东西。但事实上，无服务器架构并不是万能的，在使用之前还需要考虑以下这些因素： 成本 使用范围 时间 控制方式 其中值得注意的是控制方式。现在已经有一些项目为开发者提供了操作和控制无服务器架构计算环境的工具了，Apache OpenWhisk 就是其中之一。 为什么要将无服务器架构开源？关于这方面的更多内容，可以观看无服务器架构方面的专家 Saron Yitbarek 在 Command Line Heroes 节目中的访谈。 via: https://opensource.com/article/18/12/serverless-podcast-command-line-heros]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>无服务器架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于 top 工具的 6 个替代方案]]></title>
    <url>%2F2018%2F12%2F08%2FSome-Alternatives-To-top-Command-line-Utility-You-Might-Want-To-Know%2F</url>
    <content type="text"><![CDATA[在 GitHub 和 GitLab 上，不断有来自世界各地的开源应用程序和工具涌现。其中有全新的应用程序，也有针对现有各种被广泛使用的 Linux 程序的替代方案。在本文档中，我会介绍一些针对 top 工具（也就是命令行任务管理器程序）的替代方案。 top 工具的替代方案在本文中，将会介绍以下 6 种 top 工具的替代方案： Htop Vtop Gtop Gotop Ptop Hegemon 如果后续有更多类似的工具，原作者会在原文进行更新。如果你对此有兴趣，可以持续关注。 Htophtop 是一个流行的开源跨平台交互式进程管理器，也是我最喜欢的系统活动监控工具。htop 是对原版 top 工具的扩展。它最初只是用于 Linux 系统，后来开发者们不断为其添加对其它类 Unix 操作系统的支持，包括 FreeBSD 和 Mac OS。htop 还是一个自由开源软件，它基于 ncurses 并按照 GPLv2 发布。 和原版的 top 工具相比，htop 工具有这些优势： htop 比 top 启动更快 htop 支持横向滚动和纵向滚动浏览进程列表，以便看到所有的进程和完整的命令行 在 top 工具中进行杀死进程、更改进程优先级这些操作时，需要输入进程 ID，而在 htop 工具中则不需要输入 在 htop 中可以同时杀死多个进程 在 top 中每次输入一个未预设的键都要等待一段时间，尤其是在多个键组成转义字符串的时候就更麻烦了 在很多 Linux 发行版的默认软件仓库中，都带有了 htop。 在基于 Arch 的操作系统中则可以执行以下命令来安装 htop： 1$ sudo pacman -S htop 在基于 Debian 的操作系统使用以下命令： 1$ sudo apt install htop 在使用 RPM 软件管理的操作系统使用以下命令： 1$ sudo dnf install htop 或者 1$ sudo yum install htop 在 openSUSE 系统中： 1$ sudo zypper in htop 用法 不带任何参数执行 htop 时，会显示如下画面： 1$ htop 从图上可以看出，htop 会在界面顶部显示内存、交换空间、任务总数、系统平均负载、系统正常运行时间这些常用指标，在下方则和 top 一样显示进程列表，并且将进程的 ID、用户、进程优先级、进程 nice 值、虚拟内存使用情况、CPU 使用情况、内存使用情况等信息以多列显示出来。如果你想详细了解这些数据的含义，可以在这里阅读参考。 和 top 不同的是，htop 支持对不同的操作使用专有的按键。以下列出一些用于与 htop 交互的快捷键： F1、h、?：进入帮助界面。 F2、Shift+s：进入设置界面。在设置界面中可以配置仪表板界面顶部显示哪些数据，以及设置颜色方案、显示列、显示顺序等等多种参数。 F3、/：在进程列表中进行搜索。 F4、\：进入筛选模式。输入一个字符串，筛选出包含这个字符串的进程。进入筛选模式后再按一次 F4 或者 ESC 可以退出筛选模式。 F5、t：切换默认显示模式和树型显示模式，在树型显示模式下按 + 可以查看子树。 F6、&lt;、&gt;：依次按照进程 ID、用户、进程优先级、进程 nice 值、CPU 使用率、内存使用率排序显示。 F7、]：提高所选进程的优先级。 F8、[：降低所选进程的优先级。 F9、k：杀死所选进程。可以用 ↑ / ↓ 键选择不同的进程并按 F9 杀死进程。 F10、q： 退出 htop 以上这些快捷键都在 htop 界面底部显示。 需要注意的是，这其中有一些快捷键可能会与已有的快捷键发生冲突。例如按 F2 之后可能没有进入 htop 的设置界面，而是开始了对终端窗口的重命名。在这种情况下，你可能要更改一下快捷键的设置。 除了以上列出的快捷键以外，还有一些带有其它功能的快捷键，例如： u 可以选择显示某个用户的进程。 Shift+m 可以按照内存使用量对进程列表排序。 Shift+p 可以按照 CPU 使用量对进程列表排序。 Shit+t 可以按照进程启动时间对进程列表排序。 CTRL+l 刷新界面。 htop 的所有功能都可以在启动后通过快捷键来调用，而不需要在启动的时候带上某个参数。当然，htop 也支持带参数启动。 例如按照以下方式启动 htop 就可以只显示某个用户的进程： 1$ htop -u &lt;username&gt; 更改界面自动刷新的时间间隔： 1$ htop -d 10 看，htop 确实比 top 好用多了。 想了解 htop 的更多细节，可以查阅它的手册页面： 1$ man htop 也可以查看它的项目主页 和 GitHub 仓库。 Vtopvtop 是 top 工具的另一个替代方案。它是一个使用 NodeJS 编写的、自由开源的命令行界面系统活动监视器，并使用 MIT 许可证发布。vtop 通过使用 unicode 中的盲文字符来绘制 CPU 和内存使用情况的可视化图表。 在安装 vtop 之前，需要先安装 NodeJS。如果还没有安装 NodeJS，可以按照这个教程进行安装。 NodeJS 安装完毕之后，执行以下命令安装 vtop： 1$ npm install -g vtop 安装好 vtop 就可以执行以下命令开始监控了。 1$ vtop 显示界面如下： 如上图所示，vtop 界面和 top、htop 都有所不同，它将不同的内容分别以多个框的布局显示。另外在界面底部也展示了用于与 vtop 交互的所有快捷键。 vtop 有这些快捷键： dd ：杀死一个进程。 ↑、k：向上移动。 ↓、j：向下移动。 ←、h ：放大图表。 →、l：缩小图表。 g ：跳转到进程列表顶部。 Shift+g ：跳转到进程列表底部。 c ：以 CPU 使用量对进程排序。 m ：以内存使用量对进程排序。 想要了解更多关于 vtop 的细节，可以查阅它的项目主页或者 GitHub 仓库。 Gtopgtop 和 vtop 一样，都是一个使用 NodeJS 编写、在 MIT 许可下发布的系统活动监视器。 执行以下命令安装 gtop： 1$ npm install gtop -g 然后执行以下命令启动： 1$ gtop 显示界面如下： gtop 有一个优点，就是它会以不同的颜色来显示不同的模块，这种表现形式非常清晰明了。 主要的快捷键包括： p：按照进程 ID 对进程排序。 c：按照 CPU 使用量对进程排序。 m：按照内存使用量对进程排序。 q、Ctrl+c：退出。 想要了解更多关于 gtop 的细节，可以查阅它的 GitHub 仓库。 Gotopgotop 也是一个完全自由和开源的图表式系统活动监视器。顾名思义，它是在受到 gtop 和 vtop 的启发之后用 Go 语言编写的，因此也不再对其展开过多的赘述了。如果你有兴趣了解这个项目，可以阅读《gotop：又一个图表式系统活动监视器》这篇文章。 Ptop有些人对 NodeJS 和 Go 语言的项目可能不太感冒。如果你也是其中之一，你可以试一下使用 Python 编写的 ptop。它同样是一个自由开源的、在 MIT 许可下发布的系统活动监视器。 ptop 同时兼容 Python2.x 和 Python3.x，因此可以使用 Python 的软件包管理器 pip 轻松安装。如果你没有安装 pip，也可以参考这个教程进行安装。 安装 pip 之后，执行以下命令就可以安装 ptop： 1$ pip install ptop 又或者按照以下方式通过源代码安装： 1234$ git clone https://github.com/darxtrix/ptop$ cd ptop/$ pip install -r requirements.txt # install requirements$ sudo python setup.py install 如果需要对 ptop 进行更新，可以这样操作： 1$ pip install --upgrade ptop 即使你不执行更新，ptop 也会在第一次启动的时候提示你是否需要更新到最新的版本。 现在可以看一下启动 ptop 后的界面。 1$ ptop 就像下面这样： ptop 的快捷键包括以下这些： Ctrl+k：杀死一个进程。 Ctrl+n：按照内存使用量对进程排序。 Ctrl+t：按照进程启动时间对进程排序。 Ctrl+r：重置所有数据。 Ctrl+f：对进程进行筛选，输入进程的名称就能够筛选出符合条件的进程。 Ctrl+l：查看所选进程的详细信息。 g：跳转到进程列表顶部。 Ctrl+q：退出。 ptop 还支持更改显示主题。如果你想让 ptop 更好看，可以选择你喜欢的主题。可用的主题包括以下这些： colorful elegant simple dark light 如果需要更换主题（例如更换到 colorful 主题），可以执行以下命令： 1$ ptop -t colorful 使用 -h 参数可以查看帮助页面： 1$ ptop -h 想要了解更多关于 ptop 的细节，可以查阅它的 GitHub 仓库。 Hegemonhegemon 是一个使用 Rust 编写的系统活动监视器，如果你对 Rust 感兴趣，也可以了解一下。我们最近有一篇关于 hegemon 的文章，想要详细了解的读者不妨阅读。 总结以上就是关于 top 工具的 6 个替代方案。我并不会说它们比 top 更好或者可以完全替代 top，但多了解一些类似的工具总是好的。你有使用过这些工具吗？哪个是你最喜欢的？欢迎在评论区留言。 via: https://www.ostechnix.com/some-alternatives-to-top-command-line-utility-you-might-want-to-know/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>top</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[提高 Linux 的网络浏览器安全性的 5 个建议]]></title>
    <url>%2F2018%2F12%2F03%2F5-Easy-Tips-for-Linux-Web-Browser-Security%2F</url>
    <content type="text"><![CDATA[这些简单的步骤可以大大提高您的在线安全性。 如果你使用 Linux 桌面但从来不使用网络浏览器，那你算得上是百里挑一。网络浏览器是绝大多数人最常用的工具之一，无论是工作、娱乐、看新闻、社交、理财，对网络浏览器的依赖都比本地应用要多得多。因此，我们需要知道如何使用网络浏览器才是安全的。一直以来都有不法的犯罪分子以及他们建立的网页试图窃取私密的信息。正是由于我们需要通过网络浏览器收发大量的敏感信息，安全性就更是至关重要。 对于用户来说，需要采取什么措施呢？在下文中，我会提出一些基本的建议，让你的重要数据不会被他人轻易窃取。尽管我用于演示的是 Firefox 网络浏览器，但其中大部分建议在任何一种网络浏览器当中都可以适用。 正确选择浏览器尽管我提出的建议具有普适性，但是正确选择网络浏览器也是很必要的。网络浏览器的更新频率是它安全性的一个重要体现。网络浏览器会不断暴露出新的问题，因此版本越新的网络浏览器修复的问题就越多，也越安全。在主流的网络浏览器当中，2017 年版本更新的发布量排行榜如下： Chrome 发布了 8 个更新（Chromium 全年跟进发布了大量安全补丁）。 Firefox 发布了 7 个更新。 Edge 发布了 2 个更新。 Safari 发布了 1 个更新（苹果也会每年发布 5 到 6 个安全补丁）。 网络浏览器会经常发布更新，同时用户也要及时升级到最新的版本，否则毫无意义了。尽管大部分流行的 Linux 发行版都会自动更新网络浏览器到最新版本，但还是有一些 Linux 发行版不会自动进行更新，所以最好还是手动保持浏览器更新到最新版本。这就意味着你所使用的 Linux 发行版对应的标准软件库中存放的很可能就不是最新版本的网络浏览器，在这种情况下，你可以随时从网络浏览器开发者提供的最新版本下载页中进行下载安装。 如果你是一个勇于探索的人，你还可以尝试使用测试版或者每日构建daily build版的网络浏览器，不过，这些版本将伴随着不能稳定运行的可能性。在基于 Ubuntu 的发行版中，你可以使用到每日构建版的 Firefox，只需要执行以下命令添加所需的存储库： 1sudo apt-add-repository ppa:ubuntu-mozilla-daily/ppa 按照以下命令更新 apt 并安装每日构建版 Firefox： 12sudo apt-get updatesudo apt-get install firefox 最重要的事情就是永远不要让你的网络浏览器版本过时，必须使用最新版本的网络浏览器。就是这样。如果你没有跟上版本更新的脚步，你使用的将会是一个暴露着各种问题的浏览器。 使用隐私窗口将网络浏览器更新到最新版本之后，又该如何使用呢？答案是使用隐私窗口，如果你确实很重视安全的话。隐私窗口不会保存你的数据：密码？cookie？缓存？历史？什么都不会保存。因此隐私窗口的一个显著缺点就是每次访问常用的网站或者服务时，都得重新输入密码才能登录使用。当然，如果你认为网络浏览器的安全性很重要，就永远都不要保存任何密码。 说到这里，我觉得每一个人都需要让自己的密码变得更强。事实上，大家都应该使用强密码，然后通过管理器来存储。而我的选择是通用密码管理器Universal Password Manager。 保护好密码有的人可能会认为，每次都需要重复输入密码，这样的操作太麻烦了。在 Firefox 中，如果你既想保护好自己的密码，又不想经常输入密码，就可以通过主密码Master Password这一款内置的工具来实现你的需求。起用了这个工具之后，需要输入正确的主密码，才能后续使用保存在浏览器中的其它密码。你可以按照以下步骤进行操作： 打开 Firefox。 点击菜单按钮。 点击“偏好设置”。 在偏好设置页面，点击“隐私与安全”。 在页面中勾选“使用主密码”选项（图 1）。 确认以后，输入新的主密码（图 2）。 重启 Firefox。 图 1： Firefox 偏好设置页中的主密码设置。 图 2：在 Firefox 中设置主密码。 了解你使用的扩展和插件大多数网络浏览器在保护隐私方面都有很多扩展，你可以根据自己的需求选择不同的扩展。而我自己则选择了一下这些扩展： Firefox Multi-Account Containers —— 允许将某些站点配置为在容器化选项卡中打开。 Facebook Container —— 始终在容器化选项卡中打开 Facebook（这个扩展需要 Firefox Multi-Account Containers）。 Avast Online Security —— 识别并拦截已知的钓鱼网站，并显示网站的安全评级（由超过 4 亿用户的 Avast 社区支持）。 Mining Blocker —— 拦截所有使用 CPU 的挖矿工具。 PassFF —— 通过集成 pass （一个 UNIX 密码管理器）以安全存储密码。 Privacy Badger —— 自动拦截网站跟踪。 uBlock Origin —— 拦截已知的网站跟踪。 除此以外，以下这些浏览器还有很多安全方面的扩展： Firefox Chrome、Chromium,、Vivaldi Opera 但并非每一个网络浏览器都会向用户提供扩展或插件。例如 Midoria 就只有少量可以开启或关闭的内置插件（图 3），同时这些轻量级浏览器的第三方插件也相当缺乏。 图 3：Midori 浏览器的插件窗口。 虚拟化如果担心数据在本地存储会被窃取，也可以在虚拟机上运行网络浏览器。只需要安装诸如 VirtualBox 的软件并安装 Linux 系统，然后就可以在虚拟机中运行任何一款浏览器了。再结合以上几条建议，基本可以保证一定的安全性。 事情的真相实际上，如果你的机器连接到互联网，就永远不能保证 100% 的安全。当然，只要你正确地使用网络浏览器，你的安全系数会更高，数据也不会轻易被窃取。Linux 的一个好处是被安装恶意软件的几率比其它操作系统要低得多。另外，请记住要使用最新版本的网络浏览器、保持更新操作系统，并且谨慎访问一切网站。 你还可以通过 Linux 基金会和 edX 开办的 “Linux 介绍” 公开课学习到更多这方面的内容。 via: https://www.linux.com/learn/intro-to-linux/2018/11/5-easy-tips-linux-web-browser-security]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>浏览器</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android 9.0 概览]]></title>
    <url>%2F2018%2F11%2F29%2FAn-Overview-of-Android-Pie%2F</url>
    <content type="text"><![CDATA[第九代 Android 带来了更令人满意的用户体验。 我们来谈论一下 Android。尽管 Android 只是一款内核经过修改的 Linux，但经过多年的发展，Android 开发者们（或许包括正在阅读这篇文章的你）已经为这个平台的演变做出了很多值得称道的贡献。当然，可能很多人都已经知道，但我们还是要说，Android 并不完全开源，当你使用 Google 服务的时候，就已经接触到闭源的部分了。Google Play 商店就是其中之一，它不是一个开放的服务。不过无论 Android 开源与否，这就是一个美味、营养、高效、省电的馅饼（LCTT 译注：Android 9.0 代号为 Pie）。 我在我的 Essential PH-1 手机上运行了 Android 9.0（我真的很喜欢这款手机，也知道这家公司的境况并不好）。在我自己体验了一段时间之后，我认为它是会被大众接受的。那么 Android 9.0 到底好在哪里呢？下面我们就来深入探讨一下。我们的出发点是用户的角度，而不是开发人员的角度，因此我也不会深入探讨太底层的方面。 手势操作Android 系统在新的手势操作方面投入了很多，但实际体验却不算太好。这个功能确实引起了我的兴趣。在这个功能发布之初，大家都对它了解甚少，纷纷猜测它会不会让用户使用多点触控的手势来浏览 Android 界面？又或者会不会是一个完全颠覆人们认知的东西？ 实际上，手势操作比大多数人设想的要更加微妙而简单，因为很多功能都浓缩到了 Home 键上。打开手势操作功能之后，Recent 键的功能就合并到 Home 键上了。因此，如果需要查看最近打开的应用程序，就不能简单地通过 Recent 键来查看，而应该从 Home 键向上轻扫一下。（图 1） 图 1：Android 9.0 中的”最近的应用程序“界面。 另一个不同的地方是 App Drawer。类似于查看最近打开的应用，需要在 Home 键向上滑动才能打开 App Drawer。 而后退按钮则没有去掉。在应用程序需要用到后退功能时，它就会出现在主屏幕的左下方。有时候即使应用程序自己带有后退按钮，Android 的后退按钮也会出现。 当然，如果你不喜欢使用手势操作，也可以禁用这个功能。只需要按照下列步骤操作： 打开”设置“ 向下滑动并进入“系统 &gt; 手势” 从 Home 键向上滑动 将 On/Off 滑块（图 2）滑动至 Off 位置 图 2：关闭手势操作。 电池寿命人工智能已经在 Android 得到了充分的使用。现在，Android 使用人工智能大大提供了电池的续航时间，这样的新技术称为自适应电池。自适应电池可以根据用户的个人使用习惯来决定各种应用和服务的耗电优先级。通过使用人工智能技术，Android 可以分析用户对每一个应用或服务的使用情况，并适当地关闭未使用的应用程序，以免长期驻留在内存中白白消耗电池电量。 对于这个功能的唯一一个警告是，如果人工智能出现问题并导致电池电量过早耗尽，就只能通过恢复出厂设置来解决这个问题了。尽管有这样的缺陷，在电池续航时间方面，Android 9.0 也比 Android 8.0 有所改善。 分屏功能的变化分屏对于 Android 来说不是一个新功能，但在 Android 9.0 上，它的使用方式和以往相比略有不同，而且只对于手势操作有影响，不使用手势操作的用户不受影响。要在 Android 9.0 上使用分屏功能，需要按照下列步骤操作： 从 Home 键向上滑动，打开“最近的应用程序”。 找到需要放置在屏幕顶部的应用程序。 长按应用程序顶部的图标以显示新的弹出菜单。（图 3） 点击分屏，应用程序会在屏幕的上半部分打开。 找到要打开的第二个应用程序，然后点击它添加到屏幕的下半部分。 图 3：在 Android 9.0 上将应用添加到分屏模式中。 使用分屏功能关闭应用程序的方法和原来保持一致。 应用操作这个功能在早前已经引入了，但直到 Android 9.0 发布，人们才开始对它产生明显的关注。应用操作功能可以让用户直接从应用启动器来执行应用里的某些操作。 例如，长按 GMail 启动器，就可以执行回复最近的邮件、撰写新邮件等功能。在 Android 8.0 中，这个功能则以弹出动作列表的方式展现。在 Android 9.0 中，这个功能更契合 Google 的材料设计Material Design风格（图 4）。 图 4：Android 应用操作。 声音控制在 Android 中，声音控制的方式经常发生变化。在 Android 8.0 对“请勿打扰”功能进行调整之后，声音控制已经做得相当不错了。而在 Android 9.0 当中，声音控制再次进行了优化。 Android 9.0 这次优化针对的是设备上快速控制声音的按钮。如果用户按下音量增大或减小按钮，就会看到一个新的弹出菜单，可以让用户控制设备的静音和震动情况。点击这个弹出菜单顶部的图标（图 5），可以在完全静音、静音和正常声音几种状态之间切换。 图 5：Android 9.0 上的声音控制。 屏幕截图由于我要撰写关于 Android 的文章，所以我会常常需要进行屏幕截图。而 Android 9.0 有一项我最喜欢的更新，就是分享屏幕截图。Android 9.0 可以在截取屏幕截图后，直接共享、编辑，或者删除不喜欢的截图，而不需要像以前一样打开 Google 相册、找到要共享的屏幕截图、打开图像然后共享图像。 如果你想分享屏幕截图，只需要在截图后等待弹出菜单，点击分享（图 6），从标准的 Android 分享菜单中分享即可。 图 6：共享屏幕截图变得更加容易。 更令人满意的 Android 体验Android 9.0 带来了更令人满意的用户体验。当然，以上说到的内容只是它的冰山一角。如果需要更多信息，可以查阅 Google 的官方 Android 9.0 网站。如果你的设备还没有收到升级推送，请耐心等待，Android 9.0 值得等待。 via: https://www.linux.com/learn/2018/10/overview-android-pie]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Android</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GPL 合作承诺的发展历程]]></title>
    <url>%2F2018%2F11%2F28%2FWhat-you-need-to-know-about-the-GPL-Cooperation-Commitment%2F</url>
    <content type="text"><![CDATA[GPL 合作承诺GPL Cooperation Commitment消除了开发者对许可证失效的顾虑，从而达到促进技术创新的目的。 假如能免于顾虑，技术创新和发展将会让世界发生天翻地覆的改变。GPL 合作承诺GPL Cooperation Commitment就这样应运而生，只为通过公平、一致、可预测的许可证来让科技创新无后顾之忧。 去年，我曾经写过一篇文章，讨论了许可证对开源软件下游用户的影响。在进行研究的时候，我就发现许可证的约束力并不强，而且很多情况下是不可预测的。因此，我在文章中提出了一个能使开源许可证具有一致性和可预测性的潜在解决方案。但我只考虑到了诸如通过法律系统立法的“传统”方法。 2017 年 11 月，RedHat、IBM、Google 和 Facebook 提出了这种我从未考虑过的非传统的解决方案：GPL 合作承诺。GPL 合作承诺规定了 GPL 公平一致执行的方式。我认为，GPL 合作承诺之所以有这么深刻的意义，有以下两个原因：一是许可证的公平性和一致性对于开源社区的发展来说至关重要，二是法律对不可预测性并不容忍。 了解 GPL要了解 GPL 合作承诺，首先要了解什么是 GPL。GPL 是 GNU 通用许可证GNU General Public License的缩写，它是一个公共版权的开源许可证，这就意味着开源软件的分发者必须向下游用户公开源代码。GPL 还禁止对下游的使用作出限制，要求个人用户不得拒绝他人对开源软件的使用自由、研究自由、共享自由和改进自由。GPL 规定，只要下游用户满足了许可证的要求和条件，就可以使用该许可证。如果被许可人出现了不符合许可证的情况，则视为违规。 按照第二版 GPL（GPLv2）的描述，许可证会在任何违规的情况下自动终止，这就导致了部分开发者对 GPL 有所抗拒。而在第三版 GPL（GPLv3）中则引入了“治愈条款cure provision”，这一条款规定，被许可人可以在 30 天内对违反 GPL 的行为进行改正，如果在这个缓冲期内改正完成，许可证就不会被终止。 这一规定消除了许可证被无故终止的顾虑，从而让软件的开发者和用户专注于开发和创新。 GPL 合作承诺做了什么GPL 合作承诺将 GPLv3 的治愈条款应用于使用 GPLv2 的软件上，让使用 GPLv2 许可证的开发者避免许可证无故终止的窘境，并与 GPLv3 许可证保持一致。 很多软件开发者都希望正确合规地做好一件事情，但有时候却不了解具体的实施细节。因此，GPL 合作承诺的重要性就在于能够对软件开发者们做出一些引导，让他们避免因一些简单的错误导致许可证违规终止。 Linux 基金会技术顾问委员会在 2017 年宣布，Linux 内核项目将会采用 GPLv3 的治愈条款。在 GPL 合作承诺的推动下，很多大型科技公司和个人开发者都做出了相同的承诺，会将该条款扩展应用于他们采用 GPLv2（或 LGPLv2.1）许可证的所有软件，而不仅仅是对 Linux 内核的贡献。 GPL 合作承诺的广泛采用将会对开源社区产生非常积极的影响。如果更多的公司和个人开始采用 GPL 合作承诺，就能让大量正在使用 GPLv2 或 LGPLv2.1 许可证的软件以更公平和更可预测的形式履行许可证中的条款。 截至 2018 年 11 月，包括 IBM、Google、亚马逊、微软、腾讯、英特尔、RedHat 在内的 40 余家行业巨头公司都已经签署了 GPL 合作承诺，以期为开源社区创立公平的标准以及提供可预测的执行力。GPL 合作承诺是开源社区齐心协力引领开源未来发展方向的一个成功例子。 GPL 合作承诺能够让下游用户了解到开发者对他们的尊重，同时也表示了开发者使用了 GPLv2 许可证的代码是安全的。如果你想查阅更多信息，包括如何将自己的名字添加到 GPL 合作承诺中，可以访问 GPL 合作承诺的网站。 via: https://opensource.com/article/18/11/gpl-cooperation-commitment]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>GPL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Linux 上自定义 bash 命令提示符]]></title>
    <url>%2F2018%2F11%2F26%2FHow-To-Customize-Bash-Prompt-In-Linux%2F</url>
    <content type="text"><![CDATA[众所周知，bash（the Bourne-Again Shell）是目前绝大多数 Linux 发行版使用的默认 shell。本文将会介绍如何通过添加颜色和样式来自定义 bash 命令提示符的显示。尽管很多插件或工具都可以很轻易地满足这一需求，但我们也可以不使用插件和工具，自己手动自定义一些基本的显示方式，例如添加或者修改某些元素、更改前景色、更改背景色等等。 在 Linux 中自定义 bash 命令提示符在 bash 中，我们可以通过更改 $PS1 环境变量的值来自定义 bash 命令提示符。 一般情况下，bash 命令提示符会是以下这样的形式： 在上图这种默认显示形式当中，“sk” 是我的用户名，而 “ubuntuserver” 是我的主机名。 只要插入一些以反斜杠开头的特殊转义字符串，就可以按照你的喜好修改命令提示符了。下面我来举几个例子。 在开始之前，我强烈建议你预先备份 ~/.bashrc 文件。 1$ cp ~/.bashrc ~/.bashrc.bak 更改 bash 命令提示符中的 username@hostname 部分如上所示，bash 命令提示符一般都带有 “username@hostname” 部分，这个部分是可以修改的。 只需要编辑 ~/.bashrc 文件： 1$ vi ~/.bashrc 在文件的最后添加一行： 1PS1=&quot;ostechnix&gt; &quot; 将上面的 “ostechnix” 替换为任意一个你想使用的单词，然后按 ESC 并输入 :wq 保存、退出文件。 执行以下命令使刚才的修改生效： 1$ source ~/.bashrc 你就可以看见 bash 命令提示符中出现刚才添加的 “ostechnix” 了。 再来看看另一个例子，比如将 “username@hostname” 替换为 “Hello@welcome&gt;”。 同样是像刚才那样修改 ~/.bashrc 文件。 1export PS1=&quot;Hello@welcome&gt; &quot; 然后执行 source ~/.bashrc 让修改结果立即生效。 以下是我在 Ubuntu 18.04 LTS 上修改后的效果。 仅显示用户名如果需要仅显示用户名，只需要在 ~/.bashrc 文件中加入以下这一行。 1export PS1=&quot;\u &quot; 这里的 \u 就是一个转义字符串。 下面提供了一些可以添加到 $PS1 环境变量中的用以改变 bash 命令提示符样式的转义字符串。每次修改之后，都需要执行 source ~/.bashrc 命令才能立即生效。 显示用户名和主机名1export PS1=&quot;\u\h &quot; 命令提示符会这样显示： 1skubuntuserver 显示用户名和完全限定域名1export PS1=&quot;\u\H &quot; 在用户名和主机名之间显示其它字符如果你还需要在用户名和主机名之间显示其它字符（例如 @），可以使用以下格式： 1export PS1=&quot;\u@\h &quot; 命令提示符会这样显示： 1sk@ubuntuserver 显示用户名、主机名，并在末尾添加 $ 符号1export PS1=&quot;\u@\h\\$ &quot; 综合以上两种显示方式1export PS1=&quot;\u@\h&gt; &quot; 命令提示符最终会这样显示： 1sk@ubuntuserver&gt; 相似地，还可以添加其它特殊字符，例如冒号、分号、星号、下划线、空格等等。 显示用户名、主机名、shell 名称1export PS1=&quot;\u@\h&gt;\s &quot; 显示用户名、主机名、shell 名称以及 shell 版本1export PS1=&quot;\u@\h&gt;\s\v &quot; bash 命令提示符显示样式： 显示用户名、主机名、当前目录1export PS1=&quot;\u@\h\w &quot; 如果当前目录是 $HOME ，会以一个波浪线（~）显示。 在 bash 命令提示符中显示日期除了用户名和主机名，如果还想在 bash 命令提示符中显示日期，可以在 ~/.bashrc 文件中添加以下内容： 1export PS1=&quot;\u@\h&gt;\d &quot; 在 bash 命令提示符中显示日期及 12 小时制时间1export PS1=&quot;\u@\h&gt;\d\@ &quot; 显示日期及 hh:mm:ss 格式时间1export PS1=&quot;\u@\h&gt;\d\T &quot; 显示日期及 24 小时制时间1export PS1=&quot;\u@\h&gt;\d\A &quot; 显示日期及 24 小时制 hh:mm:ss 格式时间1export PS1=&quot;\u@\h&gt;\d\t &quot; 以上是一些常见的可以改变 bash 命令提示符的转义字符串。除此以外的其它转义字符串，可以在 bash 的 man 手册 PROMPTING 章节中查阅。 你也可以随时执行以下命令查看当前的命令提示符样式。 1$ echo $PS1 在 bash 命令提示符中去掉 username@hostname 部分如果我不想做任何调整，直接把 username@hostname 部分整个去掉可以吗？答案是肯定的。 如果你是一个技术方面的博主，你有可能会需要在网站或者博客中上传自己的 Linux 终端截图。或许你的用户名和主机名太拉风、太另类，不想让别人看到，在这种情况下，你就需要隐藏命令提示符中的 “username@hostname” 部分。 如果你不想暴露自己的用户名和主机名，只需要按照以下步骤操作。 编辑 ~/.bashrc 文件： 1$ vi ~/.bashrc 在文件末尾添加这一行： 1PS1=&quot;\W&gt; &quot; 输入 :wq 保存并关闭文件。 执行以下命令让修改立即生效。 1$ source ~/.bashrc 现在看一下你的终端，“username@hostname” 部分已经消失了，只保留了一个 ~&gt; 标记。 如果你想要尽可能简单的操作，又不想弄乱你的 ~/.bashrc 文件，最好的办法就是在系统中创建另一个用户（例如 “user@example”、“admin@demo”）。用带有这样的命令提示符的用户去截图或者录屏，就不需要顾虑自己的用户名或主机名被别人看见了。 警告：在某些情况下，这种做法并不推荐。例如像 zsh 这种 shell 会继承当前 shell 的设置，这个时候可能会出现一些意想不到的问题。这个技巧只用于隐藏命令提示符中的 “username@hostname” 部分，仅此而已，如果把这个技巧挪作他用，也可能会出现异常。 为 bash 命令提示符着色目前我们也只是变更了 bash 命令提示符中的内容，下面介绍一下如何对命令提示符进行着色。 通过向 ~/.bashrc 文件写入一些配置，可以修改 bash 命令提示符的前景色（也就是文本的颜色）和背景色。 例如，下面这一行配置可以令某些文本的颜色变成红色： 1export PS1=&quot;\u@\[\e[31m\]\h\[\e[m\] &quot; 添加配置后，执行 source ~/.bashrc 立即生效。 你的 bash 命令提示符就会变成这样： 类似地，可以用这样的配置来改变背景色： 1export PS1=&quot;\u@\[\e[31;46m\]\h\[\e[m\] &quot; 添加 emoji大家都喜欢 emoji。还可以按照以下配置把 emoji 插入到命令提示符中。 1PS1=&quot;\W 🔥 &gt;&quot; 需要注意的是，emoji 的显示取决于使用的字体，因此某些终端可能会无法正常显示 emoji，取而代之的是一些乱码或者单色表情符号。 自定义 bash 命令提示符有点难，有更简单的方法吗？如果你是一个新手，编辑 $PS1 环境变量的过程可能会有些困难，因为命令提示符中的大量转义字符串可能会让你有点晕头转向。但不要担心，有一个在线的 bash $PS1 生成器可以帮助你轻松生成各种 $PS1 环境变量值。 就是这个网站： 只需要直接选择你想要的 bash 命令提示符样式，添加颜色、设计排序，然后就完成了。你可以预览输出，并将配置代码复制粘贴到 ~/.bashrc 文件中。就这么简单。顺便一提，本文中大部分的示例都是通过这个网站制作的。 我把我的 ~/.bashrc 文件弄乱了，该如何恢复？正如我在上面提到的，强烈建议在更改 ~/.bashrc 文件前做好备份（在更改其它重要的配置文件之前也一定要记得备份）。这样一旦出现任何问题，你都可以很方便地恢复到更改之前的配置状态。当然，如果你忘记了备份，还可以按照下面这篇文章中介绍的方法恢复为默认配置。 如何将 ~/.bashrc 文件恢复到默认配置 这篇文章是基于 ubuntu 的，但也适用于其它的 Linux 发行版。不过事先声明，这篇文章的方法会将 ~/.bashrc 文件恢复到系统最初时的状态，你对这个文件做过的任何修改都将丢失。 感谢阅读！ via: https://www.ostechnix.com/hide-modify-usernamelocalhost-part-terminal/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ProtectedText：一个免费的在线加密笔记]]></title>
    <url>%2F2018%2F11%2F25%2FProtectedText-A-Free-Encrypted-Notepad-To-Save-Your-Notes-Online%2F</url>
    <content type="text"><![CDATA[记录笔记是我们每个人必备的重要技能，它可以帮助我们把自己听到、读到、学到的内容长期地保留下来，也有很多的应用和工具都能让我们更好地记录笔记。下面我要介绍一个叫做 ProtectedText 的应用，这是一个可以将你的笔记在线上保存起来的免费的加密笔记。它是一个免费的 web 服务，在上面记录文本以后，它将会对文本进行加密，只需要一台支持连接到互联网并且拥有 web 浏览器的设备，就可以访问到记录的内容。 ProtectedText 不会向你询问任何个人信息，也不会保存任何密码，没有广告，没有 Cookies，更没有用户跟踪和注册流程。除了拥有密码能够解密文本的人，任何人都无法查看到笔记的内容。而且，使用前不需要在网站上注册账号，写完笔记之后，直接关闭浏览器，你的笔记也就保存好了。 在加密笔记本上记录笔记访问 https://www.protectedtext.com/ 这个链接，就可以打开 ProtectedText 页面了（LCTT 译注：如果访问不了，你知道的）。这个时候你将进入网站主页，接下来需要在页面上的输入框输入一个你想用的名称，或者在地址栏后面直接加上想用的名称。这个名称是一个自定义的名称（例如 https://www.protectedtext.com/mysite），是你查看自己保存的笔记的专有入口。 如果你选用的名称还没有被占用，你就会看到下图中的提示信息。点击 “Create” 键就可以创建你的个人笔记页了。 至此你已经创建好了你自己的笔记页面，可以开始记录笔记了。目前每个笔记页的最大容量是每页 750000+ 个字符。 ProtectedText 使用 AES 算法对你的笔记内容进行加密和解密，而计算散列则使用了 SHA512 算法。 笔记记录完毕以后，点击顶部的 “Save” 键保存。 按下保存键之后，ProtectedText 会提示你输入密码以加密你的笔记内容。按照它的要求输入两次密码，然后点击 “Save” 键。 尽管 ProtectedText 对你使用的密码没有太多要求，但毕竟密码总是一寸长一寸强，所以还是最好使用长且复杂的密码（用到数字和特殊字符）以避免暴力破解。由于 ProtectedText 不会保存你的密码，一旦密码丢失，密码和笔记内容就都找不回来了。因此，请牢记你的密码，或者使用诸如 Buttercup、KeeWeb 这样的密码管理器来存储你的密码。 在使用其它设备时，可以通过访问之前创建的 URL 就可以访问你的笔记了。届时会出现如下的提示信息，只需要输入正确的密码，就可以查看和编辑你的笔记。 一般情况下，只有知道密码的人才能正常访问笔记的内容。如果你希望将自己的笔记公开，只需要以 https://www.protectedtext.com/yourSite?yourPassword 的形式访问就可以了，ProtectedText 将会自动使用 yourPassword 字符串解密你的笔记。 ProtectedText 还有配套的 Android 应用 可以让你在移动设备上进行同步笔记、离线工作、备份笔记、锁定/解锁笔记等等操作。 优点 简单、易用、快速、免费 ProtectedText.com 的客户端代码可以在这里免费获取，如果你想了解它的底层实现，可以自行学习它的源代码 存储的内容没有到期时间，只要你愿意，笔记内容可以一直保存在服务器上 可以让你的数据限制为私有或公开开放 缺点 尽管客户端代码是公开的，但服务端代码并没有公开，因此你无法自行搭建一个类似的服务。如果你不信任这个网站，请不要使用。 由于网站不存储你的任何个人信息，包括你的密码，因此如果你丢失了密码，数据将永远无法恢复。网站方还声称他们并不清楚谁拥有了哪些数据，所以一定要牢记密码。 如果你想通过一种简单的方式将笔记保存到线上，并且需要在不需要安装任何工具的情况下访问，那么 ProtectedText 会是一个好的选择。如果你还知道其它类似的应用程序，欢迎在评论区留言！ via: https://www.ostechnix.com/protectedtext-a-free-encrypted-notepad-to-save-your-notes-online/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>加密</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker 运行官方 MySQL 镜像无法远程连接的坑]]></title>
    <url>%2F2018%2F11%2F21%2Fa-pitfall-of-connecting-failure-to-mysql-in-docker%2F</url>
    <content type="text"><![CDATA[使用 Docker 官方提供的 MySQL 镜像进行安装、建立容器（必须指定端口映射和 root 口令）。 12docker pull mysql:latestdocker run -p 9527:3306 -e MYSQL_ROOT_PASSWORD=root -d mysql 但此时如果直接远程连接该容器中的 MySQL 并输入口令后，则会出现报错信息： 1ERROR 2059 (HY000): Authentication plugin &apos;caching_sha2_password&apos; cannot be loaded: /usr/lib64/mysql/plugin/caching_sha2_password.so: cannot open shared object file: No such file or directory 根据报错信息，连接失败原因为口令使用了 caching_sha2_password 方式进行加密，通过 SELECT user, host, plugin, authentication_string FROM user WHERE user=&#39;root&#39;; 查询可以看到 root 用户的口令确实是使用 caching_sha2_password 方式进行加密，而客户端找不到 caching_sha2_password 插件，因此连接失败。 根据官方文档，可以将加密方式更改为 mysql_native_password。通过 ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;root&#39;; 将 root 用户的口令加密方式更改为 mysql_native_password，在远程即可正常连接 MySQL。]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>MySQL</tag>
        <tag>坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[more、less 和 most 的区别]]></title>
    <url>%2F2018%2F11%2F19%2FThe-Difference-Between-more-less-And-most-Commands%2F</url>
    <content type="text"><![CDATA[如果你是一个 Linux 方面的新手，你可能会在 more、less、most 这三个命令行工具之间产生疑惑。在本文当中，我会对这三个命令行工具进行对比，以及展示它们各自在 Linux 中的一些使用例子。总的来说，这几个命令行工具之间都有相通和差异，而且它们在大部分 Linux 发行版上都有自带。 我们首先来看看 more 命令。 more 命令more 是一个老式的、基础的终端分页阅读器，它可以用于打开指定的文件并进行交互式阅读。如果文件的内容太长，在一屏以内无法完整显示，就会逐页显示文件内容。使用回车键或者空格键可以滚动浏览文件的内容，但有一个限制，就是只能够单向滚动。也就是说只能按顺序往下翻页，而不能进行回看。 更正 有的 Linux 用户向我指出，在 more 当中是可以向上翻页的。不过，最原始版本的 more 确实只允许向下翻页，在后续出现的较新的版本中也允许了有限次数的向上翻页，只需要在浏览过程中按 b 键即可向上翻页。唯一的限制是 more 不能搭配管道使用（如 ls | more）。（LCTT 译注：此处原作者疑似有误，译者使用 more 是可以搭配管道使用的，或许与不同 more 版本有关） 按 q 即可退出 more。 更多示例 打开 ostechnix.txt 文件进行交互式阅读，可以执行以下命令： 1$ more ostechnix.txt 在阅读过程中，如果需要查找某个字符串，只需要像下面这样输入斜杠（/）之后接着输入需要查找的内容： 1/linux 按 n 键可以跳转到下一个匹配的字符串。 如果需要在文件的第 10 行开始阅读，只需要执行： 1$ more +10 file 就可以从文件的第 10 行开始显示文件的内容了。 如果你需要让 more 提示你按空格键来翻页，可以加上 -d 参数： 1$ more -d ostechnix.txt 如上图所示，more 会提示你可以按空格键翻页。 如果需要查看所有选项以及对应的按键，可以按 h 键。 要查看 more 的更多详细信息，可以参考手册： 1$ man more less 命令less 命令也是用于打开指定的文件并进行交互式阅读，它也支持翻页和搜索。如果文件的内容太长，也会对输出进行分页，因此也可以翻页阅读。比 more 命令更好的一点是，less 支持向上翻页和向下翻页，也就是可以在整个文件中任意阅读。 在使用功能方面，less 比 more 命令具有更多优点，以下列出其中几个： 支持向上翻页和向下翻页 支持向上搜索和向下搜索 可以跳转到文件的末尾并立即从文件的开头开始阅读 在编辑器中打开指定的文件 更多示例 打开文件： 1$ less ostechnix.txt 按空格键或回车键可以向下翻页，按 b 键可以向上翻页。 如果需要向下搜索，在输入斜杠（/）之后接着输入需要搜索的内容： 1/linux 按 n 键可以跳转到下一个匹配的字符串，如果需要跳转到上一个匹配的字符串，可以按 N 键。 如果需要向上搜索，在输入问号（?）之后接着输入需要搜索的内容： 1?linux 同样是按 n 键或 N 键跳转到下一个或上一个匹配的字符串。 只需要按 v 键，就会将正在阅读的文件在默认编辑器中打开，然后就可以对文件进行各种编辑操作了。 按 h 键可以查看 less 工具的选项和对应的按键。 按 q 键可以退出阅读。 要查看 less 的更多详细信息，可以参考手册： 1$ man less most 命令most 同样是一个终端阅读工具，而且比 more 和 less 的功能更为丰富。most 支持同时打开多个文件。你可以在打开的文件之间切换、编辑当前打开的文件、迅速跳转到文件中的某一行、分屏阅读、同时锁定或滚动多个屏幕等等功能。在默认情况下，对于较长的行，most 不会将其截断成多行显示，而是提供了左右滚动功能以在同一行内显示。 更多示例 打开文件： 1$ most ostechnix1.txt 按 e 键可以编辑当前文件。 如果需要向下搜索，在斜杠（/）或 S 或 f 之后输入需要搜索的内容，按 n 键就可以跳转到下一个匹配的字符串。 如果需要向上搜索，在问号（?）之后输入需要搜索的内容，也是通过按 n 键跳转到下一个匹配的字符串。 同时打开多个文件： 1$ most ostechnix1.txt ostechnix2.txt ostechnix3.txt 在打开了多个文件的状态下，可以输入 :n 切换到下一个文件，使用 ↑ 或 ↓ 键选择需要切换到的文件，按回车键就可以查看对应的文件。 要打开文件并跳转到某个字符串首次出现的位置（例如 linux），可以执行以下命令： 1$ most file +/linux 按 h 键可以查看帮助。 按键操作列表 移动： 空格键或 D 键 – 向下滚动一屏 DELETE 键或 U 键 – 向上滚动一屏 ↓ 键 – 向下移动一行 ↑ 键 – 向上移动一行 T 键 – 移动到文件开头 B 键 – 移动到文件末尾 &gt; 键或 TAB 键 – 向右滚动屏幕 &lt; 键 – 向左滚动屏幕 → 键 – 向右移动一列 ← 键 – 向左移动一列 J 键或 G 键 – 移动到某一行，例如 10j 可以移动到第 10 行 % 键 – 移动到文件长度某个百分比的位置 窗口命令： Ctrl-X 2、Ctrl-W 2 – 分屏 Ctrl-X 1、Ctrl-W 1 – 只显示一个窗口 O 键、Ctrl-X O – 切换到另一个窗口 Ctrl-X 0 – 删除窗口 文件内搜索： S 键或 f 键或 / 键 – 向下搜索 ? 键 – 向上搜索 n 键 – 跳转到下一个匹配的字符串 退出： q 键 – 退出 most ，且所有打开的文件都会被关闭 :N、:n – 退出当前文件并查看下一个文件（使用 ↑ 键、↓ 键选择下一个文件） 要查看 most 的更多详细信息，可以参考手册： 1$ man most 总结more – 传统且基础的分页阅读工具，仅支持向下翻页和有限次数的向上翻页。 less – 比 more 功能丰富，支持向下翻页和向上翻页，也支持文本搜索。在打开大文件的时候，比 vi 这类文本编辑器启动得更快。 most – 在上述两个工具功能的基础上，还加入了同时打开多个文件、同时锁定或滚动多个屏幕、分屏等等大量功能。 以上就是我的介绍，希望能让你通过我的文章对这三个工具有一定的认识。如果想了解这篇文章以外的关于这几个工具的详细功能，请参阅它们的 man 手册。 via: https://www.ostechnix.com/the-difference-between-more-less-and-most-commands/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gitbase：用 SQL 查询 Git 仓库]]></title>
    <url>%2F2018%2F11%2F19%2FGitbase-Exploring-git-repos-with-SQL%2F</url>
    <content type="text"><![CDATA[gitbase 是一个使用 go 开发的的开源项目，它实现了在 Git 仓库上执行 SQL 查询。 Git 已经成为了代码版本控制的事实标准，但尽管 Git 相当普及，对代码仓库的深入分析的工作难度却没有因此而下降；而 SQL 在大型代码库的查询方面则已经是一种久经考验的语言，因此诸如 Spark 和 BigQuery 这样的项目都采用了它。 所以，source{d} 很顺理成章地将这两种技术结合起来，就产生了 gitbase（LCTT 译注：source{d} 是一家开源公司，本文作者是该公司开发者关系副总裁）。gitbase 是一个代码即数据code-as-data的解决方案，可以使用 SQL 对 git 仓库进行大规模分析。 gitbase 是一个完全开源的项目。它站在了很多巨人的肩上，因此得到了足够的发展竞争力。下面就来介绍一下其中的一些“巨人”。 gitbase playground 为 gitbase 提供了一个可视化的操作环境。 用 Vitess 解析 SQLgitbase 通过 SQL 与用户进行交互，因此需要能够遵循 MySQL 协议来对通过网络传入的 SQL 请求作出解析和理解，万幸由 YouTube 建立的 Vitess 项目已经在这一方面给出了解决方案。Vitess 是一个横向扩展的 MySQL 数据库集群系统。 我们只是使用了这个项目中的部分重要代码，并将其转化为一个可以让任何人在数分钟以内编写出一个 MySQL 服务器的开源程序，就像我在 justforfunc 视频系列中展示的 CSVQL 一样，它可以使用 SQL 操作 CSV 文件。 用 go-git 读取 git 仓库在成功解析 SQL 请求之后，还需要对数据集中的 git 仓库进行查询才能返回结果。因此，我们还结合使用了 source{d} 最成功的 go-git 仓库。go-git 是使用纯 go 语言编写的具有高度可扩展性的 git 实现。 借此我们就可以很方便地将存储在磁盘上的代码仓库保存为 siva 文件格式（这同样是 source{d} 的一个开源项目），也可以通过 git clone 来对代码仓库进行复制。 使用 enry 检测语言、使用 babelfish 解析文件gitbase 集成了我们开源的语言检测项目 enry 以及代码解析项目 babelfish，因此在分析 git 仓库历史代码的能力也相当强大。babelfish 是一个自托管服务，普适于各种源代码解析，并将代码文件转换为通用抽象语法树Universal Abstract Syntax Tree（UAST）。 这两个功能在 gitbase 中可以被用户以函数 LANGUAGE 和 UAST 调用，诸如“查找上个月最常被修改的函数的名称”这样的请求就需要通过这两个功能实现。 提高性能gitbase 可以对非常大的数据集进行分析，例如来自 GitHub 高达 3 TB 源代码的 Public Git Archive（公告）。面临的工作量如此巨大，因此每一点性能都必须运用到极致。于是，我们也使用到了 Rubex 和 Pilosa 这两个项目。 使用 Rubex 和 Oniguruma 优化正则表达式速度Rubex 是 go 的正则表达式标准库包的一个准替代品。之所以说它是准替代品，是因为它没有在 regexp.Regexp 类中实现 LiteralPrefix 方法，直到现在都还没有。 Rubex 的高性能是由于使用 cgo 调用了 Oniguruma，它是一个高度优化的 C 代码库。 使用 Pilosa 索引优化查询速度索引几乎是每个关系型数据库都拥有的特性，但 Vitess 由于不需要用到索引，因此并没有进行实现。 于是我们引入了 Pilosa 这个开源项目。Pilosa 是一个使用 go 实现的分布式位图索引，可以显著提升跨多个大型数据集的查询的速度。通过 Pilosa，gitbase 才得以在巨大的数据集中进行查询。 总结我想用这一篇文章来对开源社区表达我衷心的感谢，让我们能够不负众望的在短时间内完成 gitbase 的开发。我们 source{d} 的每一位成员都是开源的拥护者，github.com/src-d 下的每一行代码都是见证。 你想使用 gitbase 吗？最简单快捷的方式是从 sourced.tech/engine 下载 source{d} 引擎，就可以通过单个命令运行 gitbase 了。 想要了解更多，可以听听我在 Go SF 大会上的演讲录音。 本文在 Medium 首发，并经许可在此发布。 via: https://opensource.com/article/18/11/gitbase]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>git</tag>
        <tag>SQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pydbgen：一个数据库随机生成器]]></title>
    <url>%2F2018%2F11%2F17%2FIntroducing-pydbgen-A-random-dataframe-database-table-generator%2F</url>
    <content type="text"><![CDATA[用这个简单的工具生成带有多表的大型数据库，让你更好地用 SQL 研究数据科学。 在研究数据科学的过程中，最麻烦的往往不是算法或者技术，而是如何获取到一批原始数据。尽管网上有很多真实优质的数据集可以用于机器学习，然而在学习 SQL 时却不是如此。 对于数据科学来说，熟悉 SQL 的重要性不亚于了解 Python 或 R 编程。如果想收集诸如姓名、年龄、信用卡信息、地址这些信息用于机器学习任务，在 Kaggle 上查找专门的数据集比使用足够大的真实数据库要容易得多。 如果有一个简单的工具或库来帮助你生成一个大型数据库，表里还存放着大量你需要的数据，岂不美哉？ 不仅仅是数据科学的入门者，即使是经验丰富的软件测试人员也会需要这样一个简单的工具，只需编写几行代码，就可以通过随机（但是是假随机）生成任意数量但有意义的数据集。 因此，我要推荐这个名为 pydbgen 的轻量级 Python 库。在后文中，我会简要说明这个库的相关内容，你也可以阅读它的文档详细了解更多信息。 pydbgen 是什么pydbgen 是一个轻量的纯 Python 库，它可以用于生成随机但有意义的数据记录（包括姓名、地址、信用卡号、日期、时间、公司名称、职位、车牌号等等），存放在 Pandas Dataframe 对象中，并保存到 SQLite 数据库或 Excel 文件。 如何安装 pydbgen目前 1.0.5 版本的 pydbgen 托管在 PyPI（Python 包索引存储库Python Package Index repository）上，并且对 Faker 有依赖关系。安装 pydbgen 只需要执行命令： 1pip install pydbgen 已经在 Python 3.6 环境下测试安装成功，但在 Python 2 环境下无法正常安装。 如何使用 pydbgen在使用 pydbgen 之前，首先要初始化 pydb 对象。 123import pydbgenfrom pydbgen import pydbgenmyDB=pydbgen.pydb() 随后就可以调用 pydb 对象公开的各种内部函数了。可以按照下面的例子，输出随机的美国城市和车牌号码： 1234567891011121314myDB.city_real()&gt;&gt; &apos;Otterville&apos;for _ in range(10): print(myDB.license_plate())&gt;&gt; 8NVX937 6YZH485 XBY-564 SCG-2185 XMR-158 6OZZ231 CJN-850 SBL-4272 TPY-658 SZL-0934 另外，如果你输入的是 city() 而不是 city_real()，返回的将会是虚构的城市名。 12345678910print(myDB.gen_data_series(num=8,data_type=&apos;city&apos;))&gt;&gt;New MichelleRobinboroughLeeburyKaylatownHamiltonfortLake ChristopherHannahstadWest Adamborough 生成随机的 Pandas Dataframe你可以指定生成数据的数量和种类，但需要注意的是，返回结果均为字符串或文本类型。 12testdf=myDB.gen_dataframe(5,[&apos;name&apos;,&apos;city&apos;,&apos;phone&apos;,&apos;date&apos;])testdf 最终产生的 Dataframe 类似下图所示。 生成数据库表你也可以指定生成数据的数量和种类，而返回结果是数据库中的文本或者变长字符串类型。在生成过程中，你可以指定对应的数据库文件名和表名。 123myDB.gen_table(db_file=&apos;Testdb.DB&apos;,table_name=&apos;People&apos;,fields=[&apos;name&apos;,&apos;city&apos;,&apos;street_address&apos;,&apos;email&apos;]) 上面的例子种生成了一个能被 MySQL 和 SQLite 支持的 .db 文件。下图则显示了这个文件中的数据表在 SQLite 可视化客户端中打开的画面。 生成 Excel 文件和上面的其它示例类似，下面的代码可以生成一个具有随机数据的 Excel 文件。值得一提的是，通过将 phone_simple 参数设为 False ，可以生成较长较复杂的电话号码。如果你想要提高自己在数据提取方面的能力，不妨尝试一下这个功能。 12myDB.gen_excel(num=20,fields=[&apos;name&apos;,&apos;phone&apos;,&apos;time&apos;,&apos;country&apos;],phone_simple=False,filename=&apos;TestExcel.xlsx&apos;) 最终的结果类似下图所示： 生成随机电子邮箱地址pydbgen 内置了一个 realistic_email 方法，它基于种子来生成随机的电子邮箱地址。如果你不想在网络上使用真实的电子邮箱地址时，这个功能可以派上用场。 12345678910111213for _ in range(10): print(myDB.realistic_email(&apos;Tirtha Sarkar&apos;))&gt;&gt;Tirtha_Sarkar@gmail.comSarkar.Tirtha@outlook.comTirtha_S48@verizon.comTirtha_Sarkar62@yahoo.comTirtha.S46@yandex.comTirtha.S@att.comSarkar.Tirtha60@gmail.comTirthaSarkar@zoho.comSarkar.Tirtha@protonmail.comTirtha.S@comcast.net 未来的改进和用户贡献目前的版本中并不完美。如果你发现了 pydbgen 的 bug 导致它在运行期间发生崩溃，请向我反馈。如果你打算对这个项目贡献代码，也随时欢迎你。当然现在也还有很多改进的方向： pydbgen 作为随机数据生成器，可以集成一些机器学习或统计建模的功能吗？ pydbgen 是否会添加可视化功能？ 一切皆有可能！ 如果你有任何问题或想法想要分享，都可以通过 tirthajyoti@gmail.com 与我联系。如果你像我一样对机器学习和数据科学感兴趣，也可以添加我的 LinkedIn 或在 Twitter 上关注我。另外，还可以在我的 GitHub 上找到更多 Python、R 或 MATLAB 的有趣代码和机器学习资源。 本文以 CC BY-SA 4.0 许可在 Towards Data Science 首发。 via: https://opensource.com/article/18/11/pydbgen-random-database-table-generator]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>数据库</tag>
        <tag>Python</tag>
        <tag>随机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[几个用于替代 du 命令的更好选择]]></title>
    <url>%2F2018%2F11%2F16%2FSome-Good-Alternatives-To-du-Command%2F</url>
    <content type="text"><![CDATA[大家对 du 命令应该都不陌生，它可以在类 Unix 系统中对文件和目录的空间使用情况进行计算和汇总。如果你也经常需要使用 du 命令，你会对以下内容感兴趣的。我发现了五个可以替代原有的 du 命令的更好的工具。当然，如果后续有更多更好的选择，我会继续列出来。如果你有其它推荐，也欢迎在评论中留言。 ncduncdu 作为普通 du 的替代品，这在 Linux 社区中已经很流行了。ncdu 正是基于开发者们对 du 的性能不满意而被开发出来的。ncdu 是一个使用 C 语言和 ncurses 接口开发的简易快速的磁盘用量分析器，可以用来查看目录或文件在本地或远程系统上占用磁盘空间的情况。如果你有兴趣查看关于 ncdu 的详细介绍，可以浏览《如何在 Linux 上使用 ncdu 查看磁盘占用量》这一篇文章。 tin-summertin-summer 是使用 Rust 语言编写的自由开源工具，它可以用于查找占用磁盘空间的文件，它也是 du 命令的另一个替代品。由于使用了多线程，因此 tin-summer 在计算大目录的大小时会比 du 命令快得多。tin-summer 与 du 命令之间的区别是前者读取文件的大小，而后者则读取磁盘使用情况。 tin-summer 的开发者认为它可以替代 du，因为它具有以下优势： 在大目录的操作速度上比 du 更快； 在显示结果上默认采用易读格式； 可以使用正则表达式排除文件或目录； 可以对输出进行排序和着色处理； 可扩展，等等。 安装 tin-summer 要安装 tin-summer，只需要在终端中执行以下命令： 1$ curl -LSfs https://japaric.github.io/trust/install.sh | sh -s -- --git vmchale/tin-summer 你也可以使用 cargo 软件包管理器安装 tin-summer，但你需要在系统上先安装 Rust。在 Rust 已经安装好的情况下，执行以下命令： 1$ cargo install tin-summer 如果上面提到的这两种方法都不能成功安装 tin-summer，还可以从它的软件发布页下载最新版本的二进制文件编译，进行手动安装。 用法 （LCTT 译注：tin-summer 的命令名为 sn） 如果需要查看当前工作目录的文件大小，可以执行以下命令： 123456$ sn f749 MB ./.rustup/toolchains749 MB ./.rustup147 MB ./.cargo/bin147 MB ./.cargo900 MB . 不需要进行额外声明，它也是默认以易读的格式向用户展示数据。在使用 du 命令的时候，则必须加上额外的 -h 参数才能得到同样的效果。 只需要按以下的形式执行命令，就可以查看某个特定目录的文件大小。 1$ sn f &lt;path-to-the-directory&gt; 还可以对输出结果进行排序，例如下面的命令可以输出指定目录中最大的 5 个文件或目录： 1234567$ sn sort /home/sk/ -n5749 MB /home/sk/.rustup749 MB /home/sk/.rustup/toolchains147 MB /home/sk/.cargo147 MB /home/sk/.cargo/bin2.6 MB /home/sk/mcelog900 MB /home/sk/ 顺便一提，上面结果中的最后一行是指定目录 /home/sk 的总大小。所以不要惊讶为什么输入的是 5 而实际输出了 6 行结果。 在当前目录下查找带有构建工程的目录，可以使用以下命令： 1$ sn ar tin-summer 同样支持查找指定大小的带有构建工程的目录。例如执行以下命令可以查找到大小在 100 MB 以上的带有构建工程的目录： 1$ sn ar -t100M 如上文所说，tin-summer 在操作大目录的时候速度比较快，因此在操作小目录的时候，速度会相对比较慢一些。不过它的开发者已经表示，将会在以后的版本中优化这个缺陷。 要获取相关的帮助，可以执行以下命令： 1$ sn --help 如果想要更详尽的介绍，可以查看这个项目的 GitHub 页面。 dustdust （含义是 du + rust = dust）使用 Rust 编写，是一个免费、开源的更直观的 du 工具。它可以在不需要 head 或sort 命令的情况下即时显示目录占用的磁盘空间。与 tin-summer 一样，它会默认情况以易读的格式显示每个目录的大小。 安装 dust 由于 dust 也是使用 Rust 编写，因此它也可以通过 cargo 软件包管理器进行安装： 1$ cargo install du-dust 也可以从它的软件发布页下载最新版本的二进制文件，并按照以下步骤安装。在写这篇文章的时候，最新的版本是 0.3.1。 1$ wget https://github.com/bootandy/dust/releases/download/v0.3.1/dust-v0.3.1-x86_64-unknown-linux-gnu.tar.gz 抽取文件： 1$ tar -xvf dust-v0.3.1-x86_64-unknown-linux-gnu.tar.gz 最后将可执行文件复制到你的 $PATH（例如 /usr/local/bin）下： 1$ sudo mv dust /usr/local/bin/ 用法 需要查看当前目录及所有子目录下的文件大小，可以执行以下命令： 1$ dust 输出示例： 带上 -p 参数可以按照从当前目录起始的完整目录显示。 1$ dust -p 如果需要查看多个目录的大小，只需要同时列出这些目录，并用空格分隔开即可： 1$ dust &lt;dir1&gt; &lt;dir2&gt; 下面再多举几个例子，例如： 显示文件的长度: 1$ dust -s 只显示 10 个目录： 1$ dust -n 10 查看当前目录下最多 3 层子目录： 1$ dust -d 3 查看帮助： 1$ dust -h 如果想要更详尽的介绍，可以查看这个项目的 GitHub 页面。 diskusdiskus 也是使用 Rust 编写的一个小型、快速的开源工具，它可以用于替代 du -sh 命令。diskus 将会计算当前目录下所有文件的总大小，它的效果相当于 du -sh 或 du -sh --bytes，但其开发者表示 diskus 的运行速度是 du -sh 的 9 倍。 安装 diskus diskus 已经存放于 Arch Linux 社区用户软件仓库Arch Linux User-community Repository（AUR）当中，可以通过任何一种 AUR 帮助工具（例如 yay）把它安装在基于 Arch 的系统上： 1$ yay -S diskus 对于 Ubuntu 及其衍生发行版，可以在 diskus 的软件发布页上下载最新版的软件包并安装： 123$ wget &quot;https://github.com/sharkdp/diskus/releases/download/v0.3.1/diskus_0.3.1_amd64.deb&quot;$ sudo dpkg -i diskus_0.3.1_amd64.deb 还可以使用 cargo 软件包管理器安装 diskus，但必须在系统上先安装 Rust 1.29+。 安装好 Rust 之后，就可以使用以下命令安装 diskus： 1$ cargo install diskus 用法 在通常情况下，如果需要查看某个目录的大小，我会使用形如 du -sh 的命令。 1$ du -sh dir 这里的 -s 参数表示显示总大小。 如果使用 diskus，直接就可以显示当前目录的总大小。 1$ diskus 我使用 diskus 查看 Arch Linux 系统上各个目录的总大小，这个工具的速度确实比 du -sh 快得多。但是它目前只能显示当前目录的大小。 要获取相关的帮助，可以执行以下命令： 1$ diskus -h 如果想要更详尽的介绍，可以查看这个项目的 GitHub 页面。 duuduu 是 Directory Usage Utility 的缩写。它是使用 Python 编写的查看指定目录大小的工具。它具有跨平台的特性，因此在 Windows、Mac OS 和 Linux 系统上都能够使用。 安装 duu 安装这个工具之前需要先安装 Python 3。不过目前很多 Linux 发行版的默认软件仓库中都带有 Python 3，所以这个依赖并不难解决。 Python 3 安装完成后，从 duu 的软件发布页下载其最新版本。 1$ wget https://github.com/jftuga/duu/releases/download/2.20/duu.py 用法 要查看当前目录的大小，只需要执行以下命令： 1$ python3 duu.py 输出示例： 从上图可以看出，duu 会显示当前目录下文件的数量情况，按照 Byte、KB、MB 单位显示这些文件的总大小，以及每个文件的大小。 如果需要查看某个目录的大小，只需要声明目录的绝对路径即可： 1$ python3 duu.py /home/sk/Downloads/ 如果想要更详尽的介绍，可以查看这个项目的 GitHub 页面。 以上就是 du 命令的五种替代方案，希望这篇文章能够帮助到你。就我自己而言，我并不会在这五种工具之间交替使用，我更喜欢使用 ncdu。欢迎在下面的评论区发表你对这些工具的评论。 via: https://www.ostechnix.com/some-good-alternatives-to-du-command/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>命令</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[5 个适合系统管理员使用的告警可视化工具]]></title>
    <url>%2F2018%2F11%2F11%2F5-alerting-and-visualization-tools-for-sysadmins%2F</url>
    <content type="text"><![CDATA[这些开源的工具能够通过输出帮助用户了解系统的运行状况，并对可能发生的潜在问题作出告警。 你大概已经知道（或猜到）告警可视化alerting and visualization工具是用来做什么的了。下面我们就要来说一下，为什么要讨论这样的工具，甚至某些系统专门将可视化作为特有的功能。 可观察性Observability的概念来自控制理论control theory，这个概念描述了我们通过对系统的输入和输出来了解其的能力。本文将重点介绍具有可观察性的输出组件。 告警可视化工具可以对其它系统的输出进行分析，进而对输出的信息进行结构化表示。告警实际上是对系统异常状态的描述，而可视化则是让用户能够直观理解的结构化表示。 常见的可视化告警告警首先要明确一下告警alert的含义。在人员无法响应告警内容情况下，不应该发送告警 —— 包括那些发给多个人但只有其中少数人可以响应的告警，以及系统中的每个异常都触发的告警。因为这样会产生告警疲劳，告警接收者也往往会对这些过多的告警采取忽视的态度 —— 直到系统恶化到以少见的方式告警。 例如，如果管理员每天都会收到告警系统发来的数百封告警邮件，他就很容易会忽略告警系统的所有邮件。除非他真的看到问题发生，或者受到了客户或上级的询问时，管理员才会重新重视告警信息。在这种情况下，告警已经失去了原有的意义和用途。 告警不是一个持续的信息流或者状态更新。告警的目的在于暴露系统无法自动恢复的问题，而且告警应该只发送给最有可能解决问题的人员。超出这个定义的内容都不应该作为告警，否则将会对实际工作造成不良的影响。 不同的告警体系都会有各自的告警类型，因此不能用优先级（P1-P5）或者诸如“信息”、“警告”、“严重”之类的字眼来一概而论，下面我会介绍一些新兴的复杂系统的事件响应中出现的通用分类方式。 刚才我提到了一个“信息”这个告警类型，但实际上告警不应该是一个信息，尽管有些人可能会不这样认为。但我觉得如果一个告警没有发送给任何一个人，它就不应该是警报，而只是一些在许多系统中被视为警报的数据点，代表了一些应该知晓但不需要响应的事件。它更应该作为告警可视化工具的一部分，而不是会导致触发告警的事件。《实用监控》是这个领域的必读书籍，其作者 Mike Julian 在书中就介绍了他自己关于告警的看法。 而非信息警报则代表告警需要被响应以及需要相关的操作。我将这些告警大致分为内部故障和外部故障两种类型，而对于大多数公司来说，通常会有两个以上的级别来确定响应告警的优先级。系统性能下降就是一种故障，因为其对用户的影响通常都是未知的。 内部故障比外部故障的优先级低，但也需要快速响应。内部故障通常包括公司员工使用的内部系统或仅对公司员工可见的应用故障。 外部故障则包括任何马上会产生业务影响的系统故障，但不包括影响系统更新的故障。外部故障一般包括客户所面临的应用故障、数据库故障和导致系统可用性或一致性失效的网络故障，这些都会影响用户的正常使用。对于不直接影响用户的依赖组件故障也属于外部故障，随着应用程序的不断运行，一旦依赖组件发生故障，系统的性能也会受到波及。这种情况对于使用某些外部服务或数据源的系统来说很常见，尽管这些外部服务或数据源对于可能不涉及到系统的主要功能，但是当系统在处理相关依赖组件的错误时可能会出现较明显的延迟。 可视化可视化的种类有很多，我就不一一赘述了。这是一个有趣的研究领域，在我这些年的数据分析经历当中，学习和应用可视化方面的知识可以说是相当有挑战性。我们需要将复杂的系统输出通过直观的方式来向他人展示，才能有效地把信息传播出去。Google Charts 和 Tableau 都提供了很多可视化方面的工具。下面将会介绍一些最常见的可视化创新解决方案。 折线图折线图可能是最常见的可视化方式了，它可以让用户很直观地按照时间维度了解系统的情况。系统中每个单一或聚合的指标都会以一条折线在图表中体现。但当同一个图表中同时存在多条折线时，就可能会对阅读有所影响（如下图所示），所以大多数情况下都可以选择仅查看其中的少数几条折线，而不是让所有折线同时显示。如果某个指标的数值产生了大于正常范围的波动，就会很容易发现。例如下图中异常的紫线、黄线、浅蓝线。 折线图的另一个用法是可以将多条折线堆叠起来以显示它们之间的关系。例如对于通过折线图反映服务器的请求数量，可以单独看到每台服务器上的请求，也可以聚合在一起看。这就可以在同一个图表中灵活查看整个系统以及每个实例的情况了。 热力图另一种常见的可视化方式是热力图。热力图与条形图比较类似，还可以在条形图的基础上显示某部分在整体中占比的变化情况。例如在查看网络请求延时的时候，就可以使用热力图快速查看到所有网络请求的总体趋势和分布情况，另外，它可以使用不同颜色来表示不同部分的数值。 在以下这个热力图中，通过竖直方向上每个时间段的色块数量分布，可以清楚地看到大部分数据集中在整个范围的中心位置。我们还可以发现，大多数时间段的色块分布都是比较宽松的，而 14:00 到 15:00 这一段则分布得很密集，这样的分布有可能意味着一种不健康的状态。 仪表图还有一种常见的可视化方式是仪表图，用户可以通过仪表图快速了解单个指标。仪表一般用于单个指标的显示，例如车速表代表汽车的行驶速度、油量表代表油箱中的汽油量等等。大多数的仪表图都有一个共通点，就是会划分出所示指标的对应状态。如下图所示，绿色表示正常的状态，橙色表示不良的状态，而红色则表示极差的状态。下图中间一行模拟了真实仪表的显示情况。 上面图表中，除了常规仪表样式的显示方式之外，还有较为直接的数据显示方式，配合相同的配色方案，一眼就可以看出各个指标所处的状态，这一点与和仪表的特点类似。所以，最下面一行可能是仪表图的最佳显示方式，用户不需要仔细阅读，就可以大致了解各个指标的不同状态。这种类型的可视化是我最常用的类型，在数秒钟之间，我就可以全面地总览系统各方面地运行情况。 火焰图由 Netflix 的 Brendan Gregg 在 2011 年开始使用的火焰图是一种较为少见地可视化方式。它不像仪表图那样可以从图表中快速得到关键信息，通常只会在需要解决某个应用的问题的时候才会用到这种图表。火焰图主要用于 CPU、内存和相关帧方面的表示，X 轴按字母顺序将帧一一列出，而 Y 轴则表示堆栈的深度。图中每个矩形都是一个标明了调用的函数的堆栈帧。矩形越宽，就表示它在堆栈中出现越频繁。在分析系统性能问题的时候，火焰图能够起到很大的作用，大家不妨尝试一下。 工具的选择在告警工具方面，有几个商用的工具相当不错。但由于这是一篇介绍开源技术的文章，我只会介绍那些已经被广泛使用的免费工具。希望你也能够为这些工具贡献你自己的代码，让它们更加完善。 告警工具Bosun如果你的电脑出现问题，得多亏 Stack Exchange 你才能在网上查到解决办法。Stack Exchange 以众包问答的模式运营着很多不同类型的网站。其中就有广受开发者欢迎的 Stack Overflow，以及运维方面有名的 Super User。除此以外，从育儿经验到科幻小说、从哲学讨论到单车论坛，Stack Exchange 都有涉猎。 Stack Exchange 开源了它的告警管理系统 Bosun，同时也发布了 Prometheus 及其 AlertManager 系统。这两个系统有共通点。Bosun 和 Prometheus 一样使用 Golang 开发，但 Bosun 比 Prometheus 更为强大，因为它可以使用指标聚合metrics aggregation以外的方式与系统交互。Bosun 还可以从日志和事件收集系统中提取数据，并且支持 Graphite、InfluxDB、OpenTSDB 和 Elasticsearch。 Bosun 的架构包括一个单一的服务器的二进制文件，一个诸如 OpenTSDB 的后端、Redis 以及 scollector 代理。 scollector 代理会自动检测主机上正在运行的服务，并反馈这些进程和其它的系统资源的情况。这些数据将发送到后端。随后 Bosun 的二进制服务文件会向后端发起查询，确定是否需要触发告警。也可以通过 Grafana 这些工具通过一个通用接口查询 Bosun 的底层后端。而 Redis 则用于存储 Bosun 的状态信息和元数据。 Bosun 有一个非常巧妙的功能，就是可以根据历史数据来测试告警。这是我几年前在使用 Prometheus 的时候就非常需要的功能，当时我有一个异常的数据需要产生告警，但没有一个可以用于测试的简便方法。为了确保告警能够正常触发，我不得不造出对应的数据来进行测试。而 Bosun 让这个步骤的耗时大大缩短。 Bosun 更是涵盖了所有常用过的功能，包括简单的图形化表示和告警的创建。它还带有强大的用于编写告警规则的表达式语言。但 Bosun 默认只带有电子邮件通知配置和 HTTP 通知配置，因此如果需要连接到 Slack 或其它工具，就需要对配置作出更大程度的定制化（其文档中有）。类似于 Prometheus，Bosun 还可以使用模板通知，你可以使用 HTML 和 CSS 来创建你所需要的电子邮件通知。 CabotCabot 由 Arachnys 公司开发。你或许对 Arachnys 公司并不了解，但它很有影响力：Arachnys 公司构建了一个基于云的先进解决方案，用于防范金融犯罪。在之前的公司时，我也曾经参与过类似“了解你的客户（KYC）”的工作。大多数公司都认为与恐怖组织产生联系会造成相当不好的影响，因为恐怖组织可能会利用自己的系统来筹集资金。而这些解决方案将有助于防范欺诈类犯罪，尽管这类犯罪情节相对较轻，但仍然也会对机构产生风险。 Arachnys 公司为什么要开发 Cabot 呢？其实只是因为 Arachnys 的开发人员对 Nagios 不太熟悉。Cabot 的出现对很多人来说都是一个好消息，它基于 Django 和 Bootstrap 开发，因此如果想对这个项目做出自己的贡献，门槛并不高。（另外值得一提的是，Cabot 这个名字来源于开发者的狗。） 与 Bosun 类似，Cabot 也不对数据进行收集，而是使用监控对象的 API 提供的数据。因此，Cabot 告警的模式是拉取而不是推送。它通过访问每个监控对象的 API，根据特定的指标检索所需的数据，然后将告警数据使用 Redis 缓存，进而持久化存储到 Postgres 数据库。 Cabot 的一个较为少见的特点是，它原生支持 Graphite，同时也支持 Jenkins。Jenkins 在这里被视为一个集中式的定时任务，它会以对待故障的方式去对待构建失败的状况。构建失败当然没有系统故障那么紧急，但一旦出现构建失败，还是需要团队采取措施去处理，毕竟并不是每个人在收到构建失败的电子邮件时都会亲自去检查 Jenkins。 Cabot 另一个有趣的功能是它可以接入 Google 日历安排值班人员，这个称为 Rota 的功能用处很大，希望其它告警系统也能加入类似的功能。Cabot 目前仅支持安排主备联系人，但还有继续改进的空间。它自己的文档也提到，如果需要全面的功能，更应该考虑付费的解决方案。 StatsAggPearson 作为一家开发了 StatsAgg 告警平台的出版公司，这是极为罕见的，当然也很值得敬佩。除此以外，Pearson 还运营着另外几个网站以及和 O’Reilly Media 合资的企业。但我仍然会将它视为出版教学书籍的公司。 StatsAgg 除了是一个告警平台，还是一个指标聚合平台，甚至也有点类似其它系统的代理。StatsAgg 支持通过 Graphite、StatsD、InfluxDB 和 OpenTSDB 输入数据，也支持将其转发到各种平台。但随着中心服务的负载不断增加，风险也不断增大。尽管如此，如果 StatsAgg 的基础架构足够强壮，即使后端存储平台出现故障，也不会对它产生告警的过程造成影响。 StatsAgg 是用 Java 开发的，为了尽可能降低复杂性，它仅包括主服务和一个 UI。StatsAgg 支持基于正则表达式匹配来发送告警，而且它更注重于服务方面的告警，而不是服务器基础告警。我认为它填补了开源监控工具方面的空白，而这正式它自己的目标。 可视化工具GrafanaGrafana 的知名度很高，它也被广泛采用。每当我需要用到数据面板的时候，我总是会想到它，因为它比我使用过的任何一款类似的产品都要好。Grafana 由 Torkel Ödegaard 开发的，像 Cabot 一样，也是在圣诞节期间开发的，并在 2014 年 1 月发布。在短短几年之间，它已经有了长足的发展。Grafana 基于 Kibana 开发，Torkel 开启了新的分支并将其命名为 Grafana。 Grafana 着重体现了实用性以及数据呈现的美观性。它天生就可以从 Graphite、Elasticsearch、OpenTSDB、Prometheus 和 InfluxDB 收集数据。此外有一个 Grafana 商用版插件可以从更多数据源获取数据，但是其他数据源插件也并非没有开源版本，Grafana 的插件生态系统已经提供了各种数据源。 Grafana 能做什么呢？Grafana 提供了一个中心化的了解系统的方式。它通过 web 来展示数据，任何人都有机会访问到相关信息，当然也可以使用身份验证来对访问进行限制。Grafana 使用各种可视化方式来提供对系统一目了然的了解。Grafana 还支持不同类型的可视化方式，包括集成告警可视化的功能。 现在你可以更直观地设置告警了。通过 Grafana，可以查看图表，还可以查看由于系统性能下降而触发告警的位置，单击要触发报警的位置，并告诉 Grafana 将告警发送何处。这是一个对告警平台非常强大的补充。告警平台不一定会因此而被取代，但告警系统一定会由此得到更多启发和发展。 Grafana 还引入了很多团队协作的功能。不同用户之间能够共享数据面板，你不再需要为 Kubernetes 集群创建独立的数据面板，因为由 Kubernetes 开发者和 Grafana 开发者共同维护的一些数据面板已经可用了。 团队协作过程中一个重要的功能是注释。注释功能允许用户将上下文添加到图表当中，其他用户就可以通过上下文更直观地理解图表。当团队成员在处理某个事件，并且需要沟通和理解时，这个功能就十分重要了。将所有相关信息都放在需要的位置，可以让整个团队中快速达成共识。在团队需要调查故障原因和定位事件责任时，这个功能就可以发挥作用了。 VizceralVizceral 由 Netflix 开发，用于在故障发生时更有效地了解流量的情况。Grafana 是一种通用性更强的工具，而 Vizceral 则专用于某些领域。 尽管 Netflix 表示已经不再在内部使用 Vizceral，也不再主动对其展开维护，但 Vizceral 仍然会定期更新。我在这里介绍这个工具，主要是为了介绍它的的可视化机制，以及如何利用它来协助解决问题。你可以在样例环境中用它来更好地掌握这一类系统的特性。 via: https://opensource.com/article/18/10/alerting-and-visualization-tools-sysadmins]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>可视化</tag>
        <tag>告警</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Ultimate Plumber 即时预览管道命令结果]]></title>
    <url>%2F2018%2F11%2F08%2FUltimate-Plumber-Writing-Linux-Pipes-With-Instant-Live-Preview%2F</url>
    <content type="text"><![CDATA[管道命令的作用是将一个命令/程序/进程的输出发送给另一个命令/程序/进程，以便将输出结果进行进一步的处理。我们可以通过使用管道命令把多个命令组合起来，使一个命令的标准输入或输出重定向到另一个命令。两个或多个 Linux 命令之间的竖线字符（|）表示在命令之间使用管道命令。管道命令的一般语法如下所示： 1Command-1 | Command-2 | Command-3 | …| Command-N Ultimate Plumber（简称 UP）是一个命令行工具，它可以用于即时预览管道命令结果。如果你在使用 Linux 时经常会用到管道命令，就可以通过它更好地运用管道命令了。它可以预先显示执行管道命令后的结果，而且是即时滚动地显示，让你可以轻松构建复杂的管道。 下文将会介绍如何安装 UP 并用它将复杂管道命令的编写变得简单。 重要警告： 在生产环境中请谨慎使用 UP！在使用它的过程中，有可能会在无意中删除重要数据，尤其是搭配 rm 或 dd 命令时需要更加小心。勿谓言之不预。 使用 Ultimate Plumber 即时预览管道命令下面给出一个简单的例子介绍 up 的使用方法。如果需要将 lshw 命令的输出传递给 up，只需要在终端中输入以下命令，然后回车： 1$ lshw |&amp; up 你会在屏幕顶部看到一个输入框，如下图所示。 在输入命令的过程中，输入管道符号并回车，就可以立即执行已经输入了的命令。Ultimate Plumber 会在下方的可滚动窗口中即时显示管道命令的输出。在这种状态下，你可以通过 PgUp/PgDn 键或 ctrl + ←/ctrl + → 组合键来查看结果。 当你满意执行结果之后，可以使用 ctrl + x 组合键退出 UP。而退出前编写的管道命令则会保存在当前工作目录的文件中，并命名为 up1.sh。如果这个文件名已经被占用，就会命名为 up2.sh、up3.sh 等等以此类推，直到第 1000 个文件。如果你不需要将管道命令保存输出，只需要使用 ctrl + c 组合键退出即可。 通过 cat 命令可以查看 upX.sh 文件的内容。例如以下是我的 up2.sh 文件的输出内容： 123$ cat up2.sh#!/bin/bashgrep network -A5 | grep : | cut -d: -f2- | paste - - 如果通过管道发送到 up 的命令运行时间太长，终端窗口的左上角会显示一个波浪号（~）字符，这就表示 up 在等待前一个命令的输出结果作为输入。在这种情况下，你可能需要使用 ctrl + s 组合键暂时冻结 up 的输入缓冲区大小。在需要解冻的时候，使用 ctrl + q 组合键即可。Ultimate Plumber 的输入缓冲区大小一般为 40 MB，到达这个限制之后，屏幕的左上角会显示一个加号。 以下是 up 命令的一个简单演示： 安装 Ultimate Plumber喜欢这个工具的话，你可以在你的 Linux 系统上安装使用。安装过程也相当简单，只需要在终端里执行以下两个命令就可以安装 up 了。 首先从 Ultimate Plumber 的发布页面下载最新的二进制文件，并将放在你系统的某个路径下，例如 /usr/local/bin/。 1$ sudo wget -O /usr/local/bin/up wget https://github.com/akavel/up/releases/download/v0.2.1/up 然后向 up 二进制文件赋予可执行权限： 1$ sudo chmod a+x /usr/local/bin/up 至此，你已经完成了 up 的安装，可以开始编写你的管道命令了。 via: https://www.ostechnix.com/ultimate-plumber-writing-linux-pipes-with-instant-live-preview/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>管道</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 机器学习的必备技巧]]></title>
    <url>%2F2018%2F11%2F08%2FMachine-learning-with-Python-Essential-hacks-and-tricks%2F</url>
    <content type="text"><![CDATA[尝试使用 Python 掌握机器学习、人工智能和深度学习。 想要入门机器学习并不难。除了大规模网络公开课Massive Open Online Courses（MOOC）之外，还有很多其它优秀的免费资源。下面我分享一些我觉得比较有用的方法。 从一些 YouTube 上的好视频开始，阅览一些关于这方面的文章或者书籍，例如 《主算法：终极学习机器的探索将如何重塑我们的世界》，而且我觉得你肯定会喜欢这些关于机器学习的很酷的互动页面。 对于“机器学习machine learning”、“人工智能artificial intelligence”、“深度学习deep learning”、“数据科学data science”、“计算机视觉computer vision”和“机器人技术robotics”这一堆新名词，你需要知道它们之间的区别。你可以阅览或聆听这些领域的专家们的演讲，例如这位有影响力的数据科学家 Brandon Rohrer 的精彩视频。或者这个讲述了数据科学相关的各种角色之间的区别的视频。 明确你自己的学习目标，并选择合适的 Coursera 课程，或者参加高校的网络公开课，例如华盛顿大学的课程就很不错。 关注优秀的博客：例如 KDnuggets 的博客、Mark Meloon 的博客、Brandon Rohrer 的博客、Open AI 的研究博客，这些都值得推荐。 如果你热衷于在线课程，后文中会有如何正确选择 MOOC 课程的指导。 最重要的是，培养自己对这些技术的兴趣。加入一些优秀的社交论坛，不要被那些耸人听闻的头条和新闻所吸引，专注于阅读和了解，将这些技术的背景知识和发展方向理解透彻，并积极思考在日常生活和工作中如何应用机器学习或数据科学的原理。例如建立一个简单的回归模型来预测下一次午餐的成本，又或者是从电力公司的网站上下载历史电费数据，在 Excel 中进行简单的时序分析以发现某种规律。在你对这些技术产生了浓厚兴趣之后，可以观看以下这个视频。 https://www.youtube.com/embed/IpGxLWOIZy4 Python 是机器学习和人工智能方面的最佳语言吗？除非你是一名专业的研究一些复杂算法纯理论证明的研究人员，否则，对于一个机器学习的入门者来说，需要熟悉至少一种高级编程语言。因为大多数情况下都是需要考虑如何将现有的机器学习算法应用于解决实际问题，而这需要有一定的编程能力作为基础。 哪一种语言是数据科学的最佳语言？这个讨论一直没有停息过。对于这方面，你可以提起精神来看一下 FreeCodeCamp 上这一篇关于数据科学语言的文章，又或者是 KDnuggets 关于 Python 和 R 之争的深入探讨。 目前人们普遍认为 Python 在开发、部署、维护各方面的效率都是比较高的。与 Java、C 和 C++ 这些较为传统的语言相比，Python 的语法更为简单和高级。而且 Python 拥有活跃的社区群体、广泛的开源文化、数百个专用于机器学习的优质代码库，以及来自业界巨头（包括 Google、Dropbox、Airbnb 等）的强大技术支持。 基础 Python 库如果你打算使用 Python 实施机器学习，你必须掌握一些 Python 包和库的使用方法。 NumPyNumPy 的完整名称是 Numerical Python，它是 Python 生态里高性能科学计算和数据分析都需要用到的基础包，几乎所有高级工具（例如 Pandas 和 scikit-learn）都依赖于它。TensorFlow 使用了 NumPy 数组作为基础构建块以支持 Tensor 对象和深度学习的图形流。很多 NumPy 操作的速度都非常快，因为它们都是通过 C 实现的。高性能对于数据科学和现代机器学习来说是一个非常宝贵的优势。 PandasPandas 是 Python 生态中用于进行通用数据分析的最受欢迎的库。Pandas 基于 NumPy 数组构建，在保证了可观的执行速度的同时，还提供了许多数据工程方面的功能，包括： 对多种不同数据格式的读写操作 选择数据子集 跨行列计算 查找并补充缺失的数据 将操作应用于数据中的独立分组 按照多种格式转换数据 组合多个数据集 高级时间序列功能 通过 Matplotlib 和 Seaborn 进行可视化 Matplotlib 和 Seaborn数据可视化和数据分析是数据科学家的必备技能，毕竟仅凭一堆枯燥的数据是无法有效地将背后蕴含的信息向受众传达的。这两项技能对于机器学习来说同样重要，因为首先要对数据集进行一个探索性分析，才能更准确地选择合适的机器学习算法。 Matplotlib 是应用最广泛的 2D Python 可视化库。它包含海量的命令和接口，可以让你根据数据生成高质量的图表。要学习使用 Matplotlib，可以参考这篇详尽的文章。 Seaborn 也是一个强大的用于统计和绘图的可视化库。它在 Matplotlib 的基础上提供样式灵活的 API、用于统计和绘图的常见高级函数，还可以和 Pandas 提供的功能相结合。要学习使用 Seaborn，可以参考这篇优秀的教程。 Scikit-learnScikit-learn 是机器学习方面通用的重要 Python 包。它实现了多种分类、回归和聚类算法，包括支持向量机、随机森林、梯度增强、k-means 算法和 DBSCAN 算法，可以与 Python 的数值库 NumPy 和科学计算库 SciPy 结合使用。它通过兼容的接口提供了有监督和无监督的学习算法。Scikit-learn 的强壮性让它可以稳定运行在生产环境中，同时它在易用性、代码质量、团队协作、文档和性能等各个方面都有良好的表现。可以参考这篇基于 Scikit-learn 的机器学习入门，或者这篇基于 Scikit-learn 的简单机器学习用例演示。 本文使用 CC BY-SA 4.0 许可，在 Heartbeat 上首发。 via: https://opensource.com/article/18/10/machine-learning-python-essential-hacks-and-tricks]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推动 DevOps 变革的三个方面]]></title>
    <url>%2F2018%2F11%2F05%2F3-areas-to-drive-DevOps-change%2F</url>
    <content type="text"><![CDATA[推动大规模的组织变革是一个痛苦的过程。对于 DevOps 来说，尽管也有阵痛，但变革带来的价值则相当可观。 避免痛苦是一种强大的动力。一些研究表明，植物也会通过遭受疼痛的过程以采取措施来保护自己。我们人类有时也会刻意让自己受苦——在剧烈运动之后，身体可能会发生酸痛，但我们仍然坚持运动。那是因为当人认为整个过程利大于弊时，几乎可以忍受任何事情。 推动大规模的组织变革的过程确实是痛苦的。有人可能会因难以改变价值观和行为而感到痛苦，有人可能会因难以带领团队而感到痛苦，也有人可能会因难以开展工作而感到痛苦。但就 DevOps 而言，我可以说这些痛苦都是值得的。 我也曾经关注过一个团队耗费大量时间优化技术流程的过程，在这个过程中，团队逐渐将流程进行自动化改造，并最终获得了成功。 图片来源：Lee Eason. CC BY-SA 4.0 这张图表充分表明了变革的价值。一家公司在我主导实行了 DevOps 转型之后，60 多个团队每月提交了超过 900 个发布请求。这些工作量的原耗时高达每个月 350 人/天，而这么多的工作量对于任何公司来说都是不可忽视的。除此以外，他们每月的部署次数从 100 次增加到了 9000 次，高危 bug 减少了 24%，工程师们更轻松了，净推荐值Net Promoter Score（NPS）也提高了，而 NPS 提高反过来也让团队的 DevOps 转型更加顺利。正如 Puppet 发布的 DevOps 报告所预测的，用在技术流程改进上的投入可以在业务成果上明显地体现出来。 而 DevOps 主导者在推动变革时必须关注这三个方面：团队管理，团队文化和团队活力。 团队管理最重要的是，改进对技术流程的投入可以转化为更好的业务成果。 组织架构越大，业务领导与一线员工之间的距离就会越大，当然发生误解的可能性也会越大。而且各种技术工具和实际应用都在以日新月异的速度变化，这就导致业务领导几乎不可能对 DevOps 或敏捷开发的转型方向有一个亲身的了解。 DevOps 主导者必须和管理层密切合作，在进行决策的时候给出相关的意见，以帮助他们做出正确的决策。 公司的管理层只是知道 DevOps 会对产品部署的方式进行改进，而并不了解其中的具体过程。假设你正在帮助一个软件开发团队实现自动化部署，当管理层得知某次部署失败时（这种情况是有的），就会想要了解这件事情的细节。如果管理层了解到进行部署的是软件团队而不是专门的发布管理团队，就可能会坚持使用传统的变更流程来保证业务的正常运作。你可能会失去团队的信任，团队也可能不愿意做出进一步的改变。 如果没有和管理层做好心理上的预期，一旦发生意外的生产事件，重建管理层的信任并得到他们的支持比事先对他们进行教育需要更长的时间。所以，最好事先和管理层在各方面协调好，这会让你在后续的工作中避免很多麻烦。 对于和管理层之间的协调，这里有两条建议： 一是重视所有规章制度。如果管理层对合同、安全等各方面有任何疑问，你都可以向法务或安全负责人咨询，这样做可以避免犯下后果严重的错误。 二是将管理层重点关注的方面输出为量化指标。举个例子，如果公司的目标是减少客户流失，而你调查得出计划外的服务宕机是造成客户流失的主要原因，那么就可以让团队对故障的平均排查时间Mean Time To Detection（MTTD）和平均解决时间Mean Time To Resolution（MTTR）实行重点优化。你可以使用这些关键指标来量化团队的工作成果，而管理层对此也可以有一个直观的了解。 团队文化DevOps 是一种专注于持续改进代码、构建、部署和操作流程的文化，而团队文化代表了团队的价值观和行为。从本质上说，团队文化是要塑造团队成员的行为方式，而这并不是一件容易的事。 我推荐一本叫做《披着狼皮的 CIO》的书。另外，研究心理学、阅读《Drive》、观看 Daniel Pink 的 TED 演讲、阅读《千面英雄》、了解每个人的心路历程，以上这些都是你推动公司技术变革所应该尝试去做的事情。如果这些你都没兴趣，说明你不是那个推动公司变革的人。如果你想成为那个人，那就开始学习吧！ 从本质上说，改变一个人真不是件容易的事。 理性的人大多都按照自己的价值观工作，然而团队通常没有让每个人都能达成共识的明确价值观。因此，你需要明确团队目前的价值观，包括价值观的形成过程和价值观的目标导向。但不能将这些价值观强加到团队成员身上，只需要让团队成员在现有条件下力所能及地做到最好就可以了。 同时需要向团队成员阐明，公司正在发生组织和团队目标的变化，团队的价值观也随之改变，最好也厘清整个过程中将会作出什么变化。例如，公司以往或许是由于资金有限，一直将节约成本的原则放在首位，在研发新产品的时候，基础架构团队不得不共享数据库集群或服务器，从而导致了服务之间的紧密耦合。然而随着时间的推移，这种做法会产生难以维护的混乱，即使是一个小小的变化也可能造成无法预料的后果。这就导致交付团队难以执行变更控制流程，进而令变更停滞不前。 如果这种状况持续几年，最终的结果将会是毫无创新、技术老旧、问题繁多以及产品品质低下，公司的发展到达了瓶颈，原本的价值观已经不再适用。所以，工作效率的优先级必须高于节约成本。如果一个选择能让团队运作更好，另一个选择只是短期来看成本便宜，那你应该选择前者。 你必须反复强调团队的价值观。每当团队取得了一定的工作进展（即使探索创新时出现一些小的失误），都应该对团队作出激励。在团队部署出现失败时，鼓励他们承担风险、吸取教训，同时指导团队如何改进他们的工作并表示支持。长此下来，团队成员就会对你产生信任，不再顾虑为切合团队的价值观而做出改变。 团队活力你有没有在会议上听过类似这样的话？“在张三度假回来之前，我们无法对这件事情做出评估。他是唯一一个了解代码的人”，或者是“我们完成不了这项任务，它在网络上需要跨团队合作，而防火墙管理员刚好请病假了”，又或者是“张三最清楚这个系统，他说是怎么样，通常就是怎么样”。那么如果团队在处理工作时，谁才是主力？就是张三。而且也一直会是他。 我们一直都认为这就是软件开发的自带属性。但是如果我们不作出改变，这种循环就会一直持续下去。 熵的存在会让团队自发地变得混乱和缺乏活力，团队的成员和主导者的都有责任控制这个熵并保持团队的活力。DevOps、敏捷开发、上云、代码重构这些行为都会令熵加速增长，这是因为转型让团队需要学习更多新技能和专业知识以开展新工作。 我们来看一个产品团队重构历史代码的例子。像往常一样，他们在 AWS 上构建新的服务。而传统的系统则在数据中心部署，并由 IT 部门进行监控和备份。IT 部门会确保在基础架构的层面上满足应用的安全需求、进行灾难恢复测试、系统补丁、安装配置了入侵检测和防病毒代理，而且 IT 部门还保留了年度审计流程所需的变更控制记录。 产品团队经常会犯一个致命的错误，就是认为 IT 是消耗资源的部门，是需要突破的瓶颈。他们希望脱离已有的 IT 部门并使用公有云，但实际上是他们忽视了 IT 部门提供的关键服务。迁移到云上只是以不同的方式实现这些关键服务，因为 AWS 也是一个数据中心，团队即使使用 AWS 也需要完成 IT 运维任务。 实际上，产品团队在向云迁移的时候也必须学习如何使用这些 IT 服务。因此，当产品团队开始重构历史代码并部署到云上时，也需要学习大量的技能才能正常运作。这些技能不会无师自通，必须自行学习或者聘用相关的人员，团队的主导者也必须积极进行管理。 在带领团队时，我找不到任何适合我的工具，因此我建立了 Tekita.io 这个项目。Tekata 免费而且容易使用。但相比起来，把注意力集中在人员和流程上更为重要，你需要不断学习，持续关注团队的短板，因为它们会影响团队的交付能力，而弥补这些短板往往需要学习大量的新知识，这就需要团队成员之间有一个很好的协作。因此 76％ 的年轻人都认为个人发展机会是公司文化最重要的的一环。 效果就是最好的证明DevOps 转型会改变团队的工作方式和文化，这需要得到管理层的支持和理解。同时，工作方式的改变意味着新技术的引入，所以在管理上也必须谨慎。但转型的最终结果是团队变得更高效、成员变得更积极、产品变得更优质，客户也变得更满意。 Lee Eason 将于 10 月 21-23 日在北卡罗来纳州 Raleigh 举行的 All Things Open 上讲述 DevOps 转型的故事。 免责声明：本文中的内容仅为 Lee Eason 的个人立场，不代表 Ipreo 或 IHS Markit。 via: https://opensource.com/article/18/10/tales-devops-transformation]]></content>
      <tags>
        <tag>DevOps</tag>
        <tag>LCTT 翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用极简浏览器 Min 浏览网页]]></title>
    <url>%2F2018%2F11%2F04%2FBrowsing-the-web-with-Min-a-minimalist-open-source-web-browser%2F</url>
    <content type="text"><![CDATA[并非所有 web 浏览器都要做到无所不能，Min 就是一个极简主义风格的浏览器。 现在还有开发新的 Web 浏览器的需要吗？即使现在浏览器领域已经成为了寡头市场，但仍然不断涌现出各种前所未有的浏览器产品。 Min 就是其中一个。顾名思义，Min 是一个小的浏览器，也是一个极简主义的浏览器。但它麻雀虽小五脏俱全，而且还是一个开源的浏览器，它的 Apache 2.0 许可证引起了我的注意。 让我们来看看 Min 有什么值得关注的方面。 开始Min 基于 Electron 框架开发，值得一提的是，Atom 文本编辑器也是基于这个框架开发的。它提供 Linux、MacOS 和 Windows 的安装程序，当然也可以从 GitHub 获取它的源代码自行编译安装。 我使用的 Linux 发行版是 Manjaro，但没有完全匹配这个发行版的安装程序。还好，我通过 Manjaro 的包管理器也能安装 Min。 安装完成后，在终端就可以直接启动 Min。 Min 号称是更智能、更快速的浏览器。经过尝试以后，我觉得它比我在其它电脑上使用过的 Firefox 和 Chrome 浏览器启动得更快。 而使用 Min 浏览网页的过程则和 Firefox 或 Chrome 一样，只要再地址栏输入 URL，回车，就好了。 Min 的功能尽管 Min 不可能带有 Firefox 或 Chrome 等浏览器得所有功能，但它也有可取之处。 Min 和其它浏览器一样，支持页面选项卡。它还有一个称为 Tasks 的功能，可以对打开的选项卡进行分组。 DuckDuckGo 是我最喜欢的搜索引擎，而 Min 的默认搜索引擎恰好就是它，这正合我意。当然，如果你喜欢另一个搜索引擎，也可以在 Min 的偏好设置中配置你喜欢的搜索引擎作为默认搜索引擎。 Min 没有使用类似 AdBlock 这样的插件来过滤你不想看到的内容，而是使用了一个名为 EasyList 的内置的广告拦截器，你可以使用它来屏蔽脚本和图片。另外 Min 还带有一个内置的防跟踪软件。 类似 Firefox，Min 有一个名为叫做 Reading List 的阅读模式。只需点击地址栏中的对应图标，就可以去除页面中的大部分无关内容，让你专注于正在阅读的内容。网页在阅读列表中可以保留 30 天。 Min 还有一个专注模式，可以隐藏其它选项卡并阻止你打开新的选项卡。在专注模式下，如果一个 web 页面中进行工作，需要多点击好几次才能打开一个新页面。 Min 也有很多快捷键让你快速使用某个功能。你可以在 GitHub 上找到这些这些快捷键的参考文档，也可以在 Min 的偏好设置中进行更改。 我发现 Min 可以在 YouTube、Vimeo、Dailymotion 等视频网站上播放视频，还可以在音乐网站 7Digital 上播放音乐。但由于我没有账号，所以没法测试是否能在 Spotify 或 Last.fm 等这些网站上播放音乐。 Min 的弱点Min 确实也有自己的缺点，例如它无法将网站添加为书签。替代方案要么是查看 Min 的搜索历史来找回你需要的链接，要么是使用一个第三方的书签服务。 最大的缺点是 Min 不支持插件。这对我来说不是一件坏事，因为浏览器启动速度和运行速度快的主要原因就在于此。当然也有一些人非常喜欢使用浏览器插件，Min 就不是他们的选择。 总结Min 算是一个中规中矩的浏览器，它可以凭借轻量、快速的优点吸引很多极简主义的用户。但是对于追求多功能的用户来说，Min 就显得相当捉襟见肘了。 所以，如果你想摆脱当今多功能浏览器的束缚，我觉得可以试用一下 Min。 via: https://opensource.com/article/18/10/min-web-browser]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>浏览器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正确选择开源数据库的 5 个技巧]]></title>
    <url>%2F2018%2F11%2F01%2F5-tips-for-choosing-the-right-open-source-database%2F</url>
    <content type="text"><![CDATA[对关键应用的选择不容许丝毫错误。 你或许会遇到需要选择合适的开源数据库的情况。但这无论对于开源方面的老手或是新手，都是一项艰巨的任务。 在过去的几年中，采用开源技术的企业越来越多。面对这样的趋势，众多开源应用公司都纷纷承诺自己提供的解决方案能够各种问题、适应各种负载。但这些承诺不能轻信，在开源应用上的选择是重要而艰难的，尤其是数据库这种关键的应用。 凭借我在 Percona 和其它公司担任 IT 专家的经验，我很幸运能够指导其他人在开源技术的选择上做出正确的决策，因为需要考虑的重要因素太多了。希望通过这篇文章能够向大家分享这方面的一些技巧。 有一个明确的目标这一点看似简单，但在和很多人聊过 MySQL、MongoDB、PostgreSQL 之后，我觉得这一点才是最重要的。 面对繁杂的开源数据库，更需要明确自己的目标。无论这个数据库是作为开发用的标准化数据库后端，抑或是用于替换遗留代码中的原有数据库，这都是一个明确的目标。 目标一旦确定，就可以集中精力与开源软件的提供方商讨更多细节了。 了解你的工作负载尽管开源数据库技术的功能越来越丰富，但这些新加入的功能都不太具有普适性。譬如 MongoDB 新增了事务的支持、MySQL 新增了 JSON 存储的功能等等。目前开源数据库的普遍趋势是不断加入新的功能，但很多人的误区却在于没有选择最适合的工具来完成自己的工作 —— 这样的人或许是一个自大的开发者，又或许是一个视野狭窄的主管 —— 最终导致公司业务上的损失。最致命的是，在业务初期，使用了不适合的工具往往也可以顺利地完成任务，但随着业务的增长，很快就会到达瓶颈，尽管这个时候还可以替换更合适的工具，但成本就比较高了。 例如，如果你需要的是数据分析仓库，关系数据库可能不是一个适合的选择；如果你处理事务的应用要求严格的数据完整性和一致性，就不要考虑 NoSQL 了。 不要重新发明轮子在过去的数十年，开源数据库技术迅速发展壮大。开源数据库从新生，到受到质疑，再到受到认可，现在已经成为很多企业生产环境的数据库。企业不再需要担心选择开源数据库技术会产生风险，因为开源数据库通常都有活跃的社区，可以为越来越多的初创公司、中型企业甚至 500 强公司提供开源数据库领域的支持和第三方工具。 Battery Ventures 是一家专注于技术的投资公司，最近推出了一个用于跟踪最受欢迎开源项目的 BOSS 指数 。它提供了对一些被广泛采用的开源项目和活跃的开源项目的详细情况。其中，数据库技术毫无悬念地占据了榜单的主导地位，在前十位之中占了一半。这个 BOSS 指数对于刚接触开源数据库领域的人来说，这是一个很好的切入点。当然，开源技术的提供者也会针对很多常见的典型问题给出对应的解决方案。 我认为，你想要做的事情很可能已经有人解决过了。即使这些先行者的解决方案不一定完全契合你的需求，但也可以从他们成功或失败的案例中根据你自己的需求修改得出合适的解决方案。 如果你采用了一个最前沿的技术，这就是你探索的好机会了。如果你的工作负载刚好适合新的开源数据库技术，放胆去尝试吧。第一个吃螃蟹的人总是会得到意外的挑战和收获。 先从简单开始你的数据库实际上需要达到多少个 9 的可用性？对许多公司来说，“实现高可用性”仅仅只是一个模糊的目标。当然，最常见的答案都会是“它是关键应用，我们无论多短的停机时间都是无法忍受的”。 数据库环境越复杂，管理的难度就越大，成本也会越高。理论上你总可以将数据库的可用性提得更高，但代价将会是大大增加的管理难度和性能下降。所以，先从简单开始，直到有需要时再逐步扩展。 例如，Booking.com 是一个有名的旅游预订网站。但少有人知的是，它使用 MySQL 作为数据库后端。 Booking.com 高级系统架构师 Nicolai Plum 曾经发表过一次演讲，讲述了他们公司使用 MySQL 数据库的历程。其中一个重点就是，在初始阶段数据库可以被配置得很简单，然后逐渐变得复杂。对于早期的数据库需求，一个简单的主从架构就足够了，但随着工作负载和数据量的增加，数据库引入了负载均衡、多个读取副本，还使用 Hadoop 进行分析。尽管如此，早期的架构仍然是非常简单的。 有疑问，找专家如果你仍然不确定数据库选择的是否合适，可以在论坛、网站或者与软件的提供者处商讨。研究各种开源数据库是否满足自己的需求是一件很有意义的事，因为总会发现你从不知道的技术。而开源社区就是分享这些信息的地方。 当你接触到开源软件和软件提供者时，有一件重要的事情需要注意。很多公司都有开放的核心业务模式，鼓励采用他们的数据库软件。你可以只接受他们的部分建议和指导，然后用你自己的能力去研究和探索替代方案。 总结选择正确的开源数据库是一个重要的过程。很多时候，人们都会在真正理解需求之前就做出决定，这是本末倒置的。 via: https://opensource.com/article/18/10/tips-choosing-right-open-source-database]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么 Python 这么慢？]]></title>
    <url>%2F2018%2F10%2F27%2FWhy-is-Python-so-slow%2F</url>
    <content type="text"><![CDATA[Python 现在越来越火，已经迅速扩张到包括 DevOps、数据科学、Web 开发、信息安全等各个领域当中。 然而，相比起 Python 扩张的速度，Python 代码的运行速度就显得有点逊色了。 在代码运行速度方面，Java、C、C++、C# 和 Python 要如何进行比较呢？并没有一个放之四海而皆准的标准，因为具体结果很大程度上取决于运行的程序类型，而语言基准测试Computer Language Benchmarks Games可以作为衡量的一个方面。 根据我这些年来进行语言基准测试的经验来看，Python 比很多语言运行起来都要慢。无论是使用 JIT 编译器的 C＃、Java，还是使用 AOT 编译器的 C、C++，又或者是 JavaScript 这些解释型语言，Python 都比它们运行得慢。 注意：对于文中的 “Python” ，一般指 CPython 这个官方的实现。当然我也会在本文中提到其它语言的 Python 实现。 我要回答的是这个问题：对于一个类似的程序，Python 要比其它语言慢 2 到 10 倍不等，这其中的原因是什么？又有没有改善的方法呢？ 主流的说法有这些： “是全局解释器锁Global Interpreter Lock（GIL）的原因” “是因为 Python 是解释型语言而不是编译型语言” “是因为 Python 是一种动态类型的语言” 哪一个才是是影响 Python 运行效率的主要原因呢？ 是全局解释器锁的原因吗？现在很多计算机都配备了具有多个核的 CPU ，有时甚至还会有多个处理器。为了更充分利用它们的处理能力，操作系统定义了一个称为线程的低级结构。某一个进程（例如 Chrome 浏览器）可以建立多个线程，在系统内执行不同的操作。在这种情况下，CPU 密集型进程就可以跨核心分担负载了，这样的做法可以大大提高应用程序的运行效率。 例如在我写这篇文章时，我的 Chrome 浏览器打开了 44 个线程。需要提及的是，基于 POSIX 的操作系统（例如 Mac OS、Linux）和 Windows 操作系统的线程结构、API 都是不同的，因此操作系统还负责对各个线程的调度。 如果你还没有写过多线程执行的代码，你就需要了解一下线程锁的概念了。多线程进程比单线程进程更为复杂，是因为需要使用线程锁来确保同一个内存地址中的数据不会被多个线程同时访问或更改。 CPython 解释器在创建变量时，首先会分配内存，然后对该变量的引用进行计数，这称为引用计数reference counting。如果变量的引用数变为 0，这个变量就会从内存中释放掉。这就是在 for 循环代码块内创建临时变量不会增加内存消耗的原因。 而当多个线程内共享一个变量时，CPython 锁定引用计数的关键就在于使用了 GIL，它会谨慎地控制线程的执行情况，无论同时存在多少个线程，解释器每次只允许一个线程进行操作。 这会对 Python 程序的性能有什么影响？如果你的程序只有单线程、单进程，代码的速度和性能不会受到全局解释器锁的影响。 但如果你通过在单进程中使用多线程实现并发，并且是 IO 密集型（例如网络 IO 或磁盘 IO）的线程，GIL 竞争的效果就很明显了。 由 David Beazley 提供的 GIL 竞争情况图http://dabeaz.blogspot.com/2010/01/python-gil-visualized.html 对于一个 web 应用（例如 Django），同时还使用了 WSGI，那么对这个 web 应用的每一个请求都运行一个单独的 Python 解释器，而且每个请求只有一个锁。同时因为 Python 解释器的启动比较慢，某些 WSGI 实现还具有“守护进程模式”，可以使 Python 进程一直就绪。 其它的 Python 解释器表现如何？PyPy 也是一种带有 GIL 的解释器，但通常比 CPython 要快 3 倍以上。 Jython 则是一种没有 GIL 的解释器，这是因为 Jython 中的 Python 线程使用 Java 线程来实现，并且由 JVM 内存管理系统来进行管理。 JavaScript 在这方面又是怎样做的呢？所有的 Javascript 引擎使用的都是 mark-and-sweep 垃圾收集算法，而 GIL 使用的则是 CPython 的内存管理算法。 JavaScript 没有 GIL，而且它是单线程的，也不需要用到 GIL， JavaScript 的事件循环和 Promise/Callback 模式实现了以异步编程的方式代替并发。在 Python 当中也有一个类似的 asyncio 事件循环。 是因为 Python 是解释型语言吗？我经常会听到这个说法，但是这过于粗陋地简化了 Python 所实际做的工作了。其实当终端上执行 python myscript.py 之后，CPython 会对代码进行一系列的读取、语法分析、解析、编译、解释和执行的操作。 如果你对这一系列过程感兴趣，也可以阅读一下我之前的文章：在 6 分钟内修改 Python 语言 。 .pyc 文件的创建是这个过程的重点。在代码编译阶段，Python 3 会将字节码序列写入 __pycache__/ 下的文件中，而 Python 2 则会将字节码序列写入当前目录的 .pyc 文件中。对于你编写的脚本、导入的所有代码以及第三方模块都是如此。 因此，绝大多数情况下（除非你的代码是一次性的……），Python 都会解释字节码并本地执行。与 Java、C#.NET 相比： Java 代码会被编译为“中间语言”，由 Java 虚拟机读取字节码，并将其即时编译为机器码。.NET CIL 也是如此，.NET CLR（Common-Language-Runtime）将字节码即时编译为机器码。 既然 Python 像 Java 和 C# 那样都使用虚拟机或某种字节码，为什么 Python 在基准测试中仍然比 Java 和 C# 慢得多呢？首要原因是，.NET 和 Java 都是 JIT 编译的。 即时Just-in-time（JIT）编译需要一种中间语言，以便将代码拆分为多个块（或多个帧）。而提前ahead of time（AOT）编译器则需要确保 CPU 在任何交互发生之前理解每一行代码。 JIT 本身不会使执行速度加快，因为它执行的仍然是同样的字节码序列。但是 JIT 会允许在运行时进行优化。一个优秀的 JIT 优化器会分析出程序的哪些部分会被多次执行，这就是程序中的“热点”，然后优化器会将这些代码替换为更有效率的版本以实现优化。 这就意味着如果你的程序是多次重复相同的操作时，有可能会被优化器优化得更快。而且，Java 和 C# 是强类型语言，因此优化器对代码的判断可以更为准确。 PyPy 使用了明显快于 CPython 的 JIT。更详细的结果可以在这篇性能基准测试文章中看到：哪一个 Python 版本最快?。 那为什么 CPython 不使用 JIT 呢？JIT 也不是完美的，它的一个显著缺点就在于启动时间。 CPython 的启动时间已经相对比较慢，而 PyPy 比 CPython 启动还要慢 2 到 3 倍。Java 虚拟机启动速度也是出了名的慢。.NET CLR 则通过在系统启动时启动来优化体验，而 CLR 的开发者也是在 CLR 上开发该操作系统。 因此如果你有个长时间运行的单一 Python 进程，JIT 就比较有意义了，因为代码里有“热点”可以优化。 不过，CPython 是个通用的实现。设想如果使用 Python 开发命令行程序，但每次调用 CLI 时都必须等待 JIT 缓慢启动，这种体验就相当不好了。 CPython 试图用于各种使用情况。有可能实现将 JIT 插入到 CPython 中，但这个改进工作的进度基本处于停滞不前的状态。 如果你想充分发挥 JIT 的优势，请使用 PyPy。 是因为 Python 是一种动态类型的语言吗？在 C、C++、Java、C#、Go 这些静态类型语言中，必须在声明变量时指定变量的类型。而在动态类型语言中，虽然也有类型的概念，但变量的类型是可改变的。 12a = 1a = &quot;foo&quot; 在上面这个示例里，Python 将变量 a 一开始存储整数类型变量的内存空间释放了，并创建了一个新的存储字符串类型的内存空间，并且和原来的变量同名。 静态类型语言这样的设计并不是为了为难你，而是为了方便 CPU 运行而这样设计的。因为最终都需要将所有操作都对应为简单的二进制操作，因此必须将对象、类型这些高级的数据结构转换为低级数据结构。 Python 也实现了这样的转换，但用户看不到这些转换，也不需要关心这些转换。 不用必须声明类型并不是为了使 Python 运行慢，Python 的设计是让用户可以让各种东西变得动态：可以在运行时更改对象上的方法，也可以在运行时动态添加底层系统调用到值的声明上，几乎可以做到任何事。 但也正是这种设计使得 Python 的优化异常的难。 为了证明我的观点，我使用了一个 Mac OS 上的系统调用跟踪工具 DTrace。CPython 发布版本中没有内置 DTrace，因此必须重新对 CPython 进行编译。以下以 Python 3.6.6 为例： 12345wget https://github.com/python/cpython/archive/v3.6.6.zipunzip v3.6.6.zipcd v3.6.6./configure --with-dtracemake 这样 python.exe 将使用 DTrace 追踪所有代码。Paul Ross 也作过关于 DTrace 的闪电演讲。你可以下载 Python 的 DTrace 启动文件来查看函数调用、执行时间、CPU 时间、系统调用，以及各种其它的内容。 1sudo dtrace -s toolkit/&lt;tracer&gt;.d -c ‘../cpython/python.exe script.py’ py_callflow 追踪器显示了程序里调用的所有函数。 那么，Python 的动态类型会让它变慢吗？ 类型比较和类型转换消耗的资源是比较多的，每次读取、写入或引用变量时都会检查变量的类型 Python 的动态程度让它难以被优化，因此很多 Python 的替代品能够如此快都是为了提升速度而在灵活性方面作出了妥协 而 Cython 结合了 C 的静态类型和 Python 来优化已知类型的代码，它可以将性能提升 84 倍。 总结 由于 Python 是一种动态、多功能的语言，因此运行起来会相对缓慢。对于不同的实际需求，可以使用各种不同的优化或替代方案。 例如可以使用异步，引入分析工具或使用多种解释器来优化 Python 程序。 对于不要求启动时间且代码可以充分利用 JIT 的程序，可以考虑使用 PyPy。 而对于看重性能并且静态类型变量较多的程序，不妨使用 Cython。 延伸阅读Jake VDP 的优秀文章（略微过时） https://jakevdp.github.io/blog/2014/05/09/why-python-is-slow/ Dave Beazley 关于 GIL 的演讲 http://www.dabeaz.com/python/GIL.pdf JIT 编译器的那些事 https://hacks.mozilla.org/2017/02/a-crash-course-in-just-in-time-jit-compilers/ via: https://hackernoon.com/why-is-python-so-slow-e5074b6fe55b]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在双系统引导下替换 Linux 发行版]]></title>
    <url>%2F2018%2F10%2F20%2FHow-to-Replace-one-Linux-Distro-With-Another-in-Dual-Boot-Guide%2F</url>
    <content type="text"><![CDATA[在双系统引导的状态下，你可以将已安装的 Linux 发行版替换为另一个发行版，同时还可以保留原本的个人数据。 假设你的电脑上已经以双系统的形式安装了 Ubuntu 和 Windows，但经过将 Linux Mint 与 Ubuntu 比较之后，你又觉得 Linux Mint 会更适合自己的时候，你会怎样做？又该如何在删除 Ubuntu 的同时在双系统中安装 Mint 呢？ 你或许觉得应该首先从在双系统中卸载 Ubuntu，然后使用 Linux Mint 重新安装成双系统。但实际上并不需要这么麻烦。 如果你已经在双系统引导中安装了一种 Linux 发行版，就可以轻松替换成另一个发行版了，而且也不必卸载已有的 Linux 发行版，只需要删除其所在的分区，然后在腾出的磁盘空间上安装另一个 Linux 发行版就可以了。 与此同时，更换 Linux 发行版后，仍然会保留原本 home 目录中包含所有文件。 下面就来详细介绍一下。 在双系统引导中替换 Linux 发行版https://youtu.be/ptF2RUehbKs 这是我的演示范例。我使用双系统引导同时安装了 Windows 10 和 Linux Mint 19，然后我会把 Linux Mint 19 替换成 Elementary OS 5，同时在替换后保留我的个人文件（包括音乐、图片、视频和 home 目录中的文件）。 你需要做好以下这些准备： 使用 Linux 和 Windows 双系统引导 需要安装的 Linux 发行版的 USB live 版 在外部磁盘备份 Windows 和 Linux 中的重要文件（并非必要，但建议备份一下） 在替换 Linux 发行版时要记住保留你的 home 目录如果想让个人文件在安装新 Linux 系统的过程中不受影响，原有的 Linux 系统必须具有单独的 root 目录和 home 目录。你可能会发现我的双系统引导教程在安装过程中不选择“与 Windows 共存”选项，而选择“其它”选项，然后手动创建 root 和 home 分区。所以，手动创建单独的 home 分区也算是一个磨刀不误砍柴工的操作。因为如果要在不丢失文件的情况下，将现有的 Linux 发行版替换为另一个发行版，需要将 home 目录存放在一个单独的分区上。 不过，你必须记住现有 Linux 系统的用户名和密码才能使用与新系统中相同的 home 目录。 如果你没有单独的 home 分区，也可以后续再进行创建。但这并不是推荐做法，因为这个过程会比较复杂，有可能会把你的系统搞乱。 下面来看看如何替换到另一个 Linux 发行版。 步骤 1：为新的 Linux 发行版创建一个 USB live 版尽管上文中已经提到了它，但我还是要重复一次以免忽略。 你可以使用 Windows 或 Linux 中的启动盘创建器（例如 Etcher）来创建 USB live 版，这个过程比较简单，这里不再详细叙述。 步骤 2：启动 USB live 版并安装 Linux你应该已经使用过双系统启动，对这个过程不会陌生。使用 USB live 版重新启动系统，在启动时反复按 F10 或 F12 进入 BIOS 设置。选择从 USB 启动，就可以看到进入 live 环境或立即安装的选项。 在安装过程中，进入“安装类型”界面时，选择“其它”选项。 在这里选择“其它”选项 步骤 3：准备分区操作下图是分区界面。你会看到使用 Ext4 文件系统类型来安装 Linux。 确定 Linux 的安装位置 在上图中，标记为 Linux Mint 19 的 Ext4 分区是 root 分区，大小为 82691 MB 的第二个 Ext4 分区是 home 分区。在这里我这里没有使用交换空间。 如果你只有一个 Ext4 分区，就意味着你的 home 目录与 root 目录位于同一分区。在这种情况下，你就无法保留 home 目录中的文件了，这个时候我建议将重要文件复制到外部磁盘，否则这些文件将不会保留。 然后是删除 root 分区。选择 root 分区，然后点击 - 号，这个操作释放了一些磁盘空间。 删除 root 分区 磁盘空间释放出来后，点击 + 号。 创建新的 root 分区 现在已经在可用空间中创建一个新分区。如果你之前的 Linux 系统中只有一个 root 分区，就应该在这里创建 root 分区和 home 分区。如果需要，还可以创建交换分区。 如果你之前已经有 root 分区和 home 分区，那么只需要从已删除的 root 分区创建 root 分区就可以了。 创建 root 分区 你可能有疑问，为什么要经过“删除”和“添加”两个过程，而不使用“更改”选项。这是因为以前使用“更改”选项好像没有效果，所以我更喜欢用 - 和 +。这是迷信吗？也许是吧。 这里有一个重要的步骤，对新创建的 root 分区进行格式化。在没有更改分区大小的情况下，默认是不会对分区进行格式化的。如果分区没有被格式化，之后可能会出现问题。 格式化 root 分区很重要 如果你在新的 Linux 系统上已经划分了单独的 home 分区，选中它并点击更改。 修改已有的 home 分区 然后指定将其作为 home 分区挂载即可。 指定 home 分区的挂载点 如果你还有交换分区，可以重复与 home 分区相同的步骤，唯一不同的是要指定将空间用作交换空间。 现在的状态应该是有一个 root 分区（将被格式化）和一个 home 分区（如果需要，还可以使用交换分区）。点击“立即安装”可以开始安装。 检查分区情况 接下来的几个界面就很熟悉了，要重点注意的是创建用户和密码的步骤。如果你之前有一个单独的 home 分区，并且还想使用相同的 home 目录，那你必须使用和之前相同的用户名和密码，至于设备名称则可以任意指定。 要保持 home 分区不变，请使用之前的用户名和密码 接下来只要静待安装完成，不需执行任何操作。 等待安装完成 安装完成后重新启动系统，你就能使用新的 Linux 发行版。 在以上的例子中，我可以在新的 Linux Mint 19 中使用原有的 Elementary OS 中的整个 home 目录，并且其中所有视频和图片都原封不动。岂不美哉？ via: https://itsfoss.com/replace-linux-from-dual-boot/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>双系统</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[json.dumps() 中的 ensure_ascii 参数]]></title>
    <url>%2F2018%2F10%2F20%2Fthe-parameter-ensure-ascii-in-json-dumps%2F</url>
    <content type="text"><![CDATA[在使用 json.dumps() 的时候，如果数据中包含中文，需要指定一个参数 ensure_ascii 的值为 False。 这是因为 json.dumps() 在序列化时，对中文默认使用 ASCII 编码。 1234567import jsonprint(json.dumps("中"))# "\u4e2d"print(json.dumps("中", ensure_ascii=False))# "中"]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 Python 为你的油箱加油]]></title>
    <url>%2F2018%2F10%2F17%2FPython-at-the-pump-A-script-for-filling-your-gas-tank%2F</url>
    <content type="text"><![CDATA[我来介绍一下我是如何使用 Python 来节省成本的。 我最近在开一辆烧 93 号汽油的车子。根据汽车制造商的说法，它只需要加 91 号汽油就可以了。然而，在美国只能买到 87 号、89 号、93 号汽油。而我家附近的汽油的物价水平是每增加一号，每加仑就要多付 30 美分，因此如果加 93 号汽油，每加仑就要多花 60 美分。为什么不能节省一些钱呢？ 一开始很简单，只需要先加满 93 号汽油，然后在油量表显示油箱半满的时候，用 89 号汽油加满，就得到一整箱 91 号汽油了。但接下来就麻烦了，剩下半箱 91 号汽油加上半箱 93 号汽油，只会变成一箱 92 号汽油，再接下来呢？如果继续算下去，只会越来越混乱。这个时候 Python 就派上用场了。 我的方案是，可以根据汽油的实时状态，不断向油箱中加入 93 号汽油或者 89 号汽油，而最终目标是使油箱内汽油的号数不低于 91。我需要做的是只是通过一些算法来判断新旧汽油混合之后的号数。使用多项式方程或许也可以解决这个问题，但如果使用 Python，好像只需要进行循环就可以了。 123456789101112131415#!/usr/bin/env python# octane.pyo = 93.0newgas = 93.0 # 这个变量记录上一次加入的汽油号数i = 1while i &lt; 21: # 20 次迭代 (加油次数) if newgas == 89.0: # 如果上一次加的是 89 号汽油，改加 93 号汽油 newgas = 93.0 o = newgas/2 + o/2 # 当油箱半满的时候就加油 else: # 如果上一次加的是 93 号汽油，则改加 89 号汽油 newgas = 89.0 o = newgas/2 + o/2 # 当油箱半满的时候就加油 print str(i) + &apos;: &apos;+ str(o) i += 1 在代码中，我首先将变量 o（油箱中的当前混合汽油号数）和变量 newgas（上一次加入的汽油号数）的初始值都设为 93，然后循环 20 次，也就是分别加入 89 号汽油和 93 号汽油一共 20 次，以保持混合汽油号数稳定。 12345678910111213141516171819201: 91.02: 92.03: 90.54: 91.755: 90.3756: 91.68757: 90.343758: 91.6718759: 90.335937510: 91.6679687511: 90.33398437512: 91.666992187513: 90.333496093814: 91.666748046915: 90.333374023416: 91.666687011717: 90.333343505918: 91.666671752919: 90.333335876520: 91.6666679382 从以上数据来看，只需要 10 到 15 次循环，汽油号数就比较稳定了，也相当接近 91 号汽油的目标。这种交替混合直到稳定的现象看起来很有趣，每次交替加入同等量的不同号数汽油，都会趋于稳定。实际上，即使加入的 89 号汽油和 93 号汽油的量不同，也会趋于稳定。 因此，我尝试了不同的比例，我认为加入的 93 号汽油需要比 89 号汽油更多一点。在尽量少补充新汽油的情况下，我最终计算到的结果是 89 号汽油要在油箱大约 7/12 满的时候加进去，而 93 号汽油则要在油箱 1/4 满的时候才加进去。 我的循环将会更改成这样： 1234567if newgas == 89.0: newgas = 93.0 o = 3*newgas/4 + o/4 else: newgas = 89.0 o = 5*newgas/12 + 7*o/12 以下是从第十次加油开始的混合汽油号数： 12345610: 92.512227297811: 91.048799257112: 92.512199814313: 91.04878322514: 92.512195806215: 91.048780887 如你所见，这个调整会令混合汽油号数始终略高于 91。当然，我的油量表并没有 1/12 的刻度，但是 7/12 略小于 5/8，我可以近似地计算。 一个更简单地方案是每次都首先加满 93 号汽油，然后在油箱半满时加入 89 号汽油直到耗尽，这可能会是我的常规方案。就我个人而言，这种方法并不太好，有时甚至会产生一些麻烦。但对于长途旅行来说，这种方案会相对简便一些。有时我也会因为油价突然下跌而购买一些汽油，所以，这个方案是我可以考虑的一系列选项之一。 当然最重要的是：开车不写码，写码不开车！ via: https://opensource.com/article/18/10/python-gas-pump]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在 Linux 中列出可用的软件包组]]></title>
    <url>%2F2018%2F10%2F14%2FHow-To-List-An-Available-Package-Groups-In-Linux%2F</url>
    <content type="text"><![CDATA[我们知道，如果想要在 Linux 中安装软件包，可以使用软件包管理器来进行安装。由于系统管理员需要频繁用到软件包管理器，所以它是 Linux 当中的一个重要工具。 但是如果想一次性安装一个软件包组，在 Linux 中有可能吗？又如何通过命令去实现呢？ 在 Linux 中确实可以用软件包管理器来达到这样的目的。很多软件包管理器都有这样的选项来实现这个功能，但就我所知，apt 或 apt-get 软件包管理器却并没有这个选项。因此对基于 Debian 的系统，需要使用的命令是 tasksel，而不是 apt 或 apt-get 这样的官方软件包管理器。 在 Linux 中安装软件包组有很多好处。对于 LAMP 来说，安装过程会包含多个软件包，但如果安装软件包组命令来安装，只安装一个包就可以了。 当你的团队需要安装 LAMP，但不知道其中具体包含哪些软件包，这个时候软件包组就派上用场了。软件包组是 Linux 系统上一个很方便的工具，它能让你轻松地完成一组软件包的安装。 软件包组是一组用于公共功能的软件包，包括系统工具、声音和视频。 安装软件包组的过程中，会获取到一系列的依赖包，从而大大节省了时间。 推荐阅读： 如何在 Linux 上按照大小列出已安装的软件包 如何在 Linux 上查看/列出可用的软件包更新 如何在 Linux 上查看软件包的安装/更新/升级/移除/卸载时间 如何在 Linux 上查看一个软件包的详细信息 如何查看一个软件包是否在你的 Linux 发行版上可用 萌新指导：一个可视化的 Linux 包管理工具 老手必会：命令行软件包管理器的用法 如何在 CentOS/RHEL 系统上列出可用的软件包组RHEL 和 CentOS 系统使用的是 RPM 软件包，因此可以使用 yum 软件包管理器来获取相关的软件包信息。 yum 是 “Yellowdog Updater, Modified” 的缩写，它是一个用于基于 RPM 系统（例如 RHEL 和 CentOS）的，开源的命令行软件包管理工具。它是从发行版仓库或其它第三方库中获取、安装、删除、查询和管理 RPM 包的主要工具。 推荐阅读： 使用 yum 命令在 RHEL/CentOS 系统上管理软件包 123456789101112131415161718192021222324252627282930313233343536373839# yum grouplistLoaded plugins: fastestmirror, securitySetting up Group ProcessLoading mirror speeds from cached hostfile * epel: epel.mirror.constant.comInstalled Groups: Base E-mail server Graphical Administration Tools Hardware monitoring utilities Legacy UNIX compatibility Milkymist Networking Tools Performance Tools Perl Support Security ToolsAvailable Groups: Additional Development Backup Client Backup Server CIFS file server Client management tools Compatibility libraries Console internet tools Debugging Tools Desktop..Available Language Groups: Afrikaans Support [af] Albanian Support [sq] Amazigh Support [ber] Arabic Support [ar] Armenian Support [hy] Assamese Support [as] Azerbaijani Support [az]..Done 如果需要列出相关联的软件包，可以执行以下这个命令。下面的例子是列出和 “Performance Tools” 组相关联的软件包。 12345678910111213141516171819202122232425262728# yum groupinfo &quot;Performance Tools&quot;Loaded plugins: fastestmirror, securitySetting up Group ProcessLoading mirror speeds from cached hostfile * epel: ewr.edge.kernel.orgGroup: Performance Tools Description: Tools for diagnosing system and application-level performance problems. Mandatory Packages: blktrace sysstat Default Packages: dstat iotop latencytop latencytop-tui oprofile perf powertop seekwatcher Optional Packages: oprofile-jit papi sdparm sg3_utils tiobench tuned tuned-utils 如何在 Fedora 系统上列出可用的软件包组Fedora 系统使用的是 DNF 软件包管理器，因此可以通过 DNF 软件包管理器来获取相关的信息。 DNF 的含义是 “Dandified yum”。DNF 软件包管理器是 YUM 软件包管理器的一个分支，它使用 hawkey/libsolv 库作为后端。从 Fedora 18 开始，Aleš Kozumplík 开始着手 DNF 的开发，直到在 Fedora 22 开始加入到系统中。 dnf 命令可以在 Fedora 22 及更高版本上安装、更新、搜索和删除软件包， 它可以自动解决软件包的依赖关系并其顺利安装，不会产生问题。 YUM 被 DNF 取代是由于 YUM 中存在一些长期未被解决的问题。为什么 Aleš Kozumplík 没有对 yum 的这些问题作出修补呢，他认为补丁解决存在技术上的难题，而 YUM 团队也不会马上接受这些更改，还有一些重要的问题。而且 YUM 的代码量有 5.6 万行，而 DNF 只有 2.9 万行。因此已经不需要沿着 YUM 的方向继续开发了，重新开一个分支才是更好的选择。 推荐阅读： 在 Fedora 系统上使用 DNF 命令管理软件包 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# dnf grouplistLast metadata expiration check: 0:00:00 ago on Sun 09 Sep 2018 07:10:36 PM IST.Available Environment Groups: Fedora Custom Operating System Minimal Install Fedora Server Edition Fedora Workstation Fedora Cloud Server KDE Plasma Workspaces Xfce Desktop LXDE Desktop Hawaii Desktop LXQt Desktop Cinnamon Desktop MATE Desktop Sugar Desktop Environment Development and Creative Workstation Web Server Infrastructure Server Basic DesktopInstalled Groups: C Development Tools and Libraries Development ToolsAvailable Groups: 3D Printing Administration Tools Ansible node Audio Production Authoring and Publishing Books and Guides Cloud Infrastructure Cloud Management Tools Container Management D Development Tools and Libraries.. RPM Development Tools Security Lab Text-based Internet Window Managers GNOME Desktop Environment Graphical Internet KDE (K Desktop Environment) Fonts Games and Entertainment Hardware Support Sound and Video System Tools 如果需要列出相关联的软件包，可以执行以下这个命令。下面的例子是列出和 “Editor” 组相关联的软件包。 1234567891011121314151617181920212223242526272829# dnf groupinfo EditorsLast metadata expiration check: 0:04:57 ago on Sun 09 Sep 2018 07:10:36 PM IST.Group: Editors Description: Sometimes called text editors, these are programs that allow you to create and edit text files. This includes Emacs and Vi. Optional Packages: code-editor cssed emacs emacs-auctex emacs-bbdb emacs-ess emacs-vm geany gobby jed joe leafpad nedit poedit psgml vim-X11 vim-enhanced xemacs xemacs-packages-base xemacs-packages-extra xemacs-xft xmlcopyeditor zile 如何在 openSUSE 系统上列出可用的软件包组openSUSE 系统使用的是 zypper 软件包管理器，因此可以通过 zypper 软件包管理器来获取相关的信息。 Zypper 是 suse 和 openSUSE 发行版的命令行包管理器。它可以用于安装、更新、搜索和删除软件包，还有管理存储库，执行各种查询等功能。 Zypper 命令行界面用到了 ZYpp 系统管理库（libzypp）。 推荐阅读： 在 openSUSE 和 suse 系统使用 zypper 命令管理软件包 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# zypper patternsLoading repository data...Warning: Repository &apos;Update Repository (Non-Oss)&apos; appears to be outdated. Consider using a different mirror or server.Warning: Repository &apos;Main Update Repository&apos; appears to be outdated. Consider using a different mirror or server.Reading installed packages...S | Name | Version | Repository | Dependency---|----------------------|---------------|-----------------------|----------- | 64bit | 20150918-25.1 | Main Repository (OSS) | | apparmor | 20150918-25.1 | Main Repository (OSS) |i | apparmor | 20150918-25.1 | @System | | base | 20150918-25.1 | Main Repository (OSS) |i+ | base | 20150918-25.1 | @System | | books | 20150918-25.1 | Main Repository (OSS) | | console | 20150918-25.1 | Main Repository (OSS) | | devel_C_C++ | 20150918-25.1 | Main Repository (OSS) |i | enhanced_base | 20150918-25.1 | @System | | enlightenment | 20150918-25.1 | Main Repository (OSS) | | file_server | 20150918-25.1 | Main Repository (OSS) | | fonts | 20150918-25.1 | Main Repository (OSS) |i | fonts | 20150918-25.1 | @System | | games | 20150918-25.1 | Main Repository (OSS) |i | games | 20150918-25.1 | @System | | gnome | 20150918-25.1 | Main Repository (OSS) | | gnome_basis | 20150918-25.1 | Main Repository (OSS) |i | imaging | 20150918-25.1 | @System | | kde | 20150918-25.1 | Main Repository (OSS) |i+ | kde | 20150918-25.1 | @System | | kde_plasma | 20150918-25.1 | Main Repository (OSS) |i | kde_plasma | 20150918-25.1 | @System | | lamp_server | 20150918-25.1 | Main Repository (OSS) | | laptop | 20150918-25.1 | Main Repository (OSS) |i+ | laptop | 20150918-25.1 | @System | | lxde | 20150918-25.1 | Main Repository (OSS) | | lxqt | 20150918-25.1 | Main Repository (OSS) |i | multimedia | 20150918-25.1 | @System | | network_admin | 20150918-25.1 | Main Repository (OSS) | | non_oss | 20150918-25.1 | Main Repository (OSS) |i | non_oss | 20150918-25.1 | @System | | office | 20150918-25.1 | Main Repository (OSS) |i | office | 20150918-25.1 | @System | | print_server | 20150918-25.1 | Main Repository (OSS) | | remote_desktop | 20150918-25.1 | Main Repository (OSS) | | x11 | 20150918-25.1 | Main Repository (OSS) |i+ | x11 | 20150918-25.1 | @System | | x86 | 20150918-25.1 | Main Repository (OSS) | | xen_server | 20150918-25.1 | Main Repository (OSS) | | xfce | 20150918-25.1 | Main Repository (OSS) | | xfce_basis | 20150918-25.1 | Main Repository (OSS) | | yast2_basis | 20150918-25.1 | Main Repository (OSS) |i | yast2_basis | 20150918-25.1 | @System | | yast2_install_wf | 20150918-25.1 | Main Repository (OSS) | 如果需要列出相关联的软件包，可以执行以下这个命令。下面的例子是列出和 “file_server” 组相关联的软件包。另外 zypper 还允许用户使用不同的选项执行相同的操作。 12345678910111213141516171819202122232425262728293031323334# zypper info file_serverLoading repository data...Warning: Repository &apos;Update Repository (Non-Oss)&apos; appears to be outdated. Consider using a different mirror or server.Warning: Repository &apos;Main Update Repository&apos; appears to be outdated. Consider using a different mirror or server.Reading installed packages...Information for pattern file_server:------------------------------------Repository : Main Repository (OSS)Name : file_serverVersion : 20150918-25.1Arch : x86_64Vendor : openSUSEInstalled : NoVisible to User : YesSummary : File ServerDescription : File services to host files so that they may be accessed or retrieved by other computers on the same network. This includes the FTP, SMB, and NFS protocols.Contents : S | Name | Type | Dependency ---|-------------------------------|---------|------------ i+ | patterns-openSUSE-base | package | Required | patterns-openSUSE-file_server | package | Required | nfs-kernel-server | package | Recommended i | nfsidmap | package | Recommended i | samba | package | Recommended i | samba-client | package | Recommended i | samba-winbind | package | Recommended | tftp | package | Recommended | vsftpd | package | Recommended | yast2-ftp-server | package | Recommended | yast2-nfs-server | package | Recommended i | yast2-samba-server | package | Recommended | yast2-tftp-server | package | Recommended 如果需要列出相关联的软件包，可以执行以下这个命令。 1234567891011121314151617181920212223242526272829303132333435# zypper pattern-info file_serverLoading repository data...Warning: Repository &apos;Update Repository (Non-Oss)&apos; appears to be outdated. Consider using a different mirror or server.Warning: Repository &apos;Main Update Repository&apos; appears to be outdated. Consider using a different mirror or server.Reading installed packages...Information for pattern file_server:------------------------------------Repository : Main Repository (OSS)Name : file_serverVersion : 20150918-25.1Arch : x86_64Vendor : openSUSEInstalled : NoVisible to User : YesSummary : File ServerDescription : File services to host files so that they may be accessed or retrieved by other computers on the same network. This includes the FTP, SMB, and NFS protocols.Contents : S | Name | Type | Dependency ---|-------------------------------|---------|------------ i+ | patterns-openSUSE-base | package | Required | patterns-openSUSE-file_server | package | Required | nfs-kernel-server | package | Recommended i | nfsidmap | package | Recommended i | samba | package | Recommended i | samba-client | package | Recommended i | samba-winbind | package | Recommended | tftp | package | Recommended | vsftpd | package | Recommended | yast2-ftp-server | package | Recommended | yast2-nfs-server | package | Recommended i | yast2-samba-server | package | Recommended | yast2-tftp-server | package | Recommended 如果需要列出相关联的软件包，也可以执行以下这个命令。 12345678910111213141516171819202122232425262728293031323334# zypper info pattern file_serverLoading repository data...Warning: Repository &apos;Update Repository (Non-Oss)&apos; appears to be outdated. Consider using a different mirror or server.Warning: Repository &apos;Main Update Repository&apos; appears to be outdated. Consider using a different mirror or server.Reading installed packages...Information for pattern file_server:------------------------------------Repository : Main Repository (OSS)Name : file_serverVersion : 20150918-25.1Arch : x86_64Vendor : openSUSEInstalled : NoVisible to User : YesSummary : File ServerDescription : File services to host files so that they may be accessed or retrieved by other computers on the same network. This includes the FTP, SMB, and NFS protocols.Contents : S | Name | Type | Dependency ---|-------------------------------|---------|------------ i+ | patterns-openSUSE-base | package | Required | patterns-openSUSE-file_server | package | Required | nfs-kernel-server | package | Recommended i | nfsidmap | package | Recommended i | samba | package | Recommended i | samba-client | package | Recommended i | samba-winbind | package | Recommended | tftp | package | Recommended | vsftpd | package | Recommended | yast2-ftp-server | package | Recommended | yast2-nfs-server | package | Recommended i | yast2-samba-server | package | Recommended | yast2-tftp-server | package | Recommended 如果需要列出相关联的软件包，也可以执行以下这个命令。 1234567891011121314151617181920212223242526272829303132333435# zypper info -t pattern file_serverLoading repository data...Warning: Repository &apos;Update Repository (Non-Oss)&apos; appears to be outdated. Consider using a different mirror or server.Warning: Repository &apos;Main Update Repository&apos; appears to be outdated. Consider using a different mirror or server.Reading installed packages...Information for pattern file_server:------------------------------------Repository : Main Repository (OSS)Name : file_serverVersion : 20150918-25.1Arch : x86_64Vendor : openSUSEInstalled : NoVisible to User : YesSummary : File ServerDescription : File services to host files so that they may be accessed or retrieved by other computers on the same network. This includes the FTP, SMB, and NFS protocols.Contents : S | Name | Type | Dependency ---|-------------------------------|---------|------------ i+ | patterns-openSUSE-base | package | Required | patterns-openSUSE-file_server | package | Required | nfs-kernel-server | package | Recommended i | nfsidmap | package | Recommended i | samba | package | Recommended i | samba-client | package | Recommended i | samba-winbind | package | Recommended | tftp | package | Recommended | vsftpd | package | Recommended | yast2-ftp-server | package | Recommended | yast2-nfs-server | package | Recommended i | yast2-samba-server | package | Recommended | yast2-tftp-server | package | Recommended 如何在 Debian/Ubuntu 系统上列出可用的软件包组由于 APT 或 APT-GET 软件包管理器没有为基于 Debian/Ubuntu 的系统提供这样的选项，因此需要使用 tasksel 命令来获取相关信息。 tasksel 是 Debian/Ubuntu 系统上一个很方便的工具，只需要很少的操作就可以用它来安装好一组软件包。可以在 /usr/share/tasksel 目录下的 .desc 文件中安排软件包的安装任务。 默认情况下，tasksel 工具是作为 Debian 系统的一部分安装的，但桌面版 Ubuntu 则没有自带 tasksel，这个功能类似软件包管理器中的元包（meta-packages）。 tasksel 工具带有一个基于 zenity 的简单用户界面，例如命令行中的弹出图形对话框。 推荐阅读： 使用 tasksel 在 Debian/Ubuntu 系统上快速安装软件包组 12345678910111213141516171819202122232425262728293031323334353637383940414243# tasksel --list-tasku kubuntu-live Kubuntu live CDu lubuntu-live-gtk Lubuntu live CD (GTK part)u ubuntu-budgie-live Ubuntu Budgie live CDu ubuntu-live Ubuntu live CDu ubuntu-mate-live Ubuntu MATE Live CDu ubuntustudio-dvd-live Ubuntu Studio live DVDu vanilla-gnome-live Ubuntu GNOME live CDu xubuntu-live Xubuntu live CDu cloud-image Ubuntu Cloud Image (instance)u dns-server DNS serveru kubuntu-desktop Kubuntu desktopu kubuntu-full Kubuntu fullu lamp-server LAMP serveru lubuntu-core Lubuntu minimal installationu lubuntu-desktop Lubuntu Desktopu lubuntu-gtk-core Lubuntu minimal installation (GTK part)u lubuntu-gtk-desktop Lubuntu Desktop (GTK part)u lubuntu-qt-core Lubuntu minimal installation (Qt part)u lubuntu-qt-desktop Lubuntu Qt Desktop (Qt part)u mail-server Mail serveru postgresql-server PostgreSQL databasei print-server Print serveru samba-server Samba file serveru tomcat-server Tomcat Java serveru ubuntu-budgie-desktop Ubuntu Budgie desktopi ubuntu-desktop Ubuntu desktopu ubuntu-mate-core Ubuntu MATE minimalu ubuntu-mate-desktop Ubuntu MATE desktopi ubuntu-usb Ubuntu desktop USBu ubuntustudio-audio Audio recording and editing suiteu ubuntustudio-desktop Ubuntu Studio desktopu ubuntustudio-desktop-core Ubuntu Studio minimal DE installationu ubuntustudio-fonts Large selection of font packagesu ubuntustudio-graphics 2D/3D creation and editing suiteu ubuntustudio-photography Photograph touchup and editing suiteu ubuntustudio-publishing Publishing applicationsu ubuntustudio-video Video creation and editing suiteu vanilla-gnome-desktop Vanilla GNOME desktopu xubuntu-core Xubuntu minimal installationu xubuntu-desktop Xubuntu desktopu openssh-server OpenSSH serveru server Basic Ubuntu server 如果需要列出相关联的软件包，可以执行以下这个命令。下面的例子是列出和 “lamp-server” 组相关联的软件包。 12# tasksel --task-desc &quot;lamp-server&quot;Selects a ready-made Linux/Apache/MySQL/PHP server. 如何在基于 Arch Linux 的系统上列出可用的软件包组基于 Arch Linux 的系统使用的是 pacman 软件包管理器，因此可以通过 pacman 软件包管理器来获取相关的信息。 pacman 是 “package manager” 的缩写。pacman 可以用于安装、构建、删除和管理 Arch Linux 软件包。pacman 使用 libalpm（Arch Linux Package Management 库，ALPM）作为后端来执行所有操作。 推荐阅读： 使用 pacman 在基于 Arch Linux 的系统上管理软件包 12345678910111213141516171819202122232425262728293031323334353637# pacman -Sgbase-develbasemultilib-develgnome-extrakde-applicationskdepimkdeutilskdeedukf5kdemultimediagnomeplasmakdegameskdesdkkdebasexfce4fprintkdegraphicskdenetworkkdeadminkf5-aidskdewebdev..dlang-ldclibretroringlxqtnon-dawnonalsaqtcurverealtimesugar-fructosetesseract-datavim-plugins 如果需要列出相关联的软件包，可以执行以下这个命令。下面的例子是列出和 “gnome” 组相关联的软件包。 123456789101112131415161718192021222324252627282930313233# pacman -Sg gnomegnome baobabgnome cheesegnome eoggnome epiphanygnome evincegnome file-rollergnome gdmgnome geditgnome gnome-backgroundsgnome gnome-calculatorgnome gnome-calendargnome gnome-charactersgnome gnome-clocksgnome gnome-color-managergnome gnome-contactsgnome gnome-control-centergnome gnome-dictionarygnome gnome-disk-utilitygnome gnome-documentsgnome gnome-font-viewer..gnome sushignome totemgnome trackergnome tracker-minersgnome vinognome xdg-user-dirs-gtkgnome yelpgnome gnome-boxesgnome gnome-softwaregnome simple-scan 也可以执行以下这个命令实现同样的效果。 1234567891011121314# pacman -S gnome:: There are 64 members in group gnome::: Repository extra 1) baobab 2) cheese 3) eog 4) epiphany 5) evince 6) file-roller 7) gdm 8) gedit 9) gnome-backgrounds 10) gnome-calculator 11) gnome-calendar 12) gnome-characters 13) gnome-clocks 14) gnome-color-manager 15) gnome-contacts 16) gnome-control-center 17) gnome-dictionary 18) gnome-disk-utility 19) gnome-documents 20) gnome-font-viewer 21) gnome-getting-started-docs 22) gnome-keyring 23) gnome-logs 24) gnome-maps 25) gnome-menus 26) gnome-music 27) gnome-photos 28) gnome-screenshot 29) gnome-session 30) gnome-settings-daemon 31) gnome-shell 32) gnome-shell-extensions 33) gnome-system-monitor 34) gnome-terminal 35) gnome-themes-extra 36) gnome-todo 37) gnome-user-docs 38) gnome-user-share 39) gnome-video-effects 40) grilo-plugins 41) gvfs 42) gvfs-afc 43) gvfs-goa 44) gvfs-google 45) gvfs-gphoto2 46) gvfs-mtp 47) gvfs-nfs 48) gvfs-smb 49) mousetweaks 50) mutter 51) nautilus 52) networkmanager 53) orca 54) rygel 55) sushi 56) totem 57) tracker 58) tracker-miners 59) vino 60) xdg-user-dirs-gtk 61) yelp:: Repository community 62) gnome-boxes 63) gnome-software 64) simple-scanEnter a selection (default=all): ^CInterrupt signal received 可以执行以下命令检查相关软件包的数量。 12# pacman -Sg gnome | wc -l64 via: https://www.2daygeek.com/how-to-list-an-available-package-groups-in-linux/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>软件包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[75 个最常用的 Linux 应用程序（2018 年）]]></title>
    <url>%2F2018%2F10%2F10%2F75-Most-Used-Essential-Linux-Applications-of-2018%2F</url>
    <content type="text"><![CDATA[对于许多应用程序来说，2018 年是非常好的一年，尤其是自由开源的应用程序。尽管各种 Linux 发行版都自带了很多默认的应用程序，但用户也可以自由地选择使用它们或者其它任何免费或付费替代方案。 下面汇总了一系列的 Linux 应用程序，这些应用程序都能够在 Linux 系统上安装，尽管还有很多其它选择。以下汇总中的任何应用程序都属于其类别中最常用的应用程序，如果你还没有用过，欢迎试用一下！ 备份工具RsyncRsync 是一个开源的、节约带宽的工具，它用于执行快速的增量文件传输，而且它也是一个免费工具。 1$ rsync [OPTION...] SRC... [DEST] 想要了解更多示例和用法，可以参考《10 个使用 Rsync 命令的实际例子》。 TimeshiftTimeshift 能够通过增量快照来保护用户的系统数据，而且可以按照日期恢复指定的快照，类似于 Mac OS 中的 Time Machine 功能和 Windows 中的系统还原功能。 BT（BitTorrent） 客户端 DelugeDeluge 是一个漂亮的跨平台 BT 客户端，旨在优化 μTorrent 体验，并向用户免费提供服务。 使用以下命令在 Ubuntu 和 Debian 安装 Deluge。 123$ sudo add-apt-repository ppa:deluge-team/ppa$ sudo apt-get update$ sudo apt-get install deluge qBittorentqBittorent 是一个开源的 BT 客户端，旨在提供类似 μTorrent 的免费替代方案。 使用以下命令在 Ubuntu 和 Debian 安装 qBittorent。 123$ sudo add-apt-repository ppa:qbittorrent-team/qbittorrent-stable$ sudo apt-get update$ sudo apt-get install qbittorrent TransmissionTransmission 是一个强大的 BT 客户端，它主要关注速度和易用性，一般在很多 Linux 发行版上都有预装。 使用以下命令在 Ubuntu 和 Debian 安装 Transmission。 123$ sudo add-apt-repository ppa:transmissionbt/ppa$ sudo apt-get update$ sudo apt-get install transmission-gtk transmission-cli transmission-common transmission-daemon 云存储 DropboxDropbox 团队在今年早些时候给他们的云服务换了一个名字，也为客户提供了更好的性能和集成了更多应用程序。Dropbox 会向用户免费提供 2 GB 存储空间。 使用以下命令在 Ubuntu 和 Debian 安装 Dropbox。 123$ cd ~ &amp;&amp; wget -O - &quot;https://www.dropbox.com/download?plat=lnx.x86&quot; | tar xzf - [On 32-Bit]$ cd ~ &amp;&amp; wget -O - &quot;https://www.dropbox.com/download?plat=lnx.x86_64&quot; | tar xzf - [On 64-Bit]$ ~/.dropbox-dist/dropboxd Google DriveGoogle Drive 是 Google 提供的云服务解决方案，这已经是一个广为人知的服务了。与 Dropbox 一样，可以通过它在所有联网的设备上同步文件。它免费提供了 15 GB 存储空间，包括Gmail、Google 图片、Google 地图等服务。 参考阅读：5 个适用于 Linux 的 Google Drive 客户端 MegaMega 也是一个出色的云存储解决方案，它的亮点除了高度的安全性之外，还有为用户免费提供高达 50 GB 的免费存储空间。它使用端到端加密，以确保用户的数据安全，所以如果忘记了恢复密钥，用户自己也无法访问到存储的数据。 参考阅读：在 Ubuntu 下载 Mega 云存储客户端 命令行编辑器 VimVim 是 vi 文本编辑器的开源克隆版本，它的主要目的是可以高度定制化并能够处理任何类型的文本。 使用以下命令在 Ubuntu 和 Debian 安装 Vim。 123$ sudo add-apt-repository ppa:jonathonf/vim$ sudo apt update$ sudo apt install vim EmacsEmacs 是一个高度可配置的文本编辑器，最流行的一个分支 GNU Emacs 是用 Lisp 和 C 编写的，它的最大特点是可以自文档化、可扩展和可自定义。 使用以下命令在 Ubuntu 和 Debian 安装 Emacs。 123$ sudo add-apt-repository ppa:kelleyk/emacs$ sudo apt update$ sudo apt install emacs25 NanoNano 是一款功能丰富的命令行文本编辑器，比较适合高级用户。它可以通过多个终端进行不同功能的操作。 使用以下命令在 Ubuntu 和 Debian 安装 Nano。 123$ sudo add-apt-repository ppa:n-muench/programs-ppa$ sudo apt-get update$ sudo apt-get install nano 下载器 Aria2Aria2 是一个开源的、轻量级的、多软件源和多协议的命令行下载器，它支持 Metalink、torrent、HTTP/HTTPS、SFTP 等多种协议。 使用以下命令在 Ubuntu 和 Debian 安装 Aria2。 1$ sudo apt-get install aria2 uGetuGet 已经成为 Linux 各种发行版中排名第一的开源下载器，它可以处理任何下载任务，包括多连接、队列、类目等。 使用以下命令在 Ubuntu 和 Debian 安装 uGet。 123$ sudo add-apt-repository ppa:plushuang-tw/uget-stable$ sudo apt update$ sudo apt install uget XDMXDM（Xtreme Download Manager）是一个使用 Java 编写的开源下载软件。和其它下载器一样，它可以结合队列、种子、浏览器使用，而且还带有视频采集器和智能调度器。 使用以下命令在 Ubuntu 和 Debian 安装 XDM。 123$ sudo add-apt-repository ppa:noobslab/apps$ sudo apt-get update$ sudo apt-get install xdman 电子邮件客户端 ThunderbirdThunderbird 是最受欢迎的电子邮件客户端之一。它的优点包括免费、开源、可定制、功能丰富，而且最重要的是安装过程也很简便。 使用以下命令在 Ubuntu 和 Debian 安装 Thunderbird。 123$ sudo add-apt-repository ppa:ubuntu-mozilla-security/ppa$ sudo apt-get update$ sudo apt-get install thunderbird GearyGeary 是一个基于 WebKitGTK+ 的开源电子邮件客户端。它是一个免费开源的功能丰富的软件，并被 GNOME 项目收录。 使用以下命令在 Ubuntu 和 Debian 安装 Geary。 123$ sudo add-apt-repository ppa:geary-team/releases$ sudo apt-get update$ sudo apt-get install geary EvolutionEvolution 是一个免费开源的电子邮件客户端，可以用于电子邮件、会议日程、备忘录和联系人的管理。 使用以下命令在 Ubuntu 和 Debian 安装 Evolution。 123$ sudo add-apt-repository ppa:gnome3-team/gnome3-staging$ sudo apt-get update$ sudo apt-get install evolution 财务软件 GnuCashGnuCash 是一款免费的跨平台开源软件，它适用于个人和中小型企业的财务任务。 使用以下命令在 Ubuntu 和 Debian 安装 GnuCash。 123$ sudo sh -c &apos;echo &quot;deb http://archive.getdeb.net/ubuntu $(lsb_release -sc)-getdeb apps&quot; &gt;&gt; /etc/apt/sources.list.d/getdeb.list&apos;$ sudo apt-get update$ sudo apt-get install gnucash KMyMoneyKMyMoney 是一个财务管理软件，它可以提供商用或个人理财所需的大部分主要功能。 使用以下命令在 Ubuntu 和 Debian 安装 KmyMoney。 123$ sudo add-apt-repository ppa:claydoh/kmymoney2-kde4$ sudo apt-get update$ sudo apt-get install kmymoney IDE Eclipse IDEEclipse 是最广为使用的 Java IDE，它包括一个基本工作空间和一个用于自定义编程环境的强大的的插件配置系统。 关于 Eclipse IDE 的安装，可以参考 如何在 Debian 和 Ubuntu 上安装 Eclipse IDE 这一篇文章。 Netbeans IDENetbeans 是一个相当受用户欢迎的 IDE，它支持使用 Java、PHP、HTML 5、JavaScript、C/C++ 或其他语言编写移动应用，桌面软件和 web 应用。 关于 Netbeans IDE 的安装，可以参考 如何在 Debian 和 Ubuntu 上安装 Netbeans IDE 这一篇文章。 BracketsBrackets 是由 Adobe 开发的高级文本编辑器，它带有可视化工具，支持预处理程序，以及用于 web 开发的以设计为中心的用户流程。对于熟悉它的用户，它可以发挥 IDE 的作用。 使用以下命令在 Ubuntu 和 Debian 安装 Brackets。 123$ sudo add-apt-repository ppa:webupd8team/brackets$ sudo apt-get update$ sudo apt-get install brackets Atom IDEAtom IDE 是一个加强版的 Atom 编辑器，它添加了大量扩展和库以提高性能和增加功能。总之，它是各方面都变得更强大了的 Atom 。 使用以下命令在 Ubuntu 和 Debian 安装 Atom。 12$ sudo apt-get install snapd$ sudo snap install atom --classic Light TableLight Table 号称下一代的 IDE，它提供了数据流量统计和协作编程等的强大功能。 使用以下命令在 Ubuntu 和 Debian 安装 Light Table。 123$ sudo add-apt-repository ppa:dr-akulavich/lighttable$ sudo apt-get update$ sudo apt-get install lighttable-installer Visual Studio CodeVisual Studio Code 是由微软开发的代码编辑器，它包含了文本编辑器所需要的最先进的功能，包括语法高亮、自动完成、代码调试、性能统计和图表显示等功能。 参考阅读：在Ubuntu 下载 Visual Studio Code 即时通信工具 PidginPidgin 是一个开源的即时通信工具，它几乎支持所有聊天平台，还支持额外扩展功能。 使用以下命令在 Ubuntu 和 Debian 安装 Pidgin。 123$ sudo add-apt-repository ppa:jonathonf/backports$ sudo apt-get update$ sudo apt-get install pidgin SkypeSkype 也是一个广为人知的软件了，任何感兴趣的用户都可以在 Linux 上使用。 使用以下命令在 Ubuntu 和 Debian 安装 Skype。 12$ sudo apt install snapd$ sudo snap install skype --classic EmpathyEmpathy 是一个支持多协议语音、视频聊天、文本和文件传输的即时通信工具。它还允许用户添加多个服务的帐户，并用其与所有服务的帐户进行交互。 使用以下命令在 Ubuntu 和 Debian 安装 Empathy。 1$ sudo apt-get install empathy Linux 防病毒工具ClamAV/ClamTkClamAV 是一个开源的跨平台命令行防病毒工具，用于检测木马、病毒和其他恶意代码。而 ClamTk 则是它的前端 GUI。 使用以下命令在 Ubuntu 和 Debian 安装 ClamAV 和 ClamTk。 12$ sudo apt-get install clamav$ sudo apt-get install clamtk Linux 桌面环境CinnamonCinnamon 是 GNOME 3 的自由开源衍生产品，它遵循传统的 桌面比拟desktop metaphor 约定。 使用以下命令在 Ubuntu 和 Debian 安装 Cinnamon。 123$ sudo add-apt-repository ppa:embrosyn/cinnamon$ sudo apt update$ sudo apt install cinnamon-desktop-environment lightdm MateMate 桌面环境是 GNOME 2 的衍生和延续，目的是在 Linux 上通过使用传统的桌面比拟提供有一个吸引力的 UI。 使用以下命令在 Ubuntu 和 Debian 安装 Mate。 123$ sudo apt install tasksel$ sudo apt update$ sudo tasksel install ubuntu-mate-desktop GNOMEGNOME 是由一些免费和开源应用程序组成的桌面环境，它可以运行在任何 Linux 发行版和大多数 BSD 衍生版本上。 使用以下命令在 Ubuntu 和 Debian 安装 Gnome。 123$ sudo apt install tasksel$ sudo apt update$ sudo tasksel install ubuntu-desktop KDEKDE 由 KDE 社区开发，它为用户提供图形解决方案以控制操作系统并执行不同的计算任务。 使用以下命令在 Ubuntu 和 Debian 安装 KDE。 123$ sudo apt install tasksel$ sudo apt update$ sudo tasksel install kubuntu-desktop Linux 维护工具GNOME Tweak ToolGNOME Tweak Tool 是用于自定义和调整 GNOME 3 和 GNOME Shell 设置的流行工具。 使用以下命令在 Ubuntu 和 Debian 安装 GNOME Tweak Tool。 1$ sudo apt install gnome-tweak-tool StacerStacer 是一款用于监控和优化 Linux 系统的免费开源应用程序。 使用以下命令在 Ubuntu 和 Debian 安装 Stacer。 123$ sudo add-apt-repository ppa:oguzhaninan/stacer$ sudo apt-get update$ sudo apt-get install stacer BleachBitBleachBit 是一个免费的磁盘空间清理器，它也可用作隐私管理器和系统优化器。 参考阅读：在 Ubuntu 下载 BleachBit Linux 终端工具GNOME 终端GNOME 终端 是 GNOME 的默认终端模拟器。 使用以下命令在 Ubuntu 和 Debian 安装 Gnome 终端。 1$ sudo apt-get install gnome-terminal KonsoleKonsole 是 KDE 的一个终端模拟器。 使用以下命令在 Ubuntu 和 Debian 安装 Konsole。 1$ sudo apt-get install konsole TerminatorTerminator 是一个功能丰富的终端程序，它基于 GNOME 终端，并且专注于整理终端功能。 使用以下命令在 Ubuntu 和 Debian 安装 Terminator。 1$ sudo apt-get install terminator GuakeGuake 是 GNOME 桌面环境下一个轻量级的可下拉式终端。 使用以下命令在 Ubuntu 和 Debian 安装 Guake。 1$ sudo apt-get install guake 多媒体编辑工具ArdourArdour 是一款漂亮的的数字音频工作站Digital Audio Workstation，可以完成专业的录制、编辑和混音工作。 使用以下命令在 Ubuntu 和 Debian 安装 Ardour。 123$ sudo add-apt-repository ppa:dobey/audiotools$ sudo apt-get update$ sudo apt-get install ardour AudacityAudacity 是最著名的音频编辑软件之一，它是一款跨平台的开源多轨音频编辑器。 使用以下命令在 Ubuntu 和 Debian 安装 Audacity。 123$ sudo add-apt-repository ppa:ubuntuhandbook1/audacity$ sudo apt-get update$ sudo apt-get install audacity GIMPGIMP 是 Photoshop 的开源替代品中最受欢迎的。这是因为它有多种可自定义的选项、第三方插件以及活跃的用户社区。 使用以下命令在 Ubuntu 和 Debian 安装 Gimp。 123$ sudo add-apt-repository ppa:otto-kesselgulasch/gimp$ sudo apt update$ sudo apt install gimp KritaKrita 是一款开源的绘画程序，它具有美观的 UI 和可靠的性能，也可以用作图像处理工具。 使用以下命令在 Ubuntu 和 Debian 安装 Krita。 123$ sudo add-apt-repository ppa:kritalime/ppa$ sudo apt update$ sudo apt install krita LightworksLightworks 是一款功能强大、灵活美观的专业视频编辑工具。它拥有上百种配套的视觉效果功能，可以处理任何编辑任务，毕竟这个软件已经有长达 25 年的视频处理经验。 参考阅读：在 Ubuntu 下载 Lightworks OpenShotOpenShot 是一款屡获殊荣的免费开源视频编辑器，这主要得益于其出色的性能和强大的功能。 使用以下命令在 Ubuntu 和 Debian 安装 `Openshot。 123$ sudo add-apt-repository ppa:openshot.developers/ppa$ sudo apt update$ sudo apt install openshot-qt PiTiVPitivi 也是一个美观的视频编辑器，它有优美的代码库、优质的社区，还支持优秀的协作编辑功能。 使用以下命令在 Ubuntu 和 Debian 安装 PiTiV。 123$ flatpak install --user https://flathub.org/repo/appstream/org.pitivi.Pitivi.flatpakref$ flatpak install --user http://flatpak.pitivi.org/pitivi.flatpakref$ flatpak run org.pitivi.Pitivi//stable 音乐播放器RhythmboxRhythmbox 支持海量种类的音乐，目前被认为是最可靠的音乐播放器，并由 Ubuntu 自带。 使用以下命令在 Ubuntu 和 Debian 安装 Rhythmbox。 123$ sudo add-apt-repository ppa:fossfreedom/rhythmbox$ sudo apt-get update$ sudo apt-get install rhythmbox LollypopLollypop 是一款较为年轻的开源音乐播放器，它有很多高级选项，包括网络电台，滑动播放和派对模式。尽管功能繁多，它仍然尽量做到简单易管理。 使用以下命令在 Ubuntu 和 Debian 安装 Lollypop。 123$ sudo add-apt-repository ppa:gnumdk/lollypop$ sudo apt-get update$ sudo apt-get install lollypop AmarokAmarok 是一款功能强大的音乐播放器，它有一个直观的 UI 和大量的高级功能，而且允许用户根据自己的偏好去发现新音乐。 使用以下命令在 Ubuntu 和 Debian 安装 Amarok。 12$ sudo apt-get update$ sudo apt-get install amarok ClementineClementine 是一款 Amarok 风格的音乐播放器，因此和 Amarok 相似，也有直观的用户界面、先进的控制模块，以及让用户搜索和发现新音乐的功能。 使用以下命令在 Ubuntu 和 Debian 安装 Clementine。 123$ sudo add-apt-repository ppa:me-davidsansome/clementine$ sudo apt-get update$ sudo apt-get install clementine CmusCmus 可以说是最高效的的命令行界面音乐播放器了，它具有快速可靠的特点，也支持使用扩展。 使用以下命令在 Ubuntu 和 Debian 安装 Cmus。 123$ sudo add-apt-repository ppa:jmuc/cmus$ sudo apt-get update$ sudo apt-get install cmus 办公软件Calligra 套件Calligra 套件为用户提供了一套总共 8 个应用程序，涵盖办公、管理、图表等各个范畴。 使用以下命令在 Ubuntu 和 Debian 安装 Calligra 套件。 1$ sudo apt-get install calligra LibreOfficeLibreOffice 是开源社区中开发过程最活跃的办公套件，它以可靠性著称，也可以通过扩展来添加功能。 使用以下命令在 Ubuntu 和 Debian 安装 LibreOffice。 123$ sudo add-apt-repository ppa:libreoffice/ppa$ sudo apt update$ sudo apt install libreoffice WPS OfficeWPS Office 是一款漂亮的办公套件，它有一个很具现代感的 UI。 参考阅读：在 Ubuntu 安装 WPS Office 屏幕截图工具ShutterShutter 允许用户截取桌面的屏幕截图，然后使用一些效果进行编辑，还支持上传和在线共享。 使用以下命令在 Ubuntu 和 Debian 安装 Shutter。 123$ sudo add-apt-repository -y ppa:shutter/ppa$ sudo apt update$ sudo apt install shutter KazamKazam 可以用于捕获屏幕截图，它的输出对于任何支持 VP8/WebM 和 PulseAudio 视频播放器都可用。 使用以下命令在 Ubuntu 和 Debian 安装 Kazam。 123$ sudo add-apt-repository ppa:kazam-team/unstable-series$ sudo apt update$ sudo apt install kazam python3-cairo python3-xlib Gnome ScreenshotGnome Screenshot 过去曾经和 Gnome 一起捆绑，但现在已经独立出来。它以易于共享的格式进行截屏。 使用以下命令在 Ubuntu 和 Debian 安装 Gnome Screenshot。 12$ sudo apt-get update$ sudo apt-get install gnome-screenshot 录屏工具SimpleScreenRecorderSimpleScreenRecorder 面世时已经是录屏工具中的佼佼者，现在已成为 Linux 各个发行版中最有效、最易用的录屏工具之一。 使用以下命令在 Ubuntu 和 Debian 安装 SimpleScreenRecorder。 123$ sudo add-apt-repository ppa:maarten-baert/simplescreenrecorder$ sudo apt-get update$ sudo apt-get install simplescreenrecorder recordMyDesktoprecordMyDesktop 是一个开源的会话记录器，它也能记录桌面会话的音频。 使用以下命令在 Ubuntu 和 Debian 安装 recordMyDesktop。 12$ sudo apt-get update$ sudo apt-get install gtk-recordmydesktop 文本编辑器AtomAtom 是由 GitHub 开发和维护的可定制文本编辑器。它是开箱即用的，但也可以使用扩展和主题自定义 UI 来增强其功能。 使用以下命令在 Ubuntu 和 Debian 安装 Atom。 12$ sudo apt-get install snapd$ sudo snap install atom --classic Sublime TextSublime Text 已经成为目前最棒的文本编辑器。它可定制、轻量灵活（即使打开了大量数据文件和加入了大量扩展），最重要的是可以永久免费使用。 使用以下命令在 Ubuntu 和 Debian 安装 Sublime Text。 12$ sudo apt-get install snapd$ sudo snap install sublime-text GeanyGeany 是一个内存友好的文本编辑器，它具有基本的IDE功能，可以显示加载时间、扩展库函数等。 使用以下命令在 Ubuntu 和 Debian 安装 Geany。 12$ sudo apt-get update$ sudo apt-get install geany GeditGedit 以其简单著称，在很多 Linux 发行版都有预装，它具有文本编辑器都具有的优秀的功能。 使用以下命令在 Ubuntu 和 Debian 安装 Gedit。 12$ sudo apt-get update$ sudo apt-get install gedit 备忘录软件EvernoteEvernote 是一款云上的笔记程序，它带有待办列表和提醒功能，能够与不同类型的笔记完美配合。 Evernote 在 Linux 上没有官方提供的软件，但可以参考 Linux 上的 6 个 Evernote 替代客户端 这篇文章使用其它第三方工具。 EverdoEverdo 是一款美观，安全，易兼容的备忘软件，可以用于处理待办事项和其它笔记。如果你认为 Evernote 有所不足，相信 Everdo 会是一个好的替代。 参考阅读：在 Ubuntu 下载 Everdo TaskwarriorTaskwarrior 是一个用于管理个人任务的开源跨平台命令行应用，它的速度和无干扰的环境是它的两大特点。 使用以下命令在 Ubuntu 和 Debian 安装 Taskwarrior。 12$ sudo apt-get update$ sudo apt-get install taskwarrior 视频播放器BansheeBanshee 是一个开源的支持多格式的媒体播放器，于 2005 年开始开发并逐渐成长。 使用以下命令在 Ubuntu 和 Debian 安装 Banshee。 123$ sudo add-apt-repository ppa:banshee-team/ppa$ sudo apt-get update$ sudo apt-get install banshee VLCVLC 是我最喜欢的视频播放器，它几乎可以播放任何格式的音频和视频，它还可以播放网络电台、录制桌面会话以及在线播放电影。 使用以下命令在 Ubuntu 和 Debian 安装 VLC。 123$ sudo add-apt-repository ppa:videolan/stable-daily$ sudo apt-get update$ sudo apt-get install vlc KodiKodi 是世界上最着名的媒体播放器之一，它有一个成熟的媒体中心，可以播放本地和远程的多媒体文件。 使用以下命令在 Ubuntu 和 Debian 安装 Kodi。 1234$ sudo apt-get install software-properties-common$ sudo add-apt-repository ppa:team-xbmc/ppa$ sudo apt-get update$ sudo apt-get install kodi SMPlayerSMPlayer 是 MPlayer 的 GUI 版本，所有流行的媒体格式它都能够处理，并且它还有从 YouTube 和 Chromcast 和下载字幕的功能。 使用以下命令在 Ubuntu 和 Debian 安装 SMPlayer。 123$ sudo add-apt-repository ppa:rvm/smplayer$ sudo apt-get update$ sudo apt-get install smplayer 虚拟化工具VirtualBoxVirtualBox 是一个用于操作系统虚拟化的开源应用程序，在服务器、台式机和嵌入式系统上都可以运行。 使用以下命令在 Ubuntu 和 Debian 安装 VirtualBox。 12345$ wget -q https://www.virtualbox.org/download/oracle_vbox_2016.asc -O- | sudo apt-key add -$ wget -q https://www.virtualbox.org/download/oracle_vbox.asc -O- | sudo apt-key add -$ sudo apt-get update$ sudo apt-get install virtualbox-5.2$ virtualbox VMWareVMware 是一个为客户提供平台虚拟化和云计算服务的数字工作区，是第一个成功将 x86 架构系统虚拟化的工作站。 VMware 工作站的其中一个产品就允许用户在虚拟内存中运行多个操作系统。 参阅 在 Ubuntu 上安装 VMWare Workstation Pro 可以了解 VMWare 的安装。 浏览器ChromeGoogle Chrome 无疑是最受欢迎的浏览器。Chrome 以其速度、简洁、安全、美观而受人喜爱，它遵循了 Google 的界面设计风格，是 web 开发人员不可缺少的浏览器，同时它也是免费开源的。 使用以下命令在 Ubuntu 和 Debian 安装 Google Chrome。 1234$ wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -$ sudo sh -c &apos;echo &quot;deb http://dl.google.com/linux/chrome/deb/ stable main&quot; &gt;&gt; /etc/apt/sources.list.d/google.list&apos;$ sudo apt-get update$ sudo apt-get install google-chrome-stable FirefoxFirefox Quantum 是一款漂亮、快速、完善并且可自定义的浏览器。它也是自由开源的，包含有开发人员所需要的工具，对于初学者也没有任何使用门槛。 使用以下命令在 Ubuntu 和 Debian 安装 Firefox Quantum。 123$ sudo add-apt-repository ppa:mozillateam/firefox-next$ sudo apt update &amp;&amp; sudo apt upgrade$ sudo apt install firefox VivaldiVivaldi 是一个基于 Chrome 的自由开源项目，旨在通过添加扩展来使 Chrome 的功能更加完善。色彩丰富的界面，性能良好、灵活性强是它的几大特点。 参考阅读：在 Ubuntu 下载 Vivaldi 以上就是我的推荐，你还有更好的软件向大家分享吗？欢迎评论。 via: https://www.fossmint.com/most-used-linux-applications/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 开发的五大必备工具]]></title>
    <url>%2F2018%2F10%2F08%2F5-Essential-Tools-for-Linux-Development%2F</url>
    <content type="text"><![CDATA[Linux 上的开发工具如此之多，以至于会担心找不到恰好适合你的。 Linux 已经成为工作、娱乐和个人生活等多个领域的支柱，人们已经越来越离不开它。在 Linux 的帮助下，技术的变革速度超出了人们的想象，Linux 开发的速度也以指数规模增长。因此，越来越多的开发者也不断地加入开源和学习 Linux 开发地潮流当中。在这个过程之中，合适的工具是必不可少的，可喜的是，随着 Linux 的发展，大量适用于 Linux 的开发工具也不断成熟。甚至可以说，这样的工具已经多得有点惊人。 为了选择更合适自己的开发工具，缩小选择范围是很必要的。但是这篇文章并不会要求你必须使用某个工具，而只是缩小到五个工具类别，然后对每个类别提供一个例子。然而，对于大多数类别，都会有不止一种选择。下面我们来看一下。 容器放眼于现实，现在已经是容器的时代了。容器既及其容易部署，又可以方便地构建开发环境。如果你针对的是特定的平台的开发，将开发流程所需要的各种工具都创建到容器映像中是一种很好的方法，只要使用这一个容器映像，就能够快速启动大量运行所需服务的实例。 一个使用容器的最佳范例是使用 Docker，使用容器（或 Docker）有这些好处： 开发环境保持一致 部署后即可运行 易于跨平台部署 Docker 映像适用于多种开发环境和语言 部署单个容器或容器集群都并不繁琐 通过 Docker Hub，几乎可以找到适用于任何平台、任何开发环境、任何服务器、任何服务的映像，几乎可以满足任何一种需求。使用 Docker Hub 中的映像，就相当于免除了搭建开发环境的步骤，可以直接开始开发应用程序、服务器、API 或服务。 Docker 在所有 Linux 平台上都很容易安装，例如可以通过终端输入以下命令在 Ubuntu 上安装 Docker： 1sudo apt-get install docker.io Docker 安装完毕后，就可以从 Docker 仓库中拉取映像，然后开始开发和部署了（如下图）。 图 1： Docker 镜像准备部署 版本控制工具如果你正在开发一个大型项目，又或者参与团队开发，版本控制工具是必不可少的，它可以用于记录代码变更、提交代码以及合并代码。如果没有这样的工具，项目几乎无法妥善管理。在 Linux 系统上，Git 和 GitHub 的易用性和流行程度是其它版本控制工具无法比拟的。如果你对 Git 和 GitHub 还不太熟悉，可以简单理解为 Git 是在本地计算机上安装的版本控制系统，而 GitHub 则是用于上传和管理项目的远程存储库。 Git 可以安装在大多数的 Linux 发行版上。例如在基于 Debian 的系统上，只需要通过以下这一条简单的命令就可以安装： 1sudo apt-get install git 安装完毕后，就可以使用 Git 来实施版本控制了（如下图）。 图 2：Git 已经安装，可以用于很多重要任务 Github 会要求用户创建一个帐户。用户可以免费使用 GitHub 来管理非商用项目，当然也可以使用 GitHub 的付费模式（更多相关信息，可以参阅价格矩阵）。 文本编辑器如果没有文本编辑器，在 Linux 上开发将会变得异常艰难。当然，文本编辑器之间孰优孰劣，具体还是要取决于开发者的需求。对于文本编辑器，有人可能会使用 vim、emacs 或 nano，也有人会使用带有 GUI 的编辑器。但由于重点在于开发，我们需要的是一种能够满足开发人员需求的工具。不过我首先要说，vim 对于开发人员来说确实是一个利器，但前提是要对 vim 非常熟悉，在这种前提下，vim 能够满足你的所有需求，甚至还能给你更好的体验。然而，对于一些开发者（尤其是刚开始接触 Linux 的新手）来说，这不仅难以帮助他们快速达成需求，甚至还会是一个需要逾越的障碍。考虑到这篇文章的目标是帮助 Linux 的新手（而不仅仅是为各种编辑器的死忠粉宣传他们拥护的编辑器），我更倾向于使用 GUI 编辑器。 就文本编辑器而论，选择 Bluefish 一般不会有错。 Bluefish 可以从大部分软件库中安装，它支持项目管理、远程文件多线程操作、搜索和替换、递归打开文件、侧边栏、集成 make/lint/weblint/xmllint、无限制撤销/重做、在线拼写检查、自动恢复、全屏编辑、语法高亮（如下图）、多种语言等等。 图 3：运行在 Ubuntu 18.04 上的 Bluefish IDE集成开发环境Integrated Development Environment（IDE）是包含一整套全面的工具、可以实现一站式功能的开发环境。 开发者除了可以使用 IDE 编写代码，还可以编写文档和构建软件。在 Linux 上也有很多适用的 IDE，其中 Geany 就包含在标准软件库中，它对用户非常友好，功能也相当强大。 Geany 具有语法高亮、代码折叠、自动完成，构建代码片段、自动关闭 XML 和 HTML 标签、调用提示、支持多种文件类型、符号列表、代码导航、构建编译，简单的项目管理和内置的插件系统等强大功能。 Geany 也能在系统上轻松安装，例如执行以下命令在基于 Debian 的 Linux 发行版上安装 Geany： 1sudo apt-get install geany 安装完毕后，就可以快速上手这个易用且强大的 IDE 了（如下图）。 图 4：Geany 可以作为你的 IDE 文本比较工具有时候会需要比较两个文件的内容来找到它们之间的不同之处，它们可能是同一文件的两个不同副本（有一个经过编译，而另一个没有）。这种情况下，你肯定不想要凭借肉眼来找出差异，而是想要使用像 Meld 这样的工具。 Meld 是针对开发者的文本比较和合并工具，可以使用 Meld 来发现两个文件之间的差异。虽然你可以使用命令行中的文本比较工具，但就效率而论，Meld 无疑更为优秀。 Meld 可以打开两个文件进行比较，并突出显示文件之间的差异之处。 Meld 还允许用户从两个文件的其中一方合并差异（下图显示了 Meld 同时打开两个文件）。 图 5： 以简单差异的模式比较两个文件 Meld 也可以通过大多数标准的软件库安装，在基于 Debian 的系统上，执行以下命令就可以安装： 1sudo apt-get install meld 高效地工作以上提到的五个工具除了帮助你完成工作，而且有助于提高效率。尽管适用于 Linux 开发者的工具有很多，但对于以上几个类别，你最好分别使用一个对应的工具。 via: https://www.linux.com/learn/intro-to-linux/2018/8/5-essential-tools-linux-development]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Linux 中使用 Wondershaper 限制网络带宽]]></title>
    <url>%2F2018%2F10%2F05%2FHow-To-Limit-Network-Bandwidth-In-Linux-Using-Wondershaper%2F</url>
    <content type="text"><![CDATA[以下内容将向你介绍如何轻松对网络带宽做出限制，并在类 Unix 操作系统中对网络流量进行优化。通过限制网络带宽，可以节省应用程序不必要的带宽消耗，包括软件包管理器（pacman、yum、apt）、web 浏览器、torrent 客户端、下载管理器等，并防止单个或多个用户滥用网络带宽。在本文当中，将会介绍 Wondershaper 这一个实用的命令行程序，这是我认为限制 Linux 系统 Internet 或本地网络带宽的最简单、最快捷的方式之一。 请注意，Wondershaper 只能限制本地网络接口的传入和传出流量，而不能限制路由器或调制解调器的接口。换句话说，Wondershaper 只会限制本地系统本身的网络带宽，而不会限制网络中的其它系统。因此 Wondershaper 主要用于限制本地系统中一个或多个网卡的带宽。 下面来看一下 Wondershaper 是如何优化网络流量的。 在 Linux 中使用 Wondershaper 限制网络带宽wondershaper 是用于显示系统网卡网络带宽的简单脚本。它使用了 iproute 的 tc 命令，但大大简化了操作过程。 安装 Wondershaper使用 git clone 克隆 Wondershaper 的版本库就可以安装最新版本： 1$ git clone https://github.com/magnific0/wondershaper.git 按照以下命令进入 wondershaper 目录并安装： 12$ cd wondershaper$ sudo make install 然后执行以下命令，可以让 wondershaper 在每次系统启动时都自动开始服务： 12$ sudo systemctl enable wondershaper.service$ sudo systemctl start wondershaper.service 如果你不强求安装最新版本，也可以使用软件包管理器（官方和非官方均可）来进行安装。 wondershaper 在 Arch 用户软件仓库（Arch User Repository，AUR）中可用，所以可以使用类似 yay 这些 AUR 辅助软件在基于 Arch 的系统中安装 wondershaper 。 1$ yay -S wondershaper-git 对于 Debian、Ubuntu 和 Linux Mint 可以使用以下命令安装： 1$ sudo apt-get install wondershaper 对于 Fedora 可以使用以下命令安装： 1$ sudo dnf install wondershaper 对于 RHEL、CentOS，只需要启用 EPEL 仓库，就可以使用以下命令安装： 12$ sudo yum install epel-release$ sudo yum install wondershaper 在每次系统启动时都自动启动 wondershaper 服务。 12$ sudo systemctl enable wondershaper.service$ sudo systemctl start wondershaper.service 用法首先需要找到网络接口的名称，通过以下几个命令都可以查询到网卡的详细信息： 123$ ip addr$ route$ ifconfig 在确定网卡名称以后，就可以按照以下的命令限制网络带宽： 1$ sudo wondershaper -a &lt;adapter&gt; -d &lt;rate&gt; -u &lt;rate&gt; 例如，如果网卡名称是 enp0s8，并且需要把上行、下行速率分别限制为 1024 Kbps 和 512 Kbps，就可以执行以下命令： 1$ sudo wondershaper -a enp0s8 -d 1024 -u 512 其中参数的含义是： -a：网卡名称 -d：下行带宽 -u：上行带宽 如果要对网卡解除网络带宽的限制，只需要执行： 1$ sudo wondershaper -c -a enp0s8 或者： 1$ sudo wondershaper -c enp0s8 如果系统中有多个网卡，为确保稳妥，需要按照上面的方法手动设置每个网卡的上行、下行速率。 如果你是通过 git clone 克隆 GitHub 版本库的方式安装 Wondershaper，那么在 /etc/conf.d/ 目录中会存在一个名为 wondershaper.conf 的配置文件，修改这个配置文件中的相应值（包括网卡名称、上行速率、下行速率），也可以设置上行或下行速率。 1234567891011121314$ sudo nano /etc/conf.d/wondershaper.conf[wondershaper]# Adapter#IFACE=&quot;eth0&quot;# Download rate in Kbps#DSPEED=&quot;2048&quot;# Upload rate in Kbps#USPEED=&quot;512&quot; Wondershaper 使用前： Wondershaper 使用后： 可以看到，使用 Wondershaper 限制网络带宽之后，下行速率与限制之前相比已经大幅下降。 执行以下命令可以查看更多相关信息。 1$ wondershaper -h 也可以查看 Wondershaper 的用户手册： 1$ man wondershaper 根据测试，Wondershaper 按照上面的方式可以有很好的效果。你可以试用一下，然后发表你的看法。 via: https://www.ostechnix.com/how-to-limit-network-bandwidth-in-linux-using-wondershaper/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在 Ubuntu Linux 中使用 RAR 文件]]></title>
    <url>%2F2018%2F10%2F03%2FHow-to-Use-RAR-files-in-Ubuntu-Linux%2F</url>
    <content type="text"><![CDATA[RAR 是一种非常好的归档文件格式。但相比之下 7-zip 能提供了更好的压缩率，并且默认情况下还可以在多个平台上轻松支持 Zip 文件。不过 RAR 仍然是最流行的归档格式之一。然而 Ubuntu 自带的归档管理器却不支持提取 RAR 文件，也不允许创建 RAR 文件。 办法总比问题多。只要安装 unrar 这款由 RARLAB 提供的免费软件，就能在 Ubuntu 上支持提取 RAR 文件了。你也可以安装 rar 试用版来创建和管理 RAR 文件。 提取 RAR 文件在未安装 unrar 的情况下，提取 RAR 文件会报出“未能提取”错误，就像下面这样（以 Ubuntu 18.04 为例）： 如果要解决这个错误并提取 RAR 文件，请按照以下步骤安装 unrar： 打开终端并输入： 1sudo apt-get install unrar 安装 unrar 后，直接输入 unrar 就可以看到它的用法以及如何使用这个工具处理 RAR 文件。 最常用到的功能是提取 RAR 文件。因此，可以通过右键单击 RAR 文件并执行提取，也可以借助此以下命令通过终端执行操作： 1unrar x FileName.rar 结果类似以下这样： 如果压缩文件没放在家目录中，就必须使用 cd 命令移动到目标目录下。例如 RAR 文件如果在 Music 目录下，只需要使用 cd Music 就可以移动到相应的目录，然后提取 RAR 文件。 创建和管理 RAR 文件 unrar 不允许创建 RAR 文件。因此还需要安装 rar 命令行工具才能创建 RAR 文件。 要创建 RAR 文件，首先需要通过以下命令安装 rar： 1sudo apt-get install rar 按照下面的命令语法创建 RAR 文件： 1rar a ArchiveName File_1 File_2 Dir_1 Dir_2 按照这个格式输入命令时，它会将目录中的每个文件添加到 RAR 文件中。如果需要某一个特定的文件，就要指定文件确切的名称或路径。 默认情况下，RAR 文件会放置在家目录中。 以类似的方式，可以更新或管理 RAR 文件。同样是使用以下的命令语法： 1rar u ArchiveName Filename 在终端输入 rar 就可以列出 RAR 工具的相关命令。 总结现在你已经知道如何在 Ubuntu 上管理 RAR 文件了，你会更喜欢使用 7-zip、Zip 或 Tar.xz 吗？ 欢迎在评论区中评论。 via: https://itsfoss.com/use-rar-ubuntu-linux/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>rar</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Linux 中安全且轻松地管理 Cron 定时任务]]></title>
    <url>%2F2018%2F10%2F03%2FHow-To-Easily-And-Safely-Manage-Cron-Jobs-In-Linux%2F</url>
    <content type="text"><![CDATA[在 Linux 中遇到计划任务的时候，你首先会想到的大概就是 Cron 定时任务了。Cron 定时任务能帮助你在类 Unix 操作系统中计划性地执行命令或者任务。也可以参考一下我们之前的一篇《关于 Cron 定时任务的新手指导》。对于有一定 Linux 经验的人来说，设置 Cron 定时任务不是什么难事，但对于新手来说就不一定了，他们在编辑 crontab 文件的时候不知不觉中犯的一些小错误，也有可能把整个 Cron 定时任务搞挂了。如果你在处理 Cron 定时任务的时候为了以防万一，可以尝试使用 Crontab UI，它是一个可以在类 Unix 操作系统上安全轻松管理 Cron 定时任务的 Web 页面工具。 Crontab UI 是使用 NodeJS 编写的自由开源软件。有了 Crontab UI，你在创建、删除和修改 Cron 定时任务的时候就不需要手工编辑 Crontab 文件了，只需要打开浏览器稍微操作一下，就能完成上面这些工作。你可以用 Crontab UI 轻松创建、编辑、暂停、删除、备份 Cron 定时任务，甚至还可以简单地做到导入、导出、部署其它机器上的 Cron 定时任务，它还支持错误日志、邮件发送和钩子。 安装 Crontab UI只需要一条命令就可以安装好 Crontab UI，但前提是已经安装好 NPM。如果还没有安装 NPM，可以参考《如何在 Linux 上安装 NodeJS》这篇文章。 执行这一条命令来安装 Crontab UI。 1$ npm install -g crontab-ui 就是这么简单，下面继续来看看在 Crontab UI 上如何管理 Cron 定时任务。 在 Linux 上安全轻松管理 Cron 定时任务执行这一条命令启动 Crontab UI： 1$ crontab-ui 你会看到这样的输出： 12Node version: 10.8.0Crontab UI is running at http://127.0.0.1:8000 首先在你的防火墙和路由器上放开 8000 端口，然后打开浏览器访问 &lt;http://127.0.0.1:8000&gt;。 注意，默认只有在本地才能访问到 Crontab UI 的控制台页面。但如果你想让 Crontab UI 使用系统的 IP 地址和自定义端口，也就是想让其它机器也访问到本地的 Crontab UI，你需要使用以下这个命令： 123$ HOST=0.0.0.0 PORT=9000 crontab-uiNode version: 10.8.0Crontab UI is running at http://0.0.0.0:9000 Crontab UI 就能够通过 &lt;http://IP-Address&gt;:9000 这样的 URL 被远程机器访问到了。 Crontab UI 的控制台页面长这样： 从上面的截图就可以看到，Crontab UI 的界面非常简洁，所有选项的含义都能不言自明。 在终端输入 Ctrl + C 就可以关闭 Crontab UI。 创建、编辑、运行、停止、删除 Cron 定时任务点击 “New”，输入 Cron 定时任务的信息并点击 “Save” 保存，就可以创建一个新的 Cron 定时任务了。 为 Cron 定时任务命名，这是可选的； 你想要执行的完整命令； 设定计划执行的时间。你可以按照启动、每时、每日、每周、每月、每年这些指标快速指定计划任务，也可以明确指定任务执行的具体时间。指定好计划时间后，“Jobs” 区域就会显示 Cron 定时任务的句式。 选择是否为某个 Cron 定时任务记录错误日志。 这是我的一个 Cron 定时任务样例。 如你所见，我设置了一个每月清理 pacman 缓存的 Cron 定时任务。你也可以设置多个 Cron 定时任务，都能在控制台页面看到。 如果你需要更改 Cron 定时任务中的某些参数，只需要点击 “Edit” 按钮并按照你的需求更改对应的参数。点击 “Run” 按钮可以立即执行 Cron 定时任务，点击 “Stop” 则可以立即停止 Cron 定时任务。如果想要查看某个 Cron 定时任务的详细日志，可以点击 “Log” 按钮。对于不再需要的 Cron 定时任务，就可以按 “Delete” 按钮删除。 备份 Cron 定时任务点击控制台页面的 “Backup” 按钮并确认，就可以备份所有 Cron 定时任务。 备份之后，一旦 Crontab 文件出现了错误，就可以使用备份来恢复了。 导入/导出其它机器上的 Cron 定时任务Crontab UI 还有一个令人注目的功能，就是导入、导出、部署其它机器上的 Cron 定时任务。如果同一个网络里的多台机器都需要执行同样的 Cron 定时任务，只需要点击 “Export” 按钮并选择文件的保存路径，所有的 Cron 定时任务都会导出到 crontab.db 文件中。 以下是 crontab.db 文件的内容： 12$ cat Downloads/crontab.db&#123;&quot;name&quot;:&quot;Remove Pacman Cache&quot;,&quot;command&quot;:&quot;rm -rf /var/cache/pacman&quot;,&quot;schedule&quot;:&quot;@monthly&quot;,&quot;stopped&quot;:false,&quot;timestamp&quot;:&quot;Thu Aug 23 2018 10:34:19 GMT+0000 (Coordinated Universal Time)&quot;,&quot;logging&quot;:&quot;true&quot;,&quot;mailing&quot;:&#123;&#125;,&quot;created&quot;:1535020459093,&quot;_id&quot;:&quot;lcVc1nSdaceqS1ut&quot;&#125; 导出成文件以后，你就可以把这个 crontab.db 文件放置到其它机器上并导入成 Cron 定时任务，而不需要在每一台主机上手动设置 Cron 定时任务。总之，在一台机器上设置完，导出，再导入到其他机器，就完事了。 在 Crontab 文件获取/保存 Cron 定时任务你可能在使用 Crontab UI 之前就已经使用 crontab 命令创建过 Cron 定时任务。如果是这样，你可以点击控制台页面上的 “Get from crontab” 按钮来获取已有的 Cron 定时任务。 同样地，你也可以使用 Crontab UI 来将新的 Cron 定时任务保存到 Crontab 文件中，只需要点击 “Save to crontab” 按钮就可以了。 管理 Cron 定时任务并没有想象中那么难，即使是新手使用 Crontab UI 也能轻松管理 Cron 定时任务。赶快开始尝试并发表一下你的看法吧。 via: https://www.ostechnix.com/how-to-easily-and-safely-manage-cron-jobs-in-linux/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>cron</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在 Linux 中查看进程占用的端口号]]></title>
    <url>%2F2018%2F10%2F02%2FHow-To-Find-Out-Which-Port-Number-A-Process-Is-Using-In-Linux%2F</url>
    <content type="text"><![CDATA[对于 Linux 系统管理员来说，清楚某个服务是否正确地绑定或监听某个端口，是至关重要的。如果你需要处理端口相关的问题，这篇文章可能会对你有用。 端口是 Linux 系统上特定进程之间逻辑连接的标识，包括物理端口和软件端口。由于 Linux 操作系统是一个软件，因此本文只讨论软件端口。软件端口始终与主机的 IP 地址和相关的通信协议相关联，因此端口常用于区分应用程序。大部分涉及到网络的服务都必须打开一个套接字来监听传入的网络请求，而每个服务都使用一个独立的套接字。 推荐阅读： 在 Linux 上查看进程 ID 的 4 种方法 在 Linux 上终止进程的 3 种方法 套接字是和 IP 地址、软件端口和协议结合起来使用的，而端口号对传输控制协议（TCP）和用户数据报协议（UDP）协议都适用，TCP 和 UDP 都可以使用 0 到 65535 之间的端口号进行通信。 以下是端口分配类别： 0 - 1023： 常用端口和系统端口 1024 - 49151： 软件的注册端口 49152 - 65535： 动态端口或私有端口 在 Linux 上的 /etc/services 文件可以查看到更多关于保留端口的信息。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# less /etc/services# /etc/services:# $Id: services,v 1.55 2013/04/14 ovasik Exp $## Network services, Internet style# IANA services version: last updated 2013-04-10## Note that it is presently the policy of IANA to assign a single well-known# port number for both TCP and UDP; hence, most entries here have two entries# even if the protocol doesn&apos;t support UDP operations.# Updated from RFC 1700, ``Assigned Numbers&apos;&apos; (October 1994). Not all ports# are included, only the more common ones.## The latest IANA port assignments can be gotten from# http://www.iana.org/assignments/port-numbers# The Well Known Ports are those from 0 through 1023.# The Registered Ports are those from 1024 through 49151# The Dynamic and/or Private Ports are those from 49152 through 65535## Each line describes one service, and is of the form:## service-name port/protocol [aliases ...] [# comment]tcpmux 1/tcp # TCP port service multiplexertcpmux 1/udp # TCP port service multiplexerrje 5/tcp # Remote Job Entryrje 5/udp # Remote Job Entryecho 7/tcpecho 7/udpdiscard 9/tcp sink nulldiscard 9/udp sink nullsystat 11/tcp userssystat 11/udp usersdaytime 13/tcpdaytime 13/udpqotd 17/tcp quoteqotd 17/udp quotemsp 18/tcp # message send protocol (historic)msp 18/udp # message send protocol (historic)chargen 19/tcp ttytst sourcechargen 19/udp ttytst sourceftp-data 20/tcpftp-data 20/udp# 21 is registered to ftp, but also used by fspftp 21/tcpftp 21/udp fsp fspdssh 22/tcp # The Secure Shell (SSH) Protocolssh 22/udp # The Secure Shell (SSH) Protocoltelnet 23/tcptelnet 23/udp# 24 - private mail systemlmtp 24/tcp # LMTP Mail Deliverylmtp 24/udp # LMTP Mail Delivery 可以使用以下六种方法查看端口信息。 ss：可以用于转储套接字统计信息。 netstat：可以显示打开的套接字列表。 lsof：可以列出打开的文件。 fuser：可以列出那些打开了文件的进程的进程 ID。 nmap：是网络检测工具和端口扫描程序。 systemctl：是 systemd 系统的控制管理器和服务管理器。 以下我们将找出 sshd 守护进程所使用的端口号。 方法 1：使用 ss 命令ss 一般用于转储套接字统计信息。它能够输出类似于 netstat 输出的信息，但它可以比其它工具显示更多的 TCP 信息和状态信息。 它还可以显示所有类型的套接字统计信息，包括 PACKET、TCP、UDP、DCCP、RAW、Unix 域等。 123# ss -tnlp | grep sshLISTEN 0 128 *:22 *:* users:((&quot;sshd&quot;,pid=997,fd=3))LISTEN 0 128 :::22 :::* users:((&quot;sshd&quot;,pid=997,fd=4)) 也可以使用端口号来检查。 123# ss -tnlp | grep &quot;:22&quot;LISTEN 0 128 *:22 *:* users:((&quot;sshd&quot;,pid=997,fd=3))LISTEN 0 128 :::22 :::* users:((&quot;sshd&quot;,pid=997,fd=4)) 方法 2：使用 netstat 命令netstat 能够显示网络连接、路由表、接口统计信息、伪装连接以及多播成员。 默认情况下，netstat 会列出打开的套接字。如果不指定任何地址族，则会显示所有已配置地址族的活动套接字。但 netstat 已经过时了，一般会使用 ss 来替代。 123# netstat -tnlp | grep sshtcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 997/sshdtcp6 0 0 :::22 :::* LISTEN 997/sshd 也可以使用端口号来检查。 123# netstat -tnlp | grep &quot;:22&quot;tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1208/sshdtcp6 0 0 :::22 :::* LISTEN 1208/sshd 方法 3：使用 lsof 命令lsof 能够列出打开的文件，并列出系统上被进程打开的文件的相关信息。 12345# lsof -i -P | grep sshCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 11584 root 3u IPv4 27625 0t0 TCP *:22 (LISTEN)sshd 11584 root 4u IPv6 27627 0t0 TCP *:22 (LISTEN)sshd 11592 root 3u IPv4 27744 0t0 TCP vps.2daygeek.com:ssh-&gt;103.5.134.167:49902 (ESTABLISHED) 也可以使用端口号来检查。 12345# lsof -i tcp:22COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsshd 1208 root 3u IPv4 20919 0t0 TCP *:ssh (LISTEN)sshd 1208 root 4u IPv6 20921 0t0 TCP *:ssh (LISTEN)sshd 11592 root 3u IPv4 27744 0t0 TCP vps.2daygeek.com:ssh-&gt;103.5.134.167:49902 (ESTABLISHED) 方法 4：使用 fuser 命令fuser 工具会将本地系统上打开了文件的进程的进程 ID 显示在标准输出中。 12345# fuser -v 22/tcp USER PID ACCESS COMMAND22/tcp: root 1208 F.... sshd root 12388 F.... sshd root 49339 F.... sshd 方法 5：使用 nmap 命令nmap（“Network Mapper”）是一款用于网络检测和安全审计的开源工具。它最初用于对大型网络进行快速扫描，但它对于单个主机的扫描也有很好的表现。 nmap 使用原始 IP 数据包来确定网络上可用的主机，这些主机的服务（包括应用程序名称和版本）、主机运行的操作系统（包括操作系统版本等信息）、正在使用的数据包过滤器或防火墙的类型，以及很多其它信息。 1234567891011# nmap -sV -p 22 localhostStarting Nmap 6.40 ( http://nmap.org ) at 2018-09-23 12:36 ISTNmap scan report for localhost (127.0.0.1)Host is up (0.000089s latency).Other addresses for localhost (not scanned): 127.0.0.1PORT STATE SERVICE VERSION22/tcp open ssh OpenSSH 7.4 (protocol 2.0)Service detection performed. Please report any incorrect results at http://nmap.org/submit/ .Nmap done: 1 IP address (1 host up) scanned in 0.44 seconds 方法 6：使用 systemctl 命令systemctl 是 systemd 系统的控制管理器和服务管理器。它取代了旧的 SysV 初始化系统管理，目前大多数现代 Linux 操作系统都采用了 systemd。 推荐阅读： chkservice – Linux 终端上的 systemd 单元管理工具 如何查看 Linux 系统上正在运行的服务 12345678910111213141516# systemctl status sshd● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) Active: active (running) since Sun 2018-09-23 02:08:56 EDT; 6h 11min ago Docs: man:sshd(8) man:sshd_config(5) Main PID: 11584 (sshd) CGroup: /system.slice/sshd.service └─11584 /usr/sbin/sshd -DSep 23 02:08:56 vps.2daygeek.com systemd[1]: Starting OpenSSH server daemon...Sep 23 02:08:56 vps.2daygeek.com sshd[11584]: Server listening on 0.0.0.0 port 22.Sep 23 02:08:56 vps.2daygeek.com sshd[11584]: Server listening on :: port 22.Sep 23 02:08:56 vps.2daygeek.com systemd[1]: Started OpenSSH server daemon.Sep 23 02:09:15 vps.2daygeek.com sshd[11589]: Connection closed by 103.5.134.167 port 49899 [preauth]Sep 23 02:09:41 vps.2daygeek.com sshd[11592]: Accepted password for root from 103.5.134.167 port 49902 ssh2 以上输出的内容显示了最近一次启动 sshd 服务时 ssh 服务的监听端口。但它不会将最新日志更新到输出中。 12345678910111213141516171819202122# systemctl status sshd● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) Active: active (running) since Thu 2018-09-06 07:40:59 IST; 2 weeks 3 days ago Docs: man:sshd(8) man:sshd_config(5) Main PID: 1208 (sshd) CGroup: /system.slice/sshd.service ├─ 1208 /usr/sbin/sshd -D ├─23951 sshd: [accepted] └─23952 sshd: [net]Sep 23 12:50:36 vps.2daygeek.com sshd[23909]: Invalid user pi from 95.210.113.142 port 51666Sep 23 12:50:36 vps.2daygeek.com sshd[23909]: input_userauth_request: invalid user pi [preauth]Sep 23 12:50:37 vps.2daygeek.com sshd[23911]: pam_unix(sshd:auth): check pass; user unknownSep 23 12:50:37 vps.2daygeek.com sshd[23911]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=95.210.113.142Sep 23 12:50:37 vps.2daygeek.com sshd[23909]: pam_unix(sshd:auth): check pass; user unknownSep 23 12:50:37 vps.2daygeek.com sshd[23909]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=95.210.113.142Sep 23 12:50:39 vps.2daygeek.com sshd[23911]: Failed password for invalid user pi from 95.210.113.142 port 51670 ssh2Sep 23 12:50:39 vps.2daygeek.com sshd[23909]: Failed password for invalid user pi from 95.210.113.142 port 51666 ssh2Sep 23 12:50:40 vps.2daygeek.com sshd[23911]: Connection closed by 95.210.113.142 port 51670 [preauth]Sep 23 12:50:40 vps.2daygeek.com sshd[23909]: Connection closed by 95.210.113.142 port 51666 [preauth] 大部分情况下，以上的输出不会显示进程的实际端口号。这时更建议使用以下这个 journalctl 命令检查日志文件中的详细信息。 1234567# journalctl | grep -i &quot;openssh\|sshd&quot;Sep 23 02:08:56 vps138235.vps.ovh.ca sshd[997]: Received signal 15; terminating.Sep 23 02:08:56 vps138235.vps.ovh.ca systemd[1]: Stopping OpenSSH server daemon...Sep 23 02:08:56 vps138235.vps.ovh.ca systemd[1]: Starting OpenSSH server daemon...Sep 23 02:08:56 vps138235.vps.ovh.ca sshd[11584]: Server listening on 0.0.0.0 port 22.Sep 23 02:08:56 vps138235.vps.ovh.ca sshd[11584]: Server listening on :: port 22.Sep 23 02:08:56 vps138235.vps.ovh.ca systemd[1]: Started OpenSSH server daemon. via: https://www.2daygeek.com/how-to-find-out-which-port-number-a-process-is-using-in-linux/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>端口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Linux 下截屏并编辑的最佳工具]]></title>
    <url>%2F2018%2F10%2F01%2F5-Ways-to-Take-Screenshot-in-Linux-GUI-and-Terminal%2F</url>
    <content type="text"><![CDATA[有几种获取屏幕截图并对其进行添加文字、箭头等编辑的方法，这里提及的的屏幕截图工具在 Ubuntu 和其它主流 Linux 发行版中都能够使用。 当我的主力操作系统从 Windows 转换到 Ubuntu 的时候，首要考虑的就是屏幕截图工具的可用性。尽管使用默认的键盘快捷键也可以获取屏幕截图，但如果使用屏幕截图工具，可以更方便地对屏幕截图进行编辑。 本文将会介绍在不适用第三方工具的情况下，如何通过系统自带的方法和工具获取屏幕截图，另外还会介绍一些可用于 Linux 的最佳截图工具。 方法 1：在 Linux 中截图的默认方式你想要截取整个屏幕？屏幕中的某个区域？某个特定的窗口？ 如果只需要获取一张屏幕截图，不对其进行编辑的话，那么键盘的默认快捷键就可以满足要求了。而且不仅仅是 Ubuntu ，绝大部分的 Linux 发行版和桌面环境都支持以下这些快捷键： PrtSc – 获取整个屏幕的截图并保存到 Pictures 目录。 Shift + PrtSc – 获取屏幕的某个区域截图并保存到 Pictures 目录。 Alt + PrtSc –获取当前窗口的截图并保存到 Pictures 目录。 Ctrl + PrtSc – 获取整个屏幕的截图并存放到剪贴板。 Shift + Ctrl + PrtSc – 获取屏幕的某个区域截图并存放到剪贴板。 Ctrl + Alt + PrtSc – 获取当前窗口的 截图并存放到剪贴板。 如上所述，在 Linux 中使用默认的快捷键获取屏幕截图是相当简单的。但如果要在不把屏幕截图导入到其它应用程序的情况下对屏幕截图进行编辑，还是使用屏幕截图工具比较方便。 方法 2：在 Linux 中使用 Flameshot 获取屏幕截图并编辑 功能概述： 注释 (高亮、标示、添加文本、框选) 图片模糊 图片裁剪 上传到 Imgur 用另一个应用打开截图 Flameshot 在去年发布到 GitHub，并成为一个引人注目的工具。 如果你需要的是一个能够用于标注、模糊、上传到 imgur 的新式截图工具，那么 Flameshot 是一个好的选择。 下面将会介绍如何安装 Flameshot 并根据你的偏好进行配置。 如果你用的是 Ubuntu，那么只需要在 Ubuntu 软件中心上搜索，就可以找到 Flameshot 进而完成安装了。要是你想使用终端来安装，可以执行以下命令： 1sudo apt install flameshot 如果你在安装过程中遇到问题，可以按照官方的安装说明进行操作。安装完成后，你还需要进行配置。尽管可以通过搜索来随时启动 Flameshot，但如果想使用 PrtSc 键触发启动，则需要指定对应的键盘快捷键。以下是相关配置步骤： 进入系统设置中的“键盘设置” 页面中会列出所有现有的键盘快捷键，拉到底部就会看见一个 “+” 按钮 点击 “+” 按钮添加自定义快捷键并输入以下两个字段： “名称”： 任意名称均可。 “命令”： /usr/bin/flameshot gui 最后将这个快捷操作绑定到 PrtSc 键上，可能会提示与系统的截图功能相冲突，但可以忽略掉这个警告。 配置之后，你的自定义快捷键页面大概会是以下这样： 将键盘快捷键映射到 Flameshot 方法 3：在 Linux 中使用 Shutter 获取屏幕截图并编辑 功能概述： 注释 (高亮、标示、添加文本、框选) 图片模糊 图片裁剪 上传到图片网站 Shutter 是一个对所有主流 Linux 发行版都适用的屏幕截图工具。尽管最近已经不太更新了，但仍然是操作屏幕截图的一个优秀工具。 在使用过程中可能会遇到这个工具的一些缺陷。Shutter 在任何一款最新的 Linux 发行版上最常见的问题就是由于缺少了任务栏上的程序图标，导致默认禁用了编辑屏幕截图的功能。 对于这个缺陷，还是有解决方案的。你只需要跟随我们的教程在 Shutter 中修复这个禁止编辑选项并将程序图标在任务栏上显示出来。问题修复后，就可以使用 Shutter 来快速编辑屏幕截图了。 同样地，在软件中心搜索也可以找到进而安装 Shutter，也可以在基于 Ubuntu 的发行版中执行以下命令使用命令行安装： 1sudo apt install shutter 类似 Flameshot，你可以通过搜索 Shutter 手动启动它，也可以按照相似的方式设置自定义快捷方式以 PrtSc 键唤起 Shutter。 如果要指定自定义键盘快捷键，只需要执行以下命令： 1shutter -f 方法 4：在 Linux 中使用 GIMP 获取屏幕截图 功能概述： 高级图像编辑功能（缩放、添加滤镜、颜色校正、添加图层、裁剪等） 截取某一区域的屏幕截图 如果需要对屏幕截图进行一些预先编辑，GIMP 是一个不错的选择。 通过软件中心可以安装 GIMP。如果在安装时遇到问题，可以参考其官方网站的安装说明。 要使用 GIMP 获取屏幕截图，需要先启动程序，然后通过 “File-&gt; Create-&gt; Screenshot” 导航。 打开 Screenshot 选项后，会看到几个控制点来控制屏幕截图范围。点击 “Snap” 截取屏幕截图，图像将自动显示在 GIMP 中可供编辑。 方法 5：在 Linux 中使用命令行工具获取屏幕截图这一节内容仅适用于终端爱好者。如果你也喜欢使用终端，可以使用 “GNOME 截图工具”或 “ImageMagick” 或 “Deepin Scrot”，大部分流行的 Linux 发行版中都自带这些工具。 要立即获取屏幕截图，可以执行以下命令： GNOME 截图工具（可用于 GNOME 桌面）1gnome-screenshot GNOME 截图工具是使用 GNOME 桌面的 Linux 发行版中都自带的一个默认工具。如果需要延时获取屏幕截图，可以执行以下命令（这里的 5 是需要延迟的秒数）： 1gnome-screenshot -d -5 ImageMagick如果你的操作系统是 Ubuntu、Mint 或其它流行的 Linux 发行版，一般会自带 ImageMagick 这个工具。如果没有这个工具，也可以按照官方安装说明使用安装源来安装。你也可以在终端中执行这个命令： 1sudo apt-get install imagemagick 安装完成后，执行下面的命令就可以获取到屏幕截图（截取整个屏幕）： 1import -window root image.png 这里的 “image.png” 就是屏幕截图文件保存的名称。 要获取屏幕一个区域的截图，可以执行以下命令: 1import image.png Deepin ScrotDeepin Scrot 是基于终端的一个较新的截图工具。和前面两个工具类似，一般自带于 Linux 发行版中。如果需要自行安装，可以执行以下命令： 1sudo apt-get install scrot 安装完成后，使用下面这些命令可以获取屏幕截图。 获取整个屏幕的截图： 1scrot myimage.png 获取屏幕某一区域的截图： 1scrot -s myimage.png 总结以上是一些在 Linux 上的优秀截图工具。当然还有很多截图工具没有提及（例如用于 KDE 发行版的 Spectacle），但相比起来还是上面几个工具更为好用。 如果你有比文章中提到的更好的截图工具，欢迎讨论！ via: https://itsfoss.com/take-screenshot-linux/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>截屏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何让 Ping 的输出更简单易读]]></title>
    <url>%2F2018%2F09%2F30%2FMake-The-Output-Of-Ping-Command-Prettier-And-Easier-To-Read%2F</url>
    <content type="text"><![CDATA[众所周知，ping 命令可以用来检查目标主机是否可达。使用 ping 命令的时候，会发送一个 ICMP Echo 请求，通过目标主机的响应与否来确定目标主机的状态。如果你经常使用 ping 命令，你可以尝试一下 prettyping。Prettyping 只是将一个标准的 ping 工具增加了一层封装，在运行标准 ping 命令的同时添加了颜色和 unicode 字符解析输出，所以它的输出更漂亮紧凑、清晰易读。它是用 bash 和 awk 编写的自由开源工具，支持大部分类 Unix 操作系统，包括 GNU/Linux、FreeBSD 和 Mac OS X。Prettyping 除了美化 ping 命令的输出，还有很多值得注意的功能。 检测丢失的数据包并在输出中标记出来。 显示实时数据。每次收到响应后，都会更新统计数据，而对于普通 ping 命令，只会在执行结束后统计。 可以灵活处理“未知信息”（例如错误信息），而不搞乱输出结果。 能够避免输出重复的信息。 兼容常用的 ping 工具命令参数。 能够由普通用户执行。 可以将输出重定向到文件中。 不需要安装，只需要下载二进制文件，赋予可执行权限即可执行。 快速且轻巧。 输出结果清晰直观。 安装 Prettyping如上所述，Prettyping 是一个绿色软件，不需要任何安装，只要使用以下命令下载 Prettyping 二进制文件： 1$ curl -O https://raw.githubusercontent.com/denilsonsa/prettyping/master/prettyping 将二进制文件放置到 $PATH（例如 /usr/local/bin）中： 1$ sudo mv prettyping /usr/local/bin 然后对其赋予可执行权限： 1$ sudo chmod +x /usr/local/bin/prettyping 就可以使用了。 让 ping 的输出清晰易读安装完成后，通过 prettyping 来 ping 任何主机或 IP 地址，就可以以图形方式查看输出。 1$ prettyping ostechnix.com 输出效果大概会是这样： 如果你不带任何参数执行 prettyping，它就会一直运行直到被 ctrl + c 中断。 由于 Prettyping 只是一个对普通 ping 命令的封装，所以常用的 ping 参数也是有效的。例如使用 -c 5 来指定 ping 一台主机的 5 次： 1$ prettyping -c 5 ostechnix.com Prettyping 默认会使用彩色输出，如果你不喜欢彩色的输出，可以加上 --nocolor 参数： 1$ prettyping --nocolor ostechnix.com 同样的，也可以用 --nomulticolor 参数禁用多颜色支持： 1$ prettyping --nomulticolor ostechnix.com 使用 --nounicode 参数禁用 unicode 字符： 如果你的终端不支持 UTF-8，或者无法修复系统中的 unicode 字体，只需要加上 --nounicode 参数就能轻松解决。 Prettyping 支持将输出的内容重定向到文件中，例如执行以下这个命令会将 prettyping ostechnix.com 的输出重定向到 ostechnix.txt 中： 1$ prettyping ostechnix.com | tee ostechnix.txt Prettyping 还有很多选项帮助你完成各种任务，例如： 启用/禁用延时图例（默认启用） 强制按照终端的格式输出（默认自动） 在统计数据中统计最后的 n 次 ping（默认 60 次） 覆盖对终端尺寸的自动检测 指定 awk 解释器路径（默认：awk） 指定 ping 工具路径（默认：ping） 查看帮助文档可以了解更多： 1$ prettyping --help 尽管 Prettyping 没有添加任何额外功能，但我个人喜欢它的这些优点： 实时统计 —— 可以随时查看所有实时统计信息，标准 ping 命令只会在命令执行结束后才显示统计信息。 紧凑的显示 —— 可以在终端看到更长的时间跨度。 检测丢失的数据包并显示出来。 如果你一直在寻找可视化显示 ping 命令输出的工具，那么 Prettyping 肯定会有所帮助。尝试一下，你不会失望的。 via: https://www.ostechnix.com/prettyping-make-the-output-of-ping-command-prettier-and-easier-to-read/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>ping</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让你提高效率的 Linux 技巧]]></title>
    <url>%2F2018%2F09%2F29%2FLinux-tricks-that-can-save-you-time-and-trouble%2F</url>
    <content type="text"><![CDATA[想要在 Linux 命令行工作中提高效率，你需要使用一些技巧。 巧妙的 Linux 命令行技巧能让你节省时间、避免出错，还能让你记住和复用各种复杂的命令，专注在需要做的事情本身，而不是你要怎么做。以下介绍一些好用的命令行技巧。 命令编辑如果要对一个已输入的命令进行修改，可以使用 ^a（ctrl + a）或 ^e（ctrl + e）将光标快速移动到命令的开头或命令的末尾。 还可以使用 ^ 字符实现对上一个命令的文本替换并重新执行命令，例如 ^before^after^ 相当于把上一个命令中的 before 替换为 after 然后重新执行一次。 123456789101112$ eho hello world &lt;== 错误的命令Command &apos;eho&apos; not found, did you mean: command &apos;echo&apos; from deb coreutils command &apos;who&apos; from deb coreutilsTry: sudo apt install &lt;deb name&gt;$ ^e^ec^ &lt;== 替换echo hello worldhello world 使用远程机器的名称登录到机器上如果使用命令行登录其它机器上，可以考虑添加别名。在别名中，可以填入需要登录的用户名（与本地系统上的用户名可能相同，也可能不同）以及远程机器的登录信息。例如使用 server_name =&#39;ssh -v -l username IP-address&#39; 这样的别名命令： 1$ alias butterfly=”ssh -v -l jdoe 192.168.0.11” 也可以通过在 /etc/hosts 文件中添加记录或者在 DNS 服务器中加入解析记录来把 IP 地址替换成易记的机器名称。 执行 alias 命令可以列出机器上已有的别名。 123456789101112$ aliasalias butterfly=&apos;ssh -v -l jdoe 192.168.0.11&apos;alias c=&apos;clear&apos;alias egrep=&apos;egrep --color=auto&apos;alias fgrep=&apos;fgrep --color=auto&apos;alias grep=&apos;grep --color=auto&apos;alias l=&apos;ls -CF&apos;alias la=&apos;ls -A&apos;alias list_repos=&apos;grep ^[^#] /etc/apt/sources.list /etc/apt/sources.list.d/*&apos;alias ll=&apos;ls -alF&apos;alias ls=&apos;ls --color=auto&apos;alias show_dimensions=&apos;xdpyinfo | grep &apos;\&apos;&apos;dimensions:&apos;\&apos;&apos;&apos; 只要将新的别名添加到 ~/.bashrc 或类似的文件中，就可以让别名在每次登录后都能立即生效。 冻结、解冻终端界面^s（ctrl + s）将通过执行流量控制命令 XOFF 来停止终端输出内容，这会对 PuTTY 会话和桌面终端窗口产生影响。如果误输入了这个命令，可以使用 ^q（ctrl + q）让终端重新响应。所以只需要记住 ^q 这个组合键就可以了，毕竟这种情况并不多见。 复用命令Linux 提供了很多让用户复用命令的方法，其核心是通过历史缓冲区收集执行过的命令。复用命令的最简单方法是输入 ! 然后接最近使用过的命令的开头字母；当然也可以按键盘上的向上箭头，直到看到要复用的命令，然后按回车键。还可以先使用 history 显示命令历史，然后输入 ! 后面再接命令历史记录中需要复用的命令旁边的数字。 123!! &lt;== 复用上一条命令!ec &lt;== 复用上一条以 “ec” 开头的命令!76 &lt;== 复用命令历史中的 76 号命令 查看日志文件并动态显示更新内容使用形如 tail -f /var/log/syslog 的命令可以查看指定的日志文件，并动态显示文件中增加的内容，需要监控向日志文件中追加内容的的事件时相当有用。这个命令会输出文件内容的末尾部分，并逐渐显示新增的内容。 12345678910$ tail -f /var/log/auth.logSep 17 09:41:01 fly CRON[8071]: pam_unix(cron:session): session closed for user smmspSep 17 09:45:01 fly CRON[8115]: pam_unix(cron:session): session opened for user rootSep 17 09:45:01 fly CRON[8115]: pam_unix(cron:session): session closed for user rootSep 17 09:47:00 fly sshd[8124]: Accepted password for shs from 192.168.0.22 port 47792Sep 17 09:47:00 fly sshd[8124]: pam_unix(sshd:session): session opened for user shs bySep 17 09:47:00 fly systemd-logind[776]: New session 215 of user shs.Sep 17 09:55:01 fly CRON[8208]: pam_unix(cron:session): session opened for user rootSep 17 09:55:01 fly CRON[8208]: pam_unix(cron:session): session closed for user root &lt;== 等待显示追加的内容 寻求帮助对于大多数 Linux 命令，都可以通过在输入命令后加上选项 --help 来获得这个命令的作用、用法以及它的一些相关信息。除了 man 命令之外， --help 选项可以让你在不使用所有扩展选项的情况下获取到所需要的内容。 123456789101112131415161718$ mkdir --helpUsage: mkdir [OPTION]... DIRECTORY...Create the DIRECTORY(ies), if they do not already exist.Mandatory arguments to long options are mandatory for short options too. -m, --mode=MODE set file mode (as in chmod), not a=rwx - umask -p, --parents no error if existing, make parent directories as needed -v, --verbose print a message for each created directory -Z set SELinux security context of each created directory to the default type --context[=CTX] like -Z, or if CTX is specified then set the SELinux or SMACK security context to CTX --help display this help and exit --version output version information and exitGNU coreutils online help: &lt;http://www.gnu.org/software/coreutils/&gt;Full documentation at: &lt;http://www.gnu.org/software/coreutils/mkdir&gt;or available locally via: info &apos;(coreutils) mkdir invocation&apos; 谨慎删除文件如果要谨慎使用 rm 命令，可以为它设置一个别名，在删除文件之前需要进行确认才能删除。有些系统管理员会默认使用这个别名，对于这种情况，你可能需要看看下一个技巧。 1$ rm -i &lt;== 请求确认 关闭别名你可以使用 unalias 命令以交互方式禁用别名。它不会更改别名的配置，而仅仅是暂时禁用，直到下次登录或重新设置了这一个别名才会重新生效。 1$ unalias rm 如果已经将 rm -i 默认设置为 rm 的别名，但你希望在删除文件之前不必进行确认，则可以将 unalias 命令放在一个启动文件（例如 ~/.bashrc）中。 使用 sudo如果你经常在只有 root 用户才能执行的命令前忘记使用 sudo，这里有两个方法可以解决。一是利用命令历史记录，可以使用 sudo !!（使用 !! 来运行最近的命令，并在前面添加 sudo）来重复执行，二是设置一些附加了所需 sudo 的命令别名。 1$ alias update=’sudo apt update’ 更复杂的技巧有时命令行技巧并不仅仅是一个别名。毕竟，别名能帮你做的只有替换命令以及增加一些命令参数，节省了输入的时间。但如果需要比别名更复杂功能，可以通过编写脚本、向 .bashrc 或其他启动文件添加函数来实现。例如，下面这个函数会在创建一个目录后进入到这个目录下。在设置完毕后，执行 source .bashrc，就可以使用 md temp 这样的命令来创建目录立即进入这个目录下。 1md () &#123; mkdir -p &quot;$@&quot; &amp;&amp; cd &quot;$1&quot;; &#125; 总结使用 Linux 命令行是在 Linux 系统上工作最有效也最有趣的方法，但配合命令行技巧和巧妙的别名可以让你获得更好的体验。 via: https://www.networkworld.com/article/3305811/linux/linux-tricks-that-even-you-can-love.html]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让 Python 代码更易维护的七种武器]]></title>
    <url>%2F2018%2F09%2F29%2F7-Python-libraries-for-more-maintainable-code%2F</url>
    <content type="text"><![CDATA[检查你的代码的质量，通过这些外部库使其更易维护。 可读性很重要。 — Python 之禅The Zen of Python，Tim Peters 随着软件项目进入“维护模式”，对可读性和编码标准的要求很容易落空（甚至从一开始就没有建立过那些标准）。然而，在代码库中保持一致的代码风格和测试标准能够显著减轻维护的压力，也能确保新的开发者能够快速了解项目的情况，同时能更好地全程保持应用程序的质量。 使用外部库来检查代码的质量不失为保护项目未来可维护性的一个好方法。以下会推荐一些我们最喜爱的检查代码（包括检查 PEP 8 和其它代码风格错误）的库，用它们来强制保持代码风格一致，并确保在项目成熟时有一个可接受的测试覆盖率。 检查你的代码风格PEP 8 是 Python 代码风格规范，它规定了类似行长度、缩进、多行表达式、变量命名约定等内容。尽管你的团队自身可能也会有稍微不同于 PEP 8 的代码风格规范，但任何代码风格规范的目标都是在代码库中强制实施一致的标准，使代码的可读性更强、更易于维护。下面三个库就可以用来帮助你美化代码。 1、 PylintPylint 是一个检查违反 PEP 8 规范和常见错误的库。它在一些流行的编辑器和 IDE 中都有集成，也可以单独从命令行运行。 执行 pip install pylint 安装 Pylint 。然后运行 pylint [options] path/to/dir 或者 pylint [options] path/to/module.py 就可以在命令行中使用 Pylint，它会向控制台输出代码中违反规范和出现错误的地方。 你还可以使用 pylintrc 配置文件来自定义 Pylint 对哪些代码错误进行检查。 2、 Flake8Flake8 是“将 PEP 8、Pyflakes（类似 Pylint）、McCabe（代码复杂性检查器）和第三方插件整合到一起，以检查 Python 代码风格和质量的一个 Python 工具”。 执行 pip install flake8 安装 flake8 ，然后执行 flake8 [options] path/to/dir 或者 flake8 [options] path/to/module.py 可以查看报出的错误和警告。 和 Pylint 类似，Flake8 允许通过配置文件来自定义检查的内容。它有非常清晰的文档，包括一些有用的提交钩子，可以将自动检查代码纳入到开发工作流程之中。 Flake8 也可以集成到一些流行的编辑器和 IDE 当中，但在文档中并没有详细说明。要将 Flake8 集成到喜欢的编辑器或 IDE 中，可以搜索插件（例如 Sublime Text 的 Flake8 插件）。 3、 IsortIsort 这个库能将你在项目中导入的库按字母顺序排序，并将其正确划分为不同部分（例如标准库、第三方库、自建的库等）。这样提高了代码的可读性，并且可以在导入的库较多的时候轻松找到各个库。 执行 pip install isort 安装 isort，然后执行 isort path/to/module.py 就可以运行了。文档中还提供了更多的配置项，例如通过配置 .isort.cfg 文件来决定 isort 如何处理一个库的多行导入。 和 Flake8、Pylint 一样，isort 也提供了将其与流行的编辑器和 IDE 集成的插件。 分享你的代码风格每次文件发生变动之后都用命令行手动检查代码是一件痛苦的事，你可能也不太喜欢通过运行 IDE 中某个插件来实现这个功能。同样地，你的同事可能会用不同的代码检查方式，也许他们的编辑器中也没有那种插件，甚至你自己可能也不会严格检查代码和按照警告来更正代码。总之，你分享出来的代码库将会逐渐地变得混乱且难以阅读。 一个很好的解决方案是使用一个库，自动将代码按照 PEP 8 规范进行格式化。我们推荐的三个库都有不同的自定义级别来控制如何格式化代码。其中有一些设置较为特殊，例如 Pylint 和 Flake8 ，你需要先行测试，看看是否有你无法忍受但又不能修改的默认配置。 4、 Autopep8Autopep8 可以自动格式化指定的模块中的代码，包括重新缩进行、修复缩进、删除多余的空格，并重构常见的比较错误（例如布尔值和 None 值）。你可以查看文档中完整的更正列表。 运行 pip install --upgrade autopep8 安装 Autopep8。然后执行 autopep8 --in-place --aggressive --aggressive &lt;filename&gt; 就可以重新格式化你的代码。aggressive 选项的数量表示 Auotopep8 在代码风格控制上有多少控制权。在这里可以详细了解 aggressive 选项。 5、 YapfYapf 是另一种有自己的配置项列表的重新格式化代码的工具。它与 Autopep8 的不同之处在于它不仅会指出代码中违反 PEP 8 规范的地方，还会对没有违反 PEP 8 但代码风格不一致的地方重新格式化，旨在令代码的可读性更强。 执行 pip install yapf 安装 Yapf，然后执行 yapf [options] path/to/dir 或 yapf [options] path/to/module.py 可以对代码重新格式化。定制选项的完整列表在这里。 6、 BlackBlack 在代码检查工具当中算是比较新的一个。它与 Autopep8 和 Yapf 类似，但限制较多，没有太多的自定义选项。这样的好处是你不需要去决定使用怎么样的代码风格，让 Black 来给你做决定就好。你可以在这里查阅 Black 有限的自定义选项以及如何在配置文件中对其进行设置。 Black 依赖于 Python 3.6+，但它可以格式化用 Python 2 编写的代码。执行 pip install black 安装 Black，然后执行 black path/to/dir 或 black path/to/module.py 就可以使用 Black 优化你的代码。 检查你的测试覆盖率如果你正在进行编写测试，你需要确保提交到代码库的新代码都已经测试通过，并且不会降低测试覆盖率。虽然测试覆盖率不是衡量测试有效性和充分性的唯一指标，但它是确保项目遵循基本测试标准的一种方法。对于计算测试覆盖率，我们推荐使用 Coverage 这个库。 7、 CoverageCoverage 有数种显示测试覆盖率的方式，包括将结果输出到控制台或 HTML 页面，并指出哪些具体哪些地方没有被覆盖到。你可以通过配置文件自定义 Coverage 检查的内容，让你更方便使用。 执行 pip install coverage 安装 Converage 。然后执行 coverage [path/to/module.py] [args] 可以运行程序并查看输出结果。如果要查看哪些代码行没有被覆盖，执行 coverage report -m 即可。 持续集成工具持续集成Continuous integration（CI）是在合并和部署代码之前自动检查代码风格错误和测试覆盖率最小值的过程。很多免费或付费的工具都可以用于执行这项工作，具体的过程不在本文中赘述，但 CI 过程是令代码更易读和更易维护的重要步骤，关于这一部分可以参考 Travis CI 和 Jenkins。 以上这些只是用于检查 Python 代码的各种工具中的其中几个。如果你有其它喜爱的工具，欢迎在评论中分享。 via: https://opensource.com/article/18/7/7-python-libraries-more-maintainable-code]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 top 命令了解 Fedora 的内存使用情况]]></title>
    <url>%2F2018%2F09%2F26%2FUnderstand-Fedora-memory-usage-with-top%2F</url>
    <content type="text"><![CDATA[如果你使用过 top 命令来查看 Fedora 系统中的内存使用情况，你可能会惊讶，看起来消耗的数量比系统可用的内存更多。下面会详细介绍内存使用情况以及如何理解这些数据。 内存实际使用情况操作系统对内存的使用方式并不是太通俗易懂。事实上，其背后有很多不为人知的巧妙技术在发挥着作用。通过这些方式，可以在无需用户干预的情况下，让操作系统更有效地使用内存。 大多数应用程序都不是系统自带的，但每个应用程序都依赖于安装在系统中的库中的一些函数集。在 Fedora 中，RPM 包管理系统能够确保在安装应用程序时也会安装所依赖的库。 当应用程序运行时，操作系统并不需要将它要用到的所有信息都加载到物理内存中。而是会为存放代码的存储空间构建一个映射，称为虚拟内存。操作系统只把需要的部分加载到内存中，当某一个部分不再需要后，这一部分内存就会被释放掉。 这意味着应用程序可以映射大量的虚拟内存，而使用较少的系统物理内存。特殊情况下，映射的虚拟内存甚至可以比系统实际可用的物理内存更多！而且在操作系统中这种情况也并不少见。 另外，不同的应用程序可能会对同一个库都有依赖。Fedora 中的 Linux 内核通常会在各个应用程序之间共享内存，而不需要为不同应用分别加载同一个库的多个副本。类似地，对于同一个应用程序的不同实例也是采用这种方式共享内存。 如果不首先了解这些细节，top 命令显示的数据可能会让人摸不着头脑。下面就举例说明如何正确查看内存使用量。 使用 top 命令查看内存使用量如果你还没有使用过 top 命令，可以打开终端直接执行查看。使用 Shift + M 可以按照内存使用量来进行排序。下图是在 Fedora Workstation 中执行的结果，在你的机器上显示的结果可能会略有不同： 主要通过以下三列来查看内存使用情况：VIRT、RES 和 SHR。目前以 KB 为单位显示相关数值。 VIRT 列代表该进程映射的虚拟virtual内存。如上所述，虚拟内存不是实际消耗的物理内存。例如， GNOME Shell 进程 gnome-shell 实际上没有消耗超过 3.1 GB 的物理内存，但它对很多更低或更高级的库都有依赖，系统必须对每个库都进行映射，以确保在有需要时可以加载这些库。 RES 列代表应用程序消耗了多少实际（驻留resident）内存。对于 GNOME Shell 大约是 180788 KB。例子中的系统拥有大约 7704 MB 的物理内存，因此内存使用率显示为 2.3％。 但根据 SHR 列显示，其中至少有 88212 KB 是共享shared内存，这部分内存可能是其它应用程序也在使用的库函数。这意味着 GNOME Shell 本身大约有 92 MB 内存不与其他进程共享。需要注意的是，上述例子中的其它程序也共享了很多内存。在某些应用程序中，共享内存在内存使用量中会占很大的比例。 值得一提的是，有时进程之间通过内存通信，这些内存也是共享的，但 top 这样的工具却不一定能检测到，所以以上的说明也不一定准确。 关于交换分区系统还可以通过交换分区来存储数据（例如硬盘），但读写的速度相对较慢。当物理内存渐渐用满，操作系统就会查找内存中暂时不会使用的部分，将其写出到交换区域等待需要的时候使用。 因此，如果交换内存的使用量一直偏高，表明系统的物理内存已经供不应求了。有时候一个不正常的应用也有可能导致出现这种情况，但如果这种现象经常出现，就需要考虑提升物理内存或者限制某些程序的运行了。 感谢 Stig Nygaard 在 Flickr 上提供的图片（CC BY 2.0）。 via: https://fedoramagazine.org/understand-fedora-memory-usage-top/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>top</tag>
        <tag>内存</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 NetworkManager 随机化你的 MAC 地址]]></title>
    <url>%2F2018%2F09%2F19%2FRandomize-your-MAC-address-using-NetworkManager%2F</url>
    <content type="text"><![CDATA[今时今日，无论在家里的沙发上，还是在外面的咖啡厅，只要打开笔记本电脑，连上 Wi-Fi，就能通过网络与外界保持联系。但现在的 Wi-Fi 热点们大都能够通过每张网卡对应的唯一 MAC 地址来追踪你的设备。下面就来看一下如何避免被追踪。 现在很多人已经开始注重个人隐私这个问题。个人隐私问题并不仅仅指防止他人能够访问到你电脑上的私有内容（这又是另一个问题了），而更多的是指可追踪性legibility，也就是是否能够被轻易地统计和追踪到。大家都应该对此更加重视。同时，这方面的底线是，服务提供者在得到了用户的授权后才能对用户进行追踪，例如机场的计时 Wi-Fi 只有在用户授权后才能够使用。 因为固定的 MAC 地址能被轻易地追踪到，所以应该定时进行更换，随机的 MAC 地址是一个好的选择。由于 MAC 地址一般只在局域网内使用，因此随机的 MAC 地址也不大会产生冲突。 配置 NetworkManager要将随机的 MAC 地址默认地用于所有的 Wi-Fi 连接，需要创建 /etc/NetworkManager/conf.d/00-macrandomize.conf 这个文件： 1234567[device]wifi.scan-rand-mac-address=yes[connection]wifi.cloned-mac-address=stableethernet.cloned-mac-address=stableconnection.stable-id=$&#123;CONNECTION&#125;/$&#123;BOOT&#125; 然后重启 NetworkManager ： 1systemctl restart NetworkManager 以上配置文件中，将 cloned-mac-address 的值设置为 stable 就可以在每次 NetworkManager 激活连接的时候都生成相同的 MAC 地址，但连接时使用不同的 MAC 地址。如果要在每次激活连接时也获得随机的 MAC 地址，需要将 cloned-mac-address 的值设置为 random。 设置为 stable 可以从 DHCP 获取相同的 IP 地址，也可以让 Wi-Fi 的强制主页captive portal根据 MAC 地址记住你的登录状态。如果设置为 random ，在每次连接的时候都需要重新认证（或者点击“我同意”），在使用机场 Wi-Fi 的时候会需要到这种 random 模式。可以在这篇 NetworkManager 的博客文章中参阅到有关使用 nmcli 从终端配置特定连接的详细说明。 使用 ip link 命令可以查看当前的 MAC 地址，MAC 地址将会显示在 ether 一词的后面。 1234567$ ip link1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:002: enp2s0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc fq_codel state DOWN mode DEFAULT group default qlen 1000 link/ether 52:54:00:5f:d5:4e brd ff:ff:ff:ff:ff:ff3: wlp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP mode DORMANT group default qlen 1000 link/ether 52:54:00:03:23:59 brd ff:ff:ff:ff:ff:ff 什么时候不能随机化 MAC 地址当然，在某些情况下确实需要能被追踪到。例如在家用网络中，可能需要将路由器配置为对电脑分配一致的 IP 地址以进行端口转发；再例如公司的雇主可能需要根据 MAC 地址来提供 Wi-Fi 服务，这时候就需要进行追踪。要更改特定的 Wi-Fi 连接，请使用 nmcli 查看 NetworkManager 连接并显示当前设置： 123456789$ nmcli c | grep wifiAmtrak_WiFi 5f4b9f75-9e41-47f8-8bac-25dae779cd87 wifi -- StaplesHotspot de57940c-32c2-468b-8f96-0a3b9a9b0a5e wifi -- MyHome e8c79829-1848-4563-8e44-466e14a3223d wifi wlp1s0 ...$ nmcli c show 5f4b9f75-9e41-47f8-8bac-25dae779cd87 | grep cloned802-11-wireless.cloned-mac-address: --$ nmcli c show e8c79829-1848-4563-8e44-466e14a3223d | grep cloned802-11-wireless.cloned-mac-address: stable 这个例子在 Amtrak 使用完全随机 MAC 地址（使用默认配置）和 MyHome 的永久 MAC 地址（使用 stable 配置）。永久 MAC 地址是在硬件生产的时候分配到网络接口上的，网络管理员能够根据永久 MAC 地址来查看设备的制造商 ID。 更改配置并重新连接活动的接口： 123456$ nmcli c modify 5f4b9f75-9e41-47f8-8bac-25dae779cd87 802-11-wireless.cloned-mac-address random$ nmcli c modify e8c79829-1848-4563-8e44-466e14a3223d 802-11-wireless.cloned-mac-address permanent$ nmcli c down e8c79829-1848-4563-8e44-466e14a3223d$ nmcli c up e8c79829-1848-4563-8e44-466e14a3223d$ ip link... 你还可以安装 NetworkManager-tui ，就可以通过可视化界面菜单来编辑连接。 总结当你走在路上时，你要留意周围的环境，并警惕可能的危险。同样，在使用公共互联网资源时也要注意你自己的可追踪性。 via: https://fedoramagazine.org/randomize-mac-address-nm/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Mac</tag>
        <tag>Wi-Fi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python re.findall() 中的关于括号的坑]]></title>
    <url>%2F2018%2F08%2F11%2Fa-pitfall-of-re-findall-with-brackets-in-Python%2F</url>
    <content type="text"><![CDATA[在 Python 中使用正则表达式进行匹配时，使用 re.search() 和 re.findall() 时对正则表达式的处理有所不同。 例如使用正则表达式 ([0-9A-F]{2}:){5}[0-9A-F]{2} 匹配一个 MAC 地址，待处理的字符串为 12:34:56:78:90:AB 。 使用 re.search() 进行匹配： 123import rematch = re.search('([0-9A-F]&#123;2&#125;:)&#123;5&#125;[0-9A-F]&#123;2&#125;', '12:34:56:78:90:AB').group()print(match) 结果为 ‘12:34:56:78:90:AB’ ，符合预期； 使用 re.findall() 进行匹配： 123import rematch = re.findall('([0-9A-F]&#123;2&#125;:)&#123;5&#125;[0-9A-F]&#123;2&#125;', '12:34:56:78:90:AB')print(match) 结果为 [‘90:’]，不符合预期。 主要原因是 re.findall() 在匹配的时候，返回的是括号所匹配到的结果，在这里是只返回 [0-9A-F]{2}: 的匹配结果，而且后面带有 {5} ，因此返回第五个符合的匹配；对于多个括号，则返回多个括号分别匹配到的结果；如果没有括号，则返回就返回整条语句所匹配到的结果。 解决方案是使用括号将整个正则表达式括起来，这样 re.findall() 将会从外到内将每一组括号匹配到的结果列出。 123import rematch = re.findall('(([0-9A-F]&#123;2&#125;:)&#123;5&#125;[0-9A-F]&#123;2&#125;)', '12:34:56:78:90:AB')print(match) 结果为 [(‘12:34:56:78:90:AB’, ‘90:’)] ，获取第一个元素即可。 实际上这是正则表达式所特有的 ， 任何一门高级语言使用正则都满足这个特点：有括号时只能匹配到括号中的内容，没有括号（相当于在最外层增加了一个括号）。在正则表达式里面 “()” 代表的是分组的意思，一个括号代表一个分组，匹配是只能匹配到 ”()” 中的内容。]]></content>
      <tags>
        <tag>Python</tag>
        <tag>坑</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 在字典中根据条件筛选数据]]></title>
    <url>%2F2018%2F07%2F11%2Ffilting-data-in-dictionaries-in-Python%2F</url>
    <content type="text"><![CDATA[首先创建一个字典 1234import randomd = &#123;str(x): random.randint(60, 100) for x in range(1, 21)&#125;print(d) 执行结果为 1&#123;'1': 65, '2': 75, '3': 96, '4': 85, '5': 78, '6': 94, '7': 92, '8': 68, '9': 94, '10': 72, '11': 97, '12': 65, '13': 64, '14': 72, '15': 88, '16': 93, '17': 75, '18': 61, '19': 83, '20': 71&#125; 如果需要在字典中筛选出值大于 90 的 id(key) 都有哪些，有以下四种实现方式： 循环迭代 12345dd = &#123;&#125;for k in d: if d[k] &gt; 90: dd[k] = d[k]print(dd) 结果为： 1&#123;'3': 96, '6': 94, '7': 92, '9': 94, '11': 97, '16': 93&#125; filter() 函数 12dd = list(filter(lambda x: d[x] &gt; 90, d))print(dd) 结果为： 1['3', '6', '7', '9', '11', '16'] 字典解析式 12dd = &#123;k: v for k, v in d.items() if v &gt; 90&#125;print(dd) 结果为： 1&#123;'3': 96, '6': 94, '7': 92, '9': 94, '11': 97, '16': 93&#125; 生成器解析式 123dd = (&#123;k: v&#125; for k, v in d.items() if v &gt; 90)for i in dd: print(i) 结果为： 123456&#123;'3': 96&#125;&#123;'6': 94&#125;&#123;'7': 92&#125;&#123;'9': 94&#125;&#123;'11': 97&#125;&#123;'16': 93&#125;]]></content>
      <tags>
        <tag>Python</tag>
        <tag>奇技淫巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Saltstack 初始化部署]]></title>
    <url>%2F2018%2F07%2F10%2Finitiation-of-saltstack%2F</url>
    <content type="text"><![CDATA[主控端安装 salt-master： 123yum install -y salt-mastersystemctl enable salt-master.servicesystemctl start salt-master.service 被控端安装 salt-minion： 123yum install -y salt-minionsystemctl enable salt-minion.servicesystemctl start salt-minion.service 在主控端添加 TCP 4505、TCP 4506 的规则，在被控端无需配置防火墙。原理是被控端直接与主控端的 zeroMQ 建立长连接，接受广播到的任务信息并执行。 12iptables -I INPUT -m state --state new -m tcp -p tcp --dport 4505 -j ACCEPTiptables -I INPUT -m state --state new -m tcp -p tcp --dport 4506 -j ACCEPT 在主控端进行角色配置，修改主控端配置文件 /etc/salt/master： 123456789interface: &#123;主控端 IP 地址&#125;# 自动认证，如果不打开，需要通过 `salt-key -a &#123;id&#125;` 进行 key 的认证auto_accept: true# 指定 Saltstack 文件根目录位置file_roots: base: - /srv/salt 然后重启主控端的 Saltstack 服务。 在被控端进行角色配置，修改被控端配置文件 /etc/salt/minion： 1234master: &#123;主控端 IP 地址&#125;# 修改被控端主机识别 idid: &#123;id&#125; 然后重启被控端的 Saltstack 服务。]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Python</tag>
        <tag>Saltstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用 Ansible 打补丁以及安装应用]]></title>
    <url>%2F2018%2F05%2F19%2FHow-to-use-Ansible-to-patch-systems-and-install-applications%2F</url>
    <content type="text"><![CDATA[使用 Ansible IT 自动化引擎节省更新的时间。 你有没有想过，如何打补丁、重启系统，然后继续工作？ 如果你的回答是肯定的，那就需要了解一下 Ansible 了。它是一个配置管理工具，对于一些复杂的有时候需要几个小时才能完成的系统管理任务，又或者对安全性有比较高要求的时候，使用 Ansible 能够大大简化工作流程。 以我作为系统管理员的经验，打补丁是一项最有难度的工作。每次遇到公共漏洞批露Common Vulnearbilities and Exposure（CVE）通知或者信息保障漏洞预警Information Assurance Vulnerability Alert（IAVA）时都必须要高度关注安全漏洞，否则安全部门将会严肃追究自己的责任。 使用 Ansible 可以通过运行封装模块以缩短打补丁的时间，下面以 yum 模块更新系统为例，使用 Ansible 可以执行安装、更新、删除、从其它地方安装（例如持续集成/持续开发中的 rpmbuild）。以下是系统更新的任务： 1234- name: update the system yum: name: &quot;*&quot; state: latest 在第一行，我们给这个任务命名，这样可以清楚 Ansible 的工作内容。第二行表示使用 yum 模块在CentOS虚拟机中执行更新操作。第三行 name: &quot;*&quot; 表示更新所有程序。最后一行 state: latest 表示更新到最新的 RPM。 系统更新结束之后，需要重新启动并重新连接： 1234567891011121314151617181920- name: restart system to reboot to newest kernel shell: &quot;sleep 5 &amp;&amp; reboot&quot; async: 1 poll: 0- name: wait for 10 seconds pause: seconds: 10- name: wait for the system to reboot wait_for_connection: connect_timeout: 20 sleep: 5 delay: 5 timeout: 60- name: install epel-release yum: name: epel-release state: latest shell 模块中的命令让系统在 5 秒休眠之后重新启动，我们使用 sleep 来保持连接不断开，使用 async 设定最大等待时长以避免发生超时，poll 设置为 0 表示直接执行不需要等待执行结果。暂停 10 秒钟以等待虚拟机恢复，使用 wait_for_connection 在虚拟机恢复连接后尽快连接。随后由 install epel-release 任务检查 RPM 的安装情况。你可以对这个剧本执行多次来验证它的幂等性，唯一会显示造成影响的是重启操作，因为我们使用了 shell 模块。如果不想造成实际的影响，可以在使用 shell 模块的时候 changed_when: False。 现在我们已经知道如何对系统进行更新、重启虚拟机、重新连接、安装 RPM 包。下面我们通过 Ansible Lightbulb 来安装 NGINX: 1234567891011121314151617181920212223242526272829303132333435363738- name: Ensure nginx packages are present yum: name: nginx, python-pip, python-devel, devel state: present notify: restart-nginx-service- name: Ensure uwsgi package is present pip: name: uwsgi state: present notify: restart-nginx-service- name: Ensure latest default.conf is present template: src: templates/nginx.conf.j2 dest: /etc/nginx/nginx.conf backup: yes notify: restart-nginx-service- name: Ensure latest index.html is present template: src: templates/index.html.j2 dest: /usr/share/nginx/html/index.html- name: Ensure nginx service is started and enabled service: name: nginx state: started enabled: yes- name: Ensure proper response from localhost can be received uri: url: &quot;http://localhost:80/&quot; return_content: yes register: response until: &apos;nginx_test_message in response.content&apos; retries: 10 delay: 1 以及用来重启 nginx 服务的操作文件： 12345# 安装 nginx 的操作文件 - name: restart-nginx-service service: name: nginx state: restarted 在这个角色里，我们使用 RPM 安装了 nginx、python-pip、python-devel、devel，用 PIP 安装了 uwsgi，接下来使用 template 模块复制 nginx.conf 和 index.html 以显示页面，并确保服务在系统启动时启动。然后就可以使用 uri 模块检查到页面的连接了。 这个是一个系统更新、系统重启、安装 RPM 包的剧本示例，后续可以继续安装 nginx，当然这里可以替换成任何你想要的角色和应用程序。 1234- hosts: all roles: - centos-update - nginx-simple 观看演示视频了解了解这个过程。 demo 这只是关于如何更新系统、重启以及后续工作的示例。简单起见，我只添加了不带变量的包，当你在操作大量主机的时候，你就需要修改其中的一些设置了： async &amp; poll serial forks 这是由于在生产环境中如果你想逐一更新每一台主机的系统，你需要花相当一段时间去等待主机重启才能够继续下去。 有关 Ansible 进行自动化工作的更多用法，请查阅其它文章。 via: https://opensource.com/article/18/3/ansible-patch-systems]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用树莓派测定颗粒物（PM 2.5）]]></title>
    <url>%2F2018%2F05%2F08%2FHow-to-measure-particulate-matter-with-a-Raspberry-Pi%2F</url>
    <content type="text"><![CDATA[使用两个简单的硬件设备和几行代码构建一个空气质量探测器。 我们在东南亚的学校定期测定空气中的颗粒物。这里的测定值非常高，尤其是在二到五月之间，干燥炎热、土地干旱等各种因素都对空气质量产生了不利的影响。我将会在这篇文章中展示如何使用树莓派来测定颗粒物。 什么是颗粒物？颗粒物就是粉尘或者空气中的微小颗粒。其中 PM10 和 PM2.5 之间的差别就是 PM10 指的是粒径小于 10 微米的颗粒，而 PM2.5 指的是粒径小于 2.5 微米的颗粒。在粒径小于 2.5 微米的的情况下，由于它们能被吸入肺泡中并且对呼吸系统造成影响，因此颗粒越小，对人的健康危害越大。 世界卫生组织的建议颗粒物浓度是： 年均 PM10 不高于 20 µg/m³ 年均 PM2.5 不高于 10 µg/m³ 不允许超标时，日均 PM10 不高于 50 µg/m³ 不允许超标时，日均 PM2.5 不高于 25 µg/m³ 以上数值实际上是低于大多数国家的标准的，例如欧盟对于 PM10 所允许的年均值是不高于 40 µg/m³。 什么是空气质量指数Air Quality Index（AQI）？空气质量指数是按照颗粒物的测定值来评价空气质量的好坏，然而由于各国之间的计算方式有所不同，这个指数并没有统一的标准。维基百科上关于空气质量指数的词条对此给出了一个概述。我们学校则以美国环境保护协会Environment Protection Agency（EPA）建立的分类法来作为依据。 空气质量指数 测定颗粒物需要哪些准备？测定颗粒物只需要以下两种器材： 树莓派（款式不限，最好带有 WiFi） SDS011 颗粒物传感器 颗粒物传感器 如果是只带有 Micro USB 的树莓派 Zero W，那还需要一根连接到标准 USB 端口的适配线，只需要 20 美元，而传感器则自带适配串行接口的 USB 适配器。 安装过程对于树莓派，只需要下载对应的 Raspbian Lite 镜像并且写入到 Micro SD 卡上就可以了（网上很多教程都有介绍如何设置 WLAN 连接，我就不细说了）。 如果要使用 SSH，那还需要在启动分区建立一个名为 ssh 的空文件。树莓派的 IP 通过路由器或者 DHCP 服务器获取，随后就可以通过 SSH 登录到树莓派了（默认密码是 raspberry）： 1$ ssh pi@192.168.1.5 首先我们需要在树莓派上安装一下这些包： 1$ sudo apt install git-core python-serial python-enum lighttpd 在开始之前，我们可以用 dmesg 来获取 USB 适配器连接的串行接口： 12345678$ dmesg[ 5.559802] usbcore: registered new interface driver usbserial[ 5.559930] usbcore: registered new interface driver usbserial_generic[ 5.560049] usbserial: USB Serial support registered for generic[ 5.569938] usbcore: registered new interface driver ch341[ 5.570079] usbserial: USB Serial support registered for ch341-uart[ 5.570217] ch341 1–1.4:1.0: ch341-uart converter detected[ 5.575686] usb 1–1.4: ch341-uart converter now attached to ttyUSB0 在最后一行，可以看到接口 ttyUSB0。然后我们需要写一个 Python 脚本来读取传感器的数据并以 JSON 格式存储，在通过一个 HTML 页面就可以把数据展示出来了。 在树莓派上读取数据首先创建一个传感器实例，每 5 分钟读取一次传感器的数据，持续 30 秒，这些数值后续都可以调整。在每两次测定的间隔，我们把传感器调到睡眠模式以延长它的使用寿命（厂商认为元件的寿命大约 8000 小时）。 我们可以使用以下命令来下载 Python 脚本： 1$ wget -O /home/pi/aqi.py https://raw.githubusercontent.com/zefanja/aqi/master/python/aqi.py 另外还需要执行以下两条命令来保证脚本正常运行： 12$ sudo chown pi:pi /var/www/html/$ echo &apos;[]&apos; &gt; /var/www/html/aqi.json 下面就可以执行脚本了： 123456789$ chmod +x aqi.p$ ./aqi.pyPM2.5:55.3, PM10:47.5PM2.5:55.5, PM10:47.7PM2.5:55.7, PM10:47.8PM2.5:53.9, PM10:47.6PM2.5:53.6, PM10:47.4PM2.5:54.2, PM10:47.3… 自动化执行脚本只需要使用诸如 crontab 的服务，我们就不需要每次都手动启动脚本了。按照以下命令打开 crontab 文件： 1$ crontab -e 在文件末尾添加这一行： 1@reboot cd /home/pi/ &amp;&amp; ./aqi.py 现在我们的脚本就会在树莓派每次重启后自动执行了。 展示颗粒物测定值和空气质量指数的 HTML 页面我们在前面已经安装了一个轻量级的 web 服务器 lighttpd，所以我们需要把 HTML、JavaScript、CSS 文件放置在 /var/www/html 目录中，这样就能通过电脑和智能手机访问到相关数据了。执行下面的三条命令，可以下载到对应的文件： 123$ wget -O /var/www/html/index.html https://raw.githubusercontent.com/zefanja/aqi/master/html/index.html$ wget -O /var/www/html/aqi.js https://raw.githubusercontent.com/zefanja/aqi/master/html/aqi.js$ wget -O /var/www/html/style.css https://raw.githubusercontent.com/zefanja/aqi/master/html/style.css 在 JavaScript 文件中，实现了打开 JSON 文件、提取数据、计算空气质量指数的过程，随后页面的背景颜色将会根据 EPA 的划分标准而变化。 你只需要用浏览器访问树莓派的地址，就可以看到当前颗粒物浓度值等数据了： http://192.168.1.5: 这个页面比较简单而且可扩展，比如可以添加一个展示过去数小时历史数据的表格等等。 这是Github上的完整源代码。 总结在资金相对紧张的情况下，树莓派是一种选择。除此以外，还有很多可以用来测定颗粒物的应用，包括室外固定装置、移动测定设备等等。我们学校则同时采用了这两种：固定装置在室外测定全天颗粒物浓度，而移动测定设备在室内检测空调过滤器的效果。 Luftdaten.info 提供了一个如何设计类似的传感器的介绍，其中的软件效果出众，而且因为它没有使用树莓派，所以硬件更是小巧。 对于学生来说，设计一个颗粒物传感器确实算得上是一个优秀的课外项目。 你又打算如何使用你的树莓派呢？ via: https://opensource.com/article/18/3/how-measure-particulate-matter-raspberry-pi]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>树莓派</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看 Linux 发行版名称和版本号的 8 种方法]]></title>
    <url>%2F2018%2F04%2F28%2FCheck-Linux-Distribution-Name-and-Version%2F</url>
    <content type="text"><![CDATA[如果你加入了一家新公司，要为开发团队安装所需的软件并重启服务，这个时候首先要弄清楚它们运行在什么发行版以及哪个版本的系统上，你才能正确完成后续的工作。作为系统管理员，充分了解系统信息是首要的任务。 查看 Linux 发行版名称和版本号有很多种方法。你可能会问，为什么要去了解这些基本信息呢？ 因为对于诸如 RHEL、Debian、openSUSE、Arch Linux 这几种主流发行版来说，它们各自拥有不同的包管理器来管理系统上的软件包，如果不知道所使用的是哪一个发行版的系统，在软件包安装的时候就会无从下手，而且由于大多数发行版都是用 systemd 命令而不是 SysVinit 脚本，在重启服务的时候也难以执行正确的命令。 下面来看看可以使用那些基本命令来查看 Linux 发行版名称和版本号。 方法总览 lsb_release 命令 /etc/*-release 文件 uname 命令 /proc/version 文件 dmesg 命令 YUM 或 DNF 命令 RPM 命令 APT-GET 命令 方法 1： lsb_release 命令LSB（Linux 标准库Linux Standard Base）能够打印发行版的具体信息，包括发行版名称、版本号、代号等。 123456# lsb_release -aNo LSB modules are available.Distributor ID: UbuntuDescription: Ubuntu 16.04.3 LTSRelease: 16.04Codename: xenial 方法 2： /etc/*-release 文件release 文件通常被视为操作系统的标识。在 /etc 目录下放置了很多记录着发行版各种信息的文件，每个发行版都各自有一套这样记录着相关信息的文件。下面是一组在 Ubuntu/Debian 系统上显示出来的文件内容。 123456789101112131415161718192021222324252627# cat /etc/issueUbuntu 16.04.3 LTS \n \l# cat /etc/issue.netUbuntu 16.04.3 LTS# cat /etc/lsb-releaseDISTRIB_ID=UbuntuDISTRIB_RELEASE=16.04DISTRIB_CODENAME=xenialDISTRIB_DESCRIPTION=&quot;Ubuntu 16.04.3 LTS&quot;# cat /etc/os-releaseNAME=&quot;Ubuntu&quot;VERSION=&quot;16.04.3 LTS (Xenial Xerus)&quot;ID=ubuntuID_LIKE=debianPRETTY_NAME=&quot;Ubuntu 16.04.3 LTS&quot;VERSION_ID=&quot;16.04&quot;HOME_URL=&quot;http://www.ubuntu.com/&quot;SUPPORT_URL=&quot;http://help.ubuntu.com/&quot;BUG_REPORT_URL=&quot;http://bugs.launchpad.net/ubuntu/&quot;VERSION_CODENAME=xenialUBUNTU_CODENAME=xenial# cat /etc/debian_version9.3 下面这一组是在 RHEL/CentOS/Fedora 系统上显示出来的文件内容。其中 /etc/redhat-release 和 /etc/system-release 文件是指向 /etc/[发行版名称]-release 文件的一个连接。 12345678910111213141516171819202122232425262728# cat /etc/centos-releaseCentOS release 6.9 (Final)# cat /etc/fedora-releaseFedora release 27 (Twenty Seven)# cat /etc/os-releaseNAME=FedoraVERSION=&quot;27 (Twenty Seven)&quot;ID=fedoraVERSION_ID=27PRETTY_NAME=&quot;Fedora 27 (Twenty Seven)&quot;ANSI_COLOR=&quot;0;34&quot;CPE_NAME=&quot;cpe:/o:fedoraproject:fedora:27&quot;HOME_URL=&quot;https://fedoraproject.org/&quot;SUPPORT_URL=&quot;https://fedoraproject.org/wiki/Communicating_and_getting_help&quot;BUG_REPORT_URL=&quot;https://bugzilla.redhat.com/&quot;REDHAT_BUGZILLA_PRODUCT=&quot;Fedora&quot;REDHAT_BUGZILLA_PRODUCT_VERSION=27REDHAT_SUPPORT_PRODUCT=&quot;Fedora&quot;REDHAT_SUPPORT_PRODUCT_VERSION=27PRIVACY_POLICY_URL=&quot;https://fedoraproject.org/wiki/Legal:PrivacyPolicy&quot;# cat /etc/redhat-releaseFedora release 27 (Twenty Seven)# cat /etc/system-releaseFedora release 27 (Twenty Seven) 方法 3： uname 命令uname（unix name 的意思） 是一个打印系统信息的工具，包括内核名称、版本号、系统详细信息以及所运行的操作系统等等。 建议阅读： 6种查看系统 Linux 内核的方法 12# uname -aLinux localhost.localdomain 4.12.14-300.fc26.x86_64 #1 SMP Wed Sep 20 16:28:07 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux 以上运行结果说明使用的操作系统版本是 Fedora 26。 方法 4： /proc/version 文件这个文件记录了 Linux 内核的版本、用于编译内核的 gcc 的版本、内核编译的时间，以及内核编译者的用户名。 12# cat /proc/versionLinux version 4.12.14-300.fc26.x86_64 ([email protected]) (gcc version 7.2.1 20170915 (Red Hat 7.2.1-2) (GCC) ) #1 SMP Wed Sep 20 16:28:07 UTC 2017 方法 5： dmesg 命令dmesg（展示信息display message 或驱动程序信息driver message）是大多数类 Unix 操作系统上的一个命令，用于打印内核的消息缓冲区的信息。 12345678910# dmesg | grep &quot;Linux&quot;[ 0.000000] Linux version 4.12.14-300.fc26.x86_64 ([email protected]) (gcc version 7.2.1 20170915 (Red Hat 7.2.1-2) (GCC) ) #1 SMP Wed Sep 20 16:28:07 UTC 2017[ 0.001000] SELinux: Initializing.[ 0.001000] SELinux: Starting in permissive mode[ 0.470288] SELinux: Registering netfilter hooks[ 0.616351] Linux agpgart interface v0.103[ 0.630063] usb usb1: Manufacturer: Linux 4.12.14-300.fc26.x86_64 ehci_hcd[ 0.688949] usb usb2: Manufacturer: Linux 4.12.14-300.fc26.x86_64 ohci_hcd[ 2.564554] SELinux: Disabled at runtime.[ 2.564584] SELinux: Unregistering netfilter hooks 方法 6： Yum/Dnf 命令Yum（Yellowdog 更新器修改版Yellowdog Updater Modified）是 Linux 操作系统上的一个包管理工具，而 yum 命令被用于一些基于 RedHat 的 Linux 发行版上安装、更新、查找、删除软件包。 建议阅读： 在 RHEL/CentOS 系统上使用 yum 命令管理软件包 1234567891011121314151617# yum info nanoLoaded plugins: fastestmirror, ovlLoading mirror speeds from cached hostfile * base: centos.zswap.net * extras: mirror2.evolution-host.com * updates: centos.zswap.netAvailable PackagesName : nanoArch : x86_64Version : 2.3.1Release : 10.el7Size : 440 kRepo : base/7/x86_64Summary : A small text editorURL : http://www.nano-editor.orgLicense : GPLv3+Description : GNU nano is a small and friendly text editor. 下面的 yum repolist 命令执行后显示了 yum 的基础源仓库、额外源仓库、更新源仓库都来自 CentOS 7 仓库。 1234567891011# yum repolistLoaded plugins: fastestmirror, ovlLoading mirror speeds from cached hostfile * base: centos.zswap.net * extras: mirror2.evolution-host.com * updates: centos.zswap.netrepo id repo name statusbase/7/x86_64 CentOS-7 - Base 9591extras/7/x86_64 CentOS-7 - Extras 388updates/7/x86_64 CentOS-7 - Updates 1929repolist: 11908 使用 dnf 命令也同样可以查看发行版名称和版本号。 建议阅读： 在 Fedora 系统上使用 DNF（YUM 的一个分支）命令管理软件包 123456789101112131415# dnf info nanoLast metadata expiration check: 0:01:25 ago on Thu Feb 15 01:59:31 2018.Installed PackagesName : nanoVersion : 2.8.7Release : 1.fc27Arch : x86_64Size : 2.1 MSource : nano-2.8.7-1.fc27.src.rpmRepo : @SystemFrom repo : fedoraSummary : A small text editorURL : https://www.nano-editor.orgLicense : GPLv3+Description : GNU nano is a small and friendly text editor. 方法 7： RPM 命令RPM（红帽包管理器RedHat Package Manager）是在 CentOS、Oracle Linux、Fedora 这些基于 RedHat 的操作系统上的一个强大的命令行包管理工具，同样也可以帮助我们查看系统的版本信息。 建议阅读： 在基于 RHEL 的系统上使用 RPM 命令管理软件包 12# rpm -q nanonano-2.8.7-1.fc27.x86_64 方法 8： APT-GET 命令Apt-Get（高级打包工具Advanced Packaging Tool）是一个强大的命令行工具，可以自动下载安装新软件包、更新已有的软件包、更新软件包列表索引，甚至更新整个 Debian 系统。 建议阅读： 在基于 Debian 的系统上使用 Apt-Get 和 Apt-Cache 命令管理软件包 12345678910# apt-cache policy nanonano: Installed: 2.5.3-2ubuntu2 Candidate: 2.5.3-2ubuntu2 Version table: * 2.5.3-2ubuntu2 500 500 http://nova.clouds.archive.ubuntu.com/ubuntu xenial-updates/main amd64 Packages 100 /var/lib/dpkg/status 2.5.3-2 500 500 http://nova.clouds.archive.ubuntu.com/ubuntu xenial/main amd64 Packages via: https://www.2daygeek.com/check-find-linux-distribution-name-and-version/]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>Linux</tag>
        <tag>版本</tag>
        <tag>发行版</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在树莓派上运行 DOS 系统]]></title>
    <url>%2F2018%2F04%2F14%2FRunning-DOS-on-the-Raspberry-Pi%2F</url>
    <content type="text"><![CDATA[不同的 CPU 架构意味着在树莓派上运行 DOS 并非唾手可得，但其实也没多麻烦。 FreeDOS 对大家来说也许并不陌生。它是一个完整、免费并且对 DOS 兼容良好的操作系统，它可以运行一些比较老旧的 DOS 游戏或者商用软件，也可以开发嵌入式的应用。只要在 MS-DOS 上能够运行的程序，在 FreeDOS 上都可以运行。 作为 FreeDOS 的发起者和项目协调人员，很多用户会把我作为内行人士进行发问。而我最常被问到的问题是：“FreeDOS 可以在树莓派上运行吗？” 这个问题并不令人意外。毕竟 Linux 在树莓派上能够很好地运行，而 FreeDOS 和 Linux 相比是一个更古老、占用资源更少的操作系统，那 FreeDOS 为啥不能树莓派上运行呢？ 简单来说。由于 CPU 架构的原因，FreeDOS 并不能在树莓派中独立运行。和其它 DOS 类的系统一样，FreeDOS 需要英特尔 x86 架构 CPU 以及 BIOS 来提供基础的运行时服务。而树莓派运行在 ARM 架构的 CPU 上，与英特尔 CPU 二进制不兼容，也没有 BIOS。因此树莓派在硬件层面就不支持 FreeDOS。 不过通过 PC 模拟器还是能在树莓派上运行 FreeDOS 的，虽然这样也许稍有不足，但也不失为一个能在树莓派上运行 FreeDOS 的方法。 DOSBox 怎么样?有人可能会问：“为什么不用 DOSBox 呢？” DOSBox 是一个开源的跨平台 x86 模拟器，在 Linux 上也能使用，它能够为应用软件尤其是游戏软件提供了一个类 DOS 的运行环境，所以如果你只是想玩 DOS 游戏的话，DOSBox 是一个不错的选择。但在大众眼中，DOSBox 是专为 DOS 游戏而设的，而在运行一些别的 DOS 应用软件方面，DOSBox 只是表现平平。 对多数人来说，这只是个人偏好的问题，我喜欢用 FreeDOS 来运行 DOS 游戏和其它程序，完整的 DOS 系统和 DOSBox 相比能让我体验到更好的灵活性和操控性。我只用 DOSBox 来玩游戏，在其它方面还是选择完整的 FreeDOS。 在树莓派上安装 FreeDOSQEMU（Quick EMUlator）是一款能在 Linux 系统上运行 DOS 系统的开源的虚拟机软件。很多流行的 Linux 系统都自带 QEMU。QEMU 在我的树莓派上的 Raspbian 系统中也同样能够运行，下文就有一些我在树莓派 Raspbian GNU/Linux 9 (Stretch) 系统中使用 QEMU 的截图。 去年我在写了一篇关于如何在 Linux 系统中运行 DOS 程序的文章的时候就用到了 QEMU，在树莓派上使用 QEMU 来安装运行 FreeDOS 的步骤基本上和在别的基于 GNOME 的系统上没有什么太大的区别。 在 QEMU 中你需要通过添加各种组件来搭建虚拟机。先指定一个用来安装运行 DOS 的虚拟磁盘镜像，通过 qemu-img 命令来创建一个虚拟磁盘镜像，对于 FreeDOS 来说不需要太大的空间，所以我只创建了一个 200MB 的虚拟磁盘： 1qemu-img create freedos.img 200M 和 VMware 或者 VirtualBox 这些 PC 模拟器不同，使用 QEMU 需要通过添加各种组件来搭建虚拟机，尽管有点麻烦，但是并不困难。我使用了以下这些参数来在树莓派上使用 QEMU 安装 FreeDOS 系统： 1qemu-system-i386 -m 16 -k en-us -rtc base=localtime -soundhw sb16,adlib -device cirrus-vga -hda freedos.img -cdrom FD12CD.iso -boot order=d 你可以在我其它的文章中找到这些命令的完整介绍。简单来说，上面这条命令指定了一个英特尔 i386 兼容虚拟机，并且分配了 16MB 内存、一个英文输入键盘、一个基于系统时间的实时时钟、一个声卡、一个音乐卡以及一个 VGA 卡。文件 freedos.img 指定为第一个硬盘（C:），FD12CD.iso 镜像作为 CD-ROM （D:）驱动。QEMU 设定为从 D: 的 CD-ROM 启动。 你只需要按照提示就可以轻松安装好 FreeDOS 1.2 了。但是由于 microSD 卡在面对大量的 I/O 时速度比较慢，所以安装操作系统需要花费很长时间。 在树莓派上运行 FreeDOS你的运行情况取决于使用哪一种 microSD 卡。我用的是 SanDisk Ultra 64GB microSDXC UHS-I U1A1 ，其中 U1 这种型号专用于支持 1080p 的视频录制（例如 GoPro），它的最低串行写速度能够达到 10MB/s。相比之下，V60 型号专用于 4K 视频录制，最低连续写入速度能达到 60MB/s。如果你的树莓派使用的是 V60 的 microSD 卡甚至是 V30（也能达到 30MB/s），你就能明显看到它的 I/O 性能会比我的好。 FreeDOS 安装好之后，你可以直接从 C: 进行启动。只需要按照下面的命令用 -boot order=c 来指定 QEMU 的启动顺序即可： 1​qemu-system-i386 -m 16 -k en-us -rtc base=localtime -soundhw sb16,adlib -device cirrus-vga -hda freedos.img -cdrom FD12CD.iso -boot order=c​ 只要树莓派的 QEMU 上安装了 FreeDOS，就不会出现明显的性能问题。例如游戏通常在每一关开始的时候会加载地图、怪物、声音等一系列的数据，尽管这些内容需要加载一段时间，但在正常玩的时候并没有出现性能不足的现象。 FreeDOS 1.2 自带了很多游戏以及其它应用软件，可以使用 FDIMPLES 包管理程序来安装它们。FreeDOS 1.2 里面我最喜欢的是一款叫 WING 的太空射击游戏，让人想起经典的街机游戏 Galaga（WING 就是 Wing Is Not Galaga 的递归缩写词）。 As-Easy-As 是我最喜欢的一个 DOS 应用程序，作为 20 世纪八九十年代流行的电子表格程序，它和当时的 Lotus 1-2-3 以及现在的 Microsoft Excel、LibreOffice Calc 一样具有强大的威力。As-Easy-As 和 Lotus 1-2-3 都将数据保存为 WKS 文件，现在新版本的 Microsoft Excel 已经无法读取这种文件了，而 LibreOffice Calc 视兼容性而定有可能支持。鉴于 As-Easy-As 的初始版本是一个共享软件，TRIUS 仍然为 As-Easy-As 5.7 免费提供激活码。 我也非常喜欢 GNU Emacs 编辑器，FreeDOS 也自带了一个叫 Freemacs 的类 Emacs 的文本编辑器。它比 FreeDOS 默认的 FreeDOS Edit 编辑器更强大，也能带来 GNU Emacs 的体验。如果你也需要，可以在 FreeDOS 1.2 中通过FDIMPLES包管理程序来安装。 是的，你或许真的可以在树莓派上运行 DOS即使树莓派在硬件上不支持 DOS，但是在模拟器的帮助下，DOS 还是能够在树莓派上运行。得益于 QEMU PC 模拟器，一些经典的 DOS 游戏和 DOS 应用程序能够运行在树莓派上。在执行磁盘 I/O ，尤其是大量密集操作（例如写入大量数据）的时候，性能可能会受到轻微的影响。当你使用 QEMU 并且在虚拟机里安装好 FreeDOS 之后，你就可以尽情享受经典的 DOS 程序了。 via: https://opensource.com/article/18/3/can-you-run-dos-raspberry-pi]]></content>
      <tags>
        <tag>LCTT 翻译</tag>
        <tag>树莓派</tag>
        <tag>DoS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 5.6 无口令 dump]]></title>
    <url>%2F2018%2F04%2F09%2Fhow-to-use-mysqldump-without-password%2F</url>
    <content type="text"><![CDATA[为了提高安全性，MySQL 5.6 开始在 mysql 和 mysqldump 命令中明文输入口令时报 Warning: Using apassword on the command line interface can be insecure. 的警告。 在使用 shell 脚本来导出数据的时候，还是不要使用明文口令为妙。对于 MySQL 5.6+，可以在配置文件（CentOS 7 中为 /etc/my.cnf）中加入以下内容，再使用 mysqldump 就不需要使用口令了。 123[mysqldump]user=&#123;MySQL 用户名&#125;password=&#123;口令&#125;]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 按照多个键进行排序]]></title>
    <url>%2F2017%2F08%2F16%2Fsorting-with-multi-keys-in-Python%2F</url>
    <content type="text"><![CDATA[在 Python 中，可以使用 list.sort() 或 sorted(list) 对列表进行排序，而且可以使用 key 参数使列表按照一定的键值来排序。 有一些情况下，需要首先对列表按照键值1来进行排序，排序后有多个元素的键值1相等，在每批键值1相等的元素当中，需要再按照键值2进行排序，甚至后续还有更多用以排序的键值。此时可以把 key 参数中 lambda 表达式的返回值修改为一个元组，其中元组的每个元素依次是需要依据排序的键值。 1234567891011121314151617181920212223242526from pprint import pprint lst = [ (2, 1), (1, 2), (1, 3), (1, 1) ] pprint(sorted(lst), key=lambda x: x[0])# 此时仅对第一个元素进行排序# [# (1, 2),# (1, 3), # (1, 1), # (2, 1) # ] pprint(sorted(lst), key=lambda x: (x[0], x[1]))# 此时先对第一个元素进行排序，在第一个元素相同的情况下，按第二个元素进行排序# [# (1, 1),# (1, 2), # (1, 3), # (2, 1) # ]]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快速安装 zsh]]></title>
    <url>%2F2017%2F04%2F28%2Fhow-to-install-zsh-quickly%2F</url>
    <content type="text"><![CDATA[在新机器上快速安装比 bash 不知道高到哪里去了的 zsh。 12345678# 安装 zshyum -y install zsh# 把默认 shell 替换为 zshchsh -s /bin/zsh# 安装 oh-my-zshwhich curl || yum -y install curlcurl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh]]></content>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 下普通用户获取 sudo 权限的方法]]></title>
    <url>%2F2017%2F04%2F01%2Fhow-to-grant-sudo-privilege-to-a-normal-user%2F</url>
    <content type="text"><![CDATA[在 Linux 创建新用户后，如果需要使该用户能以 sudo 方式执行命令，需要把用户添加到 sudoers 文件中，否则在使用 sudo 的时候会报“{user} is not in the sudoers file”错误。此时需要将用户添加到 sudoers 文件中，并使其获得相应权限。 首先需要使用 root 用户，执行命令： 1visudo 打开 sudoers 文件，然后在其中添加 12&#123;user&#125; ALL=(ALL:ALL) ALL%&#123;user&#125; ALL=(ALL) NOPASSWD: ALL # 设置&#123;user&#125;组下面的用户使用 sudo 不需要输入密码 保存后，该用户即可使用 sudo 命令。 4个 ALL 之中，第 1 个 ALL 是用户(user)，第 2 个 ALL 是机器，第 3 个 ALL 是新用户身分(run_as_user, 如 root, oracle)，第 4 个ALL 是命令。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Selenium 使用 Firefox 无头浏览器]]></title>
    <url>%2F2017%2F03%2F04%2Fhow-to-use-headless-browser-of-firefox%2F</url>
    <content type="text"><![CDATA[目前 Selenium 已经停止对 PhantomJS 的支持。虽然 webdriver.PhantomJS() 仍然可以使用，但最佳选择应该是 Firefox 或者 Chrome 对应的无头浏览器，如果需要使用 Firefox 无头浏览器，可以按照以下方式开启： 123456from selenium import webdriverfrom selenium.webdriver.firefox.options import Optionsoptions = Options()options.add_argument("-headless")driver = Firefox(firefox_options=options) 此时建立的 webdriver 对象就是一个 Firefox 的无头浏览器，如果需要使用 Chrome 无头浏览器，建立方法与 Firefox 差异不大。与 PhantomJS 无头浏览器相比，Firefox 无头浏览器建立对象的速度比较慢。]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Firefox</tag>
        <tag>PhantomJS</tag>
        <tag>Selenium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible 的各个模块及相关参数]]></title>
    <url>%2F2017%2F02%2F16%2Fsome-modules-and-related-parameters-in-Ansible%2F</url>
    <content type="text"><![CDATA[command：在被控节点上执行命令 command 是 Ansible 的默认模块，可以不通过 -m 指明使用该模块 可以直接执行 -a 中的命令，但由于不通过 shell 执行，所以与 shell 有关的变量、重定向、管道等功能无法使用 kwargs： chdir：目录名。首先跳转到该目录后再执行命令 shell：在被控节点上通过 shell 执行命令 与 command 模块基本相同，而且由于通过 shell 执行，所以可以使用变量、重定向、管道等功能，并且使用所选用户的默认 shell kwargs： chdir：目录名。首先跳转到该目录后再执行命令 script：在被控节点上执行主控节点上的脚本 直接在 -a 中指明主控节点上的脚本位置即可，且这个脚本需要有 x 权限 ping：检测某个目的节点是否响应 这个检测过程并不向目的节点发送 ping 包，只是反映目的节点是否可控，目的节点即使在可达的情况下也不一定可控 不指定 -a yum：在被控节点上通过 yum 管理软件 kwargs： name：软件包名称。如果为 * ，则执行 yum -y updtae；名称前面加 @ 为安装软件包组；名称前面加 @^ 为安装环境组；这个参数也可以是 url，此时通过指定的 rpm 文件进行安装 state：软件安装状态。如果为 present、latest 或 installed 则执行安装软件；如果为 absent 或 removed 则执行移除软件 copy：从主控节点向被控节点复制文件 kwargs： src：主控节点的文件位置。可以是绝对路径或相对路径，如果是一个目录，将会进行递归复制 dest：被控节点的文件位置。必须为绝对路径，且如果 src 是一个目录，dest 也必须为一个目录 directory_mode：递归设定目录的权限。默认为系统默认权限 force：是否覆盖。默认为 yes，即当目标文件和源文件不同时，强制覆盖文件，如果为 no 则只有在目标文件不存在时才复制 fetch：从被控节点向主控节点复制文件 与 copy 模块并不仅仅是方向相反，copy 可以复制文件和目录，而 fetch 模块只能复制文件 kwargs： src：被控节点的文件位置。 dest：文件在主控节点中的保存位置。真实的保存目录需要注意，如果指定了 dest 参数为 /foo，被控节点为 bar，则文件将会保存在 /foo/bar/ 下 fail_on_missing：被控节点中的文件不存在时是否报错。默认为 no，当为 no 时即使文件不存在也不会报错，此时主控节点也不会创建相应的目录 synchronize：通过 rsync 传输文件 kwargs： src：源文件的位置。 dest：目标文件的位置。 mode：推送模式或拉取模式。默认为推送模式 push，从主控节点向被控节点传输文件 delete：是否删除文件使两方一致。两方的一致性以推送方为准，默认为 no service：用于管理服务 kwargs： name：服务名称。 state：对服务的操作。包括启动(started)、停止(stopped)、重启(restarted)、重新加载(reloaded) enabled：是否开机启动。且 state 和 enabled 两个参数中至少要有一个 sleep：在 state=restarted 的时候，指定在 stop 和 start 之间暂停的秒数 get_url：通过 http/https/ftp 下载文件 kwargs： url：下载的 uri dest：文件下载目标位置。如果 dest 为目录，则使用服务器提供的文件名，或者如果没有提供，将使用远程服务器上的 url 的基本名称。 timeout：设置超时时间。默认为 10s headers：指定访问时的请求头。以 key: value 的格式填写]]></content>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看文件中的重复行]]></title>
    <url>%2F2016%2F12%2F12%2Fhow-to-find-duplicated-lines-in-files%2F</url>
    <content type="text"><![CDATA[1sort &lt;filename&gt; | uniq -cd uniq 命令用于报告重复的行，但只能用于相邻的两行，因此需要先用 sort 对文件中的个行进行排序。加入 -d 参数能把重复的行显示出来，加入 -c 参数能显示重复的行重复了多少次。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 pymysql 模块时查询返回字典的方法]]></title>
    <url>%2F2016%2F12%2F01%2Fhow-to-return-dictionary-when-using-pymysql-module-for-querying%2F</url>
    <content type="text"><![CDATA[使用 pymysql 模块在 MySQL 中进行查询时，如果是使用以下这种默认的查询方法时，调用 fetchone() 和 fetchall() 返回的查询结果将会分别是元组和嵌套元组，只能使用下标去访问查询出来的每个字段的值，相当不方便，也不灵活。 123456789101112131415import pymysqlconnection = &#123; "host": "", "user": "", "passwd": "", "db": "", "charset": "utf8"&#125;conn = pymysql.connect(**connection)cursor = conn.cursor()sql = "blabla"cursor.execute(sql)result = cursor.fetchall() 最方便的返回莫过于字典了，字段名作为键名，查询出来的值作为键值，与字段的顺序无关。需要在查询的时候返回字典，只需要在连接参数中指定一个 cursorclass 参数为 pymysql.cursors.DictCursor 即可，使用 fetchone() 和 fetchall() 返回的查询结果分别为字典和以每一行为一个字典组成的列表。 123456789101112131415import pymysqlconnection = &#123; "host": "", "user": "", "passwd": "", "db": "", "charset": "utf8", "cursorclass": pymysql.cursors.DictCursor&#125;conn = pymysql.connect(**connection)cursor = conn.cursor()sql = "blabla"cursor.execute(sql)result = cursor.fetchall()]]></content>
      <tags>
        <tag>Python</tag>
        <tag>MySQL</tag>
        <tag>奇技淫巧</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 7 上的 systemctl 配置]]></title>
    <url>%2F2016%2F09%2F09%2Fsystemctl-configurations-on-CentOS-7%2F</url>
    <content type="text"><![CDATA[CentOS 7 的服务 systemctl 脚本存放在目录 /usr/lib/systemd/ 下，有系统（system）和用户（user）之分，需要开机不登陆就能运行的程序，存在系统服务即 /usr/lib/systemd/system/ 目录下。 CentOS 7 的每一个服务以 .service 结尾，一般会分为 3 部分：[Unit]、[Service] 和 [Install]。 [Unit]部分主要是对这个服务的说明，内容包括Description和After，Description 用于描述服务，After用于描述服务类别 [Service]部分是服务的关键，是服务的一些具体运行参数的设置。Type=forking 是后台运行的形式，User=users 是设置服务运行的用户,Group=users 是设置服务运行的用户组,PIDFile 为存放 PID 的文件路径，ExecStart 为服务的具体运行命令,ExecReload 为重启命令，ExecStop 为停止命令，PrivateTmp=True 表示给服务分配独立的临时空间。 [Install]部分是服务安装的相关设置，可设置为多用户的。 注意：[Service]部分的启动、重启、停止命令全部要求使用绝对路径，使用相对路径则会报错。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[YAML 语法]]></title>
    <url>%2F2016%2F07%2F20%2FYAML-grammar%2F</url>
    <content type="text"><![CDATA[YMAL：YMAL Ain’t Markup Language 123456789101112131415---# 一位职工记录name: Example Developerjob: Developerskill: Eliteemployed: Truefoods: - Apple - Orange - Strawberry - Mangolanguages: ruby: Elite python: Elite dotnet: Lame YAML 总是以 — （三个横杠）作为文件的开始，这是 YAML 格式的一部分； 普通的键值对直接以 key: value 的格式每行存储，冒号后面必须为一个空格； 对于列表，列表中的每个元素都以 - （一个横杠 + 一个空格）开始，且每个元素的缩进相同； 对于字典，字典中的每一个键值对和普通的键值对一样（其实整个文件存储的形式就是键值对），但同一个字典中每个键值对的缩进也要相同； 在值中含有冒号等引起解析歧义的字符时，需要用双引号将整个值包住； 使用 来引用变量。]]></content>
      <tags>
        <tag>YAML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible Inventory 文件]]></title>
    <url>%2F2016%2F07%2F18%2FAnsible-Inventory-file%2F</url>
    <content type="text"><![CDATA[Ansible 的 Inventory 文件主要记录了连接主机的信息和配置，默认路径为 /etc/ansible/hosts。 在 Inventory 文件中以行为单位直接写入主机的 host，如果仅填写了 host，则其它信息均按照默认值（如 ssh 端口为22）。也可以按照组的格式进行配置： 1234567891011[group1]host1host2[group2]host2host3[group3:children]group1group2 同一个主机可以同时属于多个组，如 host2 可以同时属于 group1 组和 group2 组。组也可以作为另一个组的成员，如 group1 和 group2 就是 group3 的成员，因此 host1、host2、host3 均属于 group3 组。 在每个 host 后可以使用变量来设置一些具体的参数，例如端口、登录用户名等。也可以为整个组设定变量： 123[group1:vars]ansible_ssh_port=2222ansible_ssh_user=root 常用的 Inventory 参数： 1234567891011121314151617181920212223242526272829303132ansible_ssh_host 将要连接的远程主机名.与你想要设定的主机的别名不同的话,可通过此变量设置.ansible_ssh_port ssh端口号.如果不是默认的端口号,通过此变量设置.ansible_ssh_user 默认的 ssh 用户名ansible_ssh_pass ssh 密码(这种方式并不安全,我们强烈建议使用 --ask-pass 或 SSH 密钥)ansible_sudo_pass sudo 密码(这种方式并不安全,我们强烈建议使用 --ask-sudo-pass)ansible_sudo_exe (new in version 1.8) sudo 命令路径(适用于1.8及以上版本)ansible_connection 与主机的连接类型.比如:local, ssh 或者 paramiko. Ansible 1.2 以前默认使用paramiko.1.2 以后默认使用 &apos;smart&apos;,&apos;smart&apos; 方式会根据是否支持 ControlPersist, 来判断&apos;ssh&apos; 方式是否可行.ansible_ssh_private_key_file ssh 使用的私钥文件.适用于有多个密钥,而你不想使用 SSH 代理的情况.ansible_shell_type 目标系统的shell类型.默认情况下,命令的执行使用 &apos;sh&apos; 语法,可设置为 &apos;csh&apos; 或 &apos;fish&apos;.ansible_python_interpreter 目标主机的 python 路径.适用于的情况: 系统中有多个 Python, 或者命令路径不是&quot;/usr/bin/python&quot;,比如 \*BSD, 或者 /usr/bin/python 不是 2.X 版本的 Python.我们不使用 &quot;/usr/bin/env&quot; 机制,因为这要求远程用户的路径设置正确,且要求 &quot;python&quot; 可执行程序名不可为 python以外的名字(实际有可能名为python26). 与 ansible_python_interpreter 的工作方式相同,可设定如 ruby 或 perl 的路径....]]></content>
      <tags>
        <tag>Ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各种文档链接]]></title>
    <url>%2F2016%2F03%2F01%2Fdocs%2F</url>
    <content type="text"><![CDATA[Ansible BeautifulSoup itchat requests scrapy]]></content>
      <tags>
        <tag>文档</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在新机器上快速安装 Python 3]]></title>
    <url>%2F2016%2F02%2F14%2Fhow-to-install-Python-3-quickly%2F</url>
    <content type="text"><![CDATA[对于以 Python 3 为主力开发语言的人来说，在一台新的机器上必须尽早安装上 Python 3。而对于绝大多数 Linux 发行版来说，都只默认安装了 Python 2 而没有 Python 3，而且有一些 Linux 自带的命令（例如 yum）会依赖 Python 2，这就需要在安装 Python 3 的同时保留 Python 2，并且使两者区分开来。 快速安装如下： 123456789101112131415161718192021222324# 版本号version="3.6.2"# 安装依赖包yum -y groupinstall "Development tools"yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel# 下载 Python 3 源码，版本号可改which wget || yum -y install wgetwget https://www.python.org/ftp/python/$version/Python-$version.tar.xz# 解包、编译、安装mkdir /usr/local/python3mv ./Python-$version.tar.xz /usr/local/python3cd /usr/local/python3tar -xvJf Python-$version.tar.xzcd Python-$versionwhich gcc || yum install -y gcc./configure --prefix=/usr/local/python3make &amp;&amp; make install# 设定 Python 3 和 pip3 的软连接ln -s /usr/local/python3/bin/python3 /usr/bin/python3ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Python</tag>
        <tag>快速安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 Vim 内 sudo 保存文件]]></title>
    <url>%2F2016%2F01%2F29%2Fhow-to-save-files-using-sudo-without-quitting-vim%2F</url>
    <content type="text"><![CDATA[有时候未使用 root 用户在一些较为重要的目录下使用 Vim 编辑文件时，往往会因为权限不足而无法保存，而退出去 sudo 后重新编辑又比较浪费时间。这个时候需要在 Vim 中执行下面这个命令，就可以在不退出 Vim 的前提下 sudo 保存文件。 1:w !sudo tee % :w 在 Vim 中是保存文件，这是毫无疑问的。 ！后面跟一个命令，表示让 Vim 执行一个外部命令。 tee 是一个把 stdin 保存到文件的小工具，具体用法是： 1tee &#123;filename&#125; 就能将 stdin 流保存到指定的文件中。 % 是 Vim 当中一个只读寄存器的名字，总保存着当前编辑文件的文件路径。]]></content>
      <tags>
        <tag>奇技淫巧</tag>
        <tag>vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 引擎 MyISAM 和 InnoDB 的区别]]></title>
    <url>%2F2015%2F12%2F13%2Fthe-difference-between-MyISAM-and-InnoDB-in-MySQL%2F</url>
    <content type="text"><![CDATA[MySQL 5.5 开始 InnoDB 成为 MySQL 的默认引擎（之前是 MyISAM）。 MyISAM 不支持事务，InnoDB 支持事务。对于 InnoDB 每一条 SQL 语句都默认封装成事务自动提交，但会影响速度。所以最好把多条 SQL 语句放在 begin 和 commit 之间组成一个事务。 MyISAM 不支持外键，InnoDB 支持外键。如果一个 InnoDB 表包含外键，这个表转为 MyISAM 表的时候会失败。 MyISAM 是非聚集索引，数据文件是分离的，索引保存的是数据文件的指针，主键索引和辅助索引是独立的。InnoDB 是聚集索引，数据文件和索引绑定在一起，因此必须要有主键，且通过主键索引的效率很高。但辅助索引需要两次查询，先查询到主键，然后再通过主键查询到数据。 MyISAM 用一个变量保存了整个表的行数，执行 SELECT COUNT(*) 的时候直接读出该变量即可，速度很快。InnoDB 不保存表的具体行数，执行 SELECT COUNT(*) 的时候需要全表扫描。 MyISAM 支持全文索引，查询效率较高。InnoDB 不支持全文索引。 MyISAM 更强调性能，更适用于执行 SELECT 较多的情况。InnoDB 更适用于 INSERT 和 UPDATE 较多的情况。 MyISAM 在 DELETE 操作时会重新建立一个表，InnoDB 会一行一行地删除记录。 MyISAM 不支持行锁，只支持表锁。MyISAM 同一个表上的读锁和写锁是互斥的，MyISAM 并发读写时如果等待队列中同时有读和写请求，默认写请求的优先级高，但 MyISAM 的写操作性能较低，会导致进程阻塞。InnoDB 支持行锁。]]></content>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中的列表去重]]></title>
    <url>%2F2015%2F10%2F13%2Flist-deduplication-in-Python%2F</url>
    <content type="text"><![CDATA[在 Python 中，普通列表可以使用 set() 来进行去重，这是使用了集合的唯一性，把列表转换为集合之后保证没有重复的元素，然后再使用 list() 把集合转换为列表。但这种方法并不保证元素之间的顺序，而且如果原列表之中含有不能被 hash 的元素（如字典、集合之类），原列表更无法转换为集合类型。 这种情况下应该保持列表的类型，使用 lambda 表达式进行去重： 1234import functools.reducelst = [2, 3, 3, 1]func = lambda x, y: x if y in x else x + [y]functools.reduce(func, [[], ] + lst) 这个时候列表 lst 就是 [2, 3, 1] 了。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么读写文件推荐使用 with 语句块？]]></title>
    <url>%2F2015%2F10%2F11%2Fwhy-WITH-block-is-recommended-for-reading-and-writing-files%2F</url>
    <content type="text"><![CDATA[12with open('file_name') as f: data = f.read() 能够使用 with 语句块的条件是 with 所求值的对象必须有一个 __enter__() 方法，一个 __exit__() 方法。 而紧跟在 with 关键字后面的语句被求值后，返回对象的 __enter__() 方法被调用，这个方法的返回值将被赋值给 as 后面的变量。当 with 语句块中的全部语句被执行完之后，将调用前面返回对象的 __exit__() 方法。 对于读写文件来说，使用 with 语句块一般较为保险。在读文件时，如果使用了 with 语句块，在代码块结束后，由于自动执行了 __exit__() 方法，因此不需要手动使用 close() 方法来关闭被读的文件；当写文件时，操作系统往往不会立刻把数据写入磁盘，而是放到内存中缓存起来，空闲的时候再进行写入，只有调用 close() 方法时，操作系统才保证把没有写入的数据全部写入磁盘，忘记调用 close() 的后果是数据可能只写了一部分到磁盘，剩下的丢失了，而使用 with语句块就有效避免了这个问题。]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 的新式类和经典类]]></title>
    <url>%2F2015%2F08%2F19%2Fnew-class-and-classic-class-in-Python%2F</url>
    <content type="text"><![CDATA[在 Python 中声明一个类的时候，如果这个类继承 object 类，这个类就是新式类；如果这个类没有继承任何类，这个类就是经典类。 1234567# 声明一个新式类class new_class(object)： pass# 声明一个经典类class classic_class(object): pass Python 的新式类已经兼容经典类，而且新式类已经解决了经典类中关于多继承的缺陷，因此在 Python 中推荐使用新式类。 1234567891011121314151617class A: def foo(self): print('called A.foo()')class B(A): passclass C(A): def foo(self): print('called C.foo()')class D(B, C): passif __name__ == '__main__': d = D() d.foo() B、C 是 A 的子类，D 多继承了 B、C 两个类，其中 C 重写了 A 中的 foo() 方法。 如果 A 是经典类，当调用 D 的实例的 foo() 方法时，Python 会按照深度优先的方法去搜索 foo() ，路径是 B-A-C ，执行的是 A 中的 foo()； 如果 A 是新式类，当调用 D 的实例的 foo() 方法时，Python 会按照广度优先的方法去搜索 foo() ，路径是 B-C-A ，执行的是 C 中的 foo()。 因为 D 是直接继承 C 的，从逻辑上说，执行 C 中的 foo() 更加合理，因此新式类对多继承的处理更为合乎逻辑。 在 Python 3.x 中的新式类已经兼容了经典类，无论 A 是否继承 object 类， D 实例中的 foo() 都会执行 C 中的 foo()。但是在 Python 2.7 中这种差异仍然存在，因此还是推荐使用新式类，要继承 object 类。]]></content>
      <tags>
        <tag>Python</tag>
        <tag>类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows 下 Python 字符编码异常解决方案]]></title>
    <url>%2F2015%2F06%2F28%2Fhow-to-fix-Python-UnicodeEncodeError-on-Windows%2F</url>
    <content type="text"><![CDATA[在中文 Windows 系统中，文件的默认字符编码为 GBK，如果将一段编码为 UTF-8 的数据流在 Windows 下写入文件，就可能会解析失败并抛出 UnicodeEncodeError 异常。 解决方案是在打开要写入的文件时在 encoding 参数中指定数据流的编码，这样就能在先从数据流的编码转换为目的编码，然后写入文件。 1f = open('something.txt', 'w', encoding='utf-8') 对于一些编码不规范的文件，在读取是可能会遇到 UnicodeDecodeError 异常，因为在文件中有可能夹杂了一些非法编码的字符。这种情况下 open() 可以接受一个 errors 参数，来指定如果遇到编码错误时应该如何处理。这个参数有两个枚举值，分别是 strict 和 ignore，前者在遇到异常的时候直接抛出异常并退出，后者为直接忽略。 1f = open('something.txt', 'w', encoding='utf-8', errors='ignore')]]></content>
      <tags>
        <tag>Python</tag>
        <tag>Windows</tag>
        <tag>编码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用 sshkey 实现免密码 ssh]]></title>
    <url>%2F2015%2F03%2F15%2Fhow-to-SSH-with-sshekeys%2F</url>
    <content type="text"><![CDATA[在使用公有云的时候，可能会受到大量的扫描，其中大部分都是对常用用户（例如 root）的口令暴力猜测。虽说使用由各种字母、数字、符号混杂的口令能够大大提高安全性，但登录后看到那几万个 failed logins 总是有点碍眼。把 ssh 的端口从 22 改成其它不常见的端口也算是一个方法，但始终是治标不治本，毕竟这只能防一防那些随意乱扫的人，对于指定要 hack 某一台主机的，总能找到开放的 ssh 端口。 从另一个角度来说，在自己反复连接远程主机的时候，每次都需要重新输入口令，也是一键比较烦的事情。 使用 sshkey 来免口令 ssh 就可以避免以上两个问题。即使把 ssh 端口保持在 22，只要 sshkey 不符合，直接就拒绝连接了。同时，在ssh key 符合的情况下，能够不需要输入口令秒连接。 首先在本地 ssh-keygen -t rsa 生成密钥，就会在 ~/.ssh 目录下生成 id_rsa 和 id_rsa.pub 两个文件，分别是私钥和公钥。私钥是自己本地保存的，而公钥是可以公开分发的，因此将公钥文件 id_rsa.pub 通过能想到的各种方法放置到远程主机的 ~/.ssh 下，并执行 cat id_rsa.pub &gt;&gt; authorized_keys 追加写入，这样就相当于让远程主机认识到本地主机，可以免口令登录了。 然后修改 ssh 服务的配置文件 /etc/ssh/sshd_config ，把 PasswordAuthentication 字段的值改为 no，并重启 ssh 服务，就把 ssh 口令登录禁用了。]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为远程主机设置别名]]></title>
    <url>%2F2015%2F03%2F01%2Fset-alias-for-remote-hosts%2F</url>
    <content type="text"><![CDATA[在进行 ssh 或者 scp 的时候，为了减少输入量和降低输入错误的概率，可以为常用的远程主机设置别名。 方法是修改 ~/.ssh/config 文件（如果不存在这个文件则创建），指定以下几个字段值即可： 1234host &#123;自定义的主机别名&#125;hostname &#123;主机的 IP&#125;port &#123;连接主机的端口&#125;user &#123;连接主机的用户名&#125;]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 WordPress 上在线安装插件的坑]]></title>
    <url>%2F2015%2F02%2F13%2Fpitfalls-of-online-installing-plugin-in-WordPress%2F</url>
    <content type="text"><![CDATA[通过 WordPress 在线安装插件，目前遇到过两个坑： 如果通过 WordPress 在线安装插件，可能会遇到“无法连接到文件系统，请确认您的凭据”的提示。这种情况下一般不是 FTP 账号密码错误，而是安装插件所需要的操作权限不够。需要把 wordpress/、wordpress/wp-content/、wordpress/wp-content/plugins/ 这三个目录的权限设置为 777，并且在配置文件 wp-config.php 中加入以下几行： 123define("FS_METHOD","direct");define("FS_CHMOD_DIR", 0777);define("FS_CHMOD_FILE", 0777); 开始安装后，可能会提示安装失败。这种情况下很可能是 DNS 被封的原因导致，把系统配置文件 /etc/resolv.conf 中的两个 nameserver 值改为 Google 的 8.8.8.8 和 8.8.4.4 后保存即可。]]></content>
      <tags>
        <tag>坑</tag>
        <tag>PHP</tag>
        <tag>WordPress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 中时间戳、格式化时间、时间数组、datetime 之间的转换]]></title>
    <url>%2F2014%2F12%2F03%2Fthe-transformation-among-timestamp-formatted-time-datetime-and-time-tuple-in-Python%2F</url>
    <content type="text"><![CDATA[1234567891011121314151617181920212223242526import timefrom datetime import datetime # 获得时间戳timestamp = time.time() # 时间戳转为时间数组time_array = time.localtime(timestamp) # 时间数组转为时间戳timestamp = time.mktime(time_array()) # 格式化时间转为时间数组time_array = time.strptime(format_time, '%Y-%m-%d %H:%M:%S') # 时间数组转为格式化时间format_time = time.strftime('%Y-%m-%d %H:%M:%S', time_array) # datetime 转为时间戳ts = dt.timestamp() # 时间戳转为 datetimedt = datetime.fromtimestamp(ts) # 直接输出当前的格式化时间time.strftime('%Y-%m-%d %H:%M:%S')]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在 CentOS 7 上手动搭建 LAMP 环境]]></title>
    <url>%2F2014%2F11%2F29%2Fhow-to-build-LAMP-environment-on-CentOS-7%2F</url>
    <content type="text"><![CDATA[拿到一台新的服务器之后，如果要搭 WordPress 之类的服务，就需要搭建一个 LAMP 环境。 鉴于网上各种一键 LAMP 的质量稂莠不齐，自己搭一个还是比较妥当的做法，而且后续如果需要自定义配置的话更加方便，不至于发生太多关于包依赖的问题。 12345678910111213141516171819202122# 安装 Apacheyum -y install httpd# 启动服务systemctl start httpd.service# 设置开机自动启动systemctl enable httpd.service # 安装 MySQL（在 CentOS 7 上其实是 MariaDB，但兼容 MySQL）yum -y install mariadb mariadb-server# 启动服务systemctl start mariadb.service# 设置开机启动服务systemctl enable mariadb.service# 设置数据库管理员密码mysql_secure_installation # 安装 PHPyum -y install php# 安装各种 PHP 的组件yum -y install php-gd php-ldap php-odbc php-pear php-xml php-xmlrpc php-mbstring php-snmp php-soap curl curl-devel php-mysql# 重启一下systemctl restart httpd.service 这样基本就可以直接安装 WordPress 了。]]></content>
      <tags>
        <tag>MySQL</tag>
        <tag>Apache</tag>
        <tag>LAMP</tag>
        <tag>PHP</tag>
      </tags>
  </entry>
</search>
